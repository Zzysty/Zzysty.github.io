<!DOCTYPE html>
<html lang="en"><head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <meta name="robots" content="noindex, nofollow" />
  <link rel="icon shortcut" href="/favicon.ico" sizes="32x32" />
<link rel="icon" href="/favicon.svg" type="image/svg+xml" />
<link rel="icon" href="/favicon-dark.svg" type="image/svg+xml" media="(prefers-color-scheme: dark)" />
<link rel="icon" href="/favicon-16x16.png" type="image/png" sizes="16x16" />
<link rel="icon" href="/favicon-32x32.png" type="image/png" sizes="32x32" />
<link rel="apple-touch-icon" href="/apple-touch-icon.png" sizes="180x180" />
<link fetchpriority="low" href="/site.webmanifest" rel="manifest" />

  <title>Deeplearning – Hextra</title>
  <meta name="description" content="网络模型LeNet 它是最早发布的卷积神经网络之一，因其在计算机视觉任务中的高效性能而受到广泛关注。 这个模型是由AT&amp;T贝尔实验室的研" />

  
    <link rel="canonical" href="http://localhost:1313/docs/deeplearning/" itemprop="url" />
  

  

<meta property="og:title" content="Deeplearning" />
<meta property="og:description" content="网络模型LeNet 它是最早发布的卷积神经网络之一，因其在计算机视觉任务中的高效性能而受到广泛关注。 这个模型是由AT&amp;T贝尔实验室的研" />
<meta property="og:type" content="article" />
<meta property="og:url" content="http://localhost:1313/docs/deeplearning/" /><meta property="article:section" content="docs" />
<meta property="article:published_time" content="2024-08-14T21:12:08+08:00" />
<meta property="article:modified_time" content="2024-08-14T21:44:21+08:00" />

  
  <meta itemprop="name" content="Deeplearning">
  <meta itemprop="description" content="网络模型LeNet 它是最早发布的卷积神经网络之一，因其在计算机视觉任务中的高效性能而受到广泛关注。 这个模型是由AT&amp;T贝尔实验室的研">
  <meta itemprop="datePublished" content="2024-08-14T21:12:08+08:00">
  <meta itemprop="dateModified" content="2024-08-14T21:44:21+08:00">
  <meta itemprop="wordCount" content="29285">
  <meta name="twitter:card" content="summary">
  <meta name="twitter:title" content="Deeplearning">
  <meta name="twitter:description" content="网络模型LeNet 它是最早发布的卷积神经网络之一，因其在计算机视觉任务中的高效性能而受到广泛关注。 这个模型是由AT&amp;T贝尔实验室的研">

    <link href="/css/compiled/main.css" rel="stylesheet" />



  <link href="/css/custom.css" rel="stylesheet" />



  


  <script>
     
    const defaultTheme = 'system';

    const setDarkTheme = () => {
      document.documentElement.classList.add("dark");
      document.documentElement.style.colorScheme = "dark";
    }
    const setLightTheme = () => {
      document.documentElement.classList.remove("dark");
      document.documentElement.style.colorScheme = "light";
    }

    if ("color-theme" in localStorage) {
      localStorage.getItem("color-theme") === "dark" ? setDarkTheme() : setLightTheme();
    } else {
      defaultTheme === "dark" ? setDarkTheme() : setLightTheme();
      if (defaultTheme === "system") {
        window.matchMedia("(prefers-color-scheme: dark)").matches ? setDarkTheme() : setLightTheme();
      }
    }
  </script>

  
</head>
<body dir="ltr"><div class="nav-container hx-sticky hx-top-0 hx-z-20 hx-w-full hx-bg-transparent print:hx-hidden">
  <div class="nav-container-blur hx-pointer-events-none hx-absolute hx-z-[-1] hx-h-full hx-w-full hx-bg-white dark:hx-bg-dark hx-shadow-[0_2px_4px_rgba(0,0,0,.02),0_1px_0_rgba(0,0,0,.06)] contrast-more:hx-shadow-[0_0_0_1px_#000] dark:hx-shadow-[0_-1px_0_rgba(255,255,255,.1)_inset] contrast-more:dark:hx-shadow-[0_0_0_1px_#fff]"></div>

  <nav class="hx-mx-auto hx-flex hx-items-center hx-justify-end hx-gap-2 hx-h-16 hx-px-6 hx-max-w-[90rem]">
    <a class="hx-flex hx-items-center hover:hx-opacity-75 ltr:hx-mr-auto rtl:hx-ml-auto" href="/">
        <img class="hx-block dark:hx-hidden" src="/images/logo.svg" alt="Hextra" height="20" width="20" />
        <img class="hx-hidden dark:hx-block" src="/images/logo-dark.svg" alt="Hextra" height="20" width="20" />
        <span class="hx-mx-2 hx-font-extrabold hx-inline hx-select-none" title="Hextra">Hextra</span>
    </a><a
            title="Docs"
            href="/docs"
            
            class="hx-text-sm contrast-more:hx-text-gray-700 contrast-more:dark:hx-text-gray-100 hx-relative -hx-ml-2 hx-hidden hx-whitespace-nowrap hx-p-2 md:hx-inline-block hx-font-medium"
          >
            <span class="hx-text-center">Docs</span>
          </a><a
            title="Blog"
            href="/blog"
            
            class="hx-text-sm contrast-more:hx-text-gray-700 contrast-more:dark:hx-text-gray-100 hx-relative -hx-ml-2 hx-hidden hx-whitespace-nowrap hx-p-2 md:hx-inline-block hx-text-gray-600 hover:hx-text-gray-800 dark:hx-text-gray-400 dark:hover:hx-text-gray-200"
          >
            <span class="hx-text-center">Blog</span>
          </a><a
            title="Project"
            href="/project"
            
            class="hx-text-sm contrast-more:hx-text-gray-700 contrast-more:dark:hx-text-gray-100 hx-relative -hx-ml-2 hx-hidden hx-whitespace-nowrap hx-p-2 md:hx-inline-block hx-text-gray-600 hover:hx-text-gray-800 dark:hx-text-gray-400 dark:hover:hx-text-gray-200"
          >
            <span class="hx-text-center">Project</span>
          </a><a
            title="About"
            href="/about"
            
            class="hx-text-sm contrast-more:hx-text-gray-700 contrast-more:dark:hx-text-gray-100 hx-relative -hx-ml-2 hx-hidden hx-whitespace-nowrap hx-p-2 md:hx-inline-block hx-text-gray-600 hover:hx-text-gray-800 dark:hx-text-gray-400 dark:hover:hx-text-gray-200"
          >
            <span class="hx-text-center">About</span>
          </a><div class="search-wrapper hx-relative md:hx-w-64">
  <div class="hx-relative hx-flex hx-items-center hx-text-gray-900 contrast-more:hx-text-gray-800 dark:hx-text-gray-300 contrast-more:dark:hx-text-gray-300">
    <input
      placeholder="Search..."
      class="search-input hx-block hx-w-full hx-appearance-none hx-rounded-lg hx-px-3 hx-py-2 hx-transition-colors hx-text-base hx-leading-tight md:hx-text-sm hx-bg-black/[.05] dark:hx-bg-gray-50/10 focus:hx-bg-white dark:focus:hx-bg-dark placeholder:hx-text-gray-500 dark:placeholder:hx-text-gray-400 contrast-more:hx-border contrast-more:hx-border-current"
      type="search"
      value=""
      spellcheck="false"
    />
    <kbd
      class="hx-absolute hx-my-1.5 hx-select-none ltr:hx-right-1.5 rtl:hx-left-1.5 hx-h-5 hx-rounded hx-bg-white hx-px-1.5 hx-font-mono hx-text-[10px] hx-font-medium hx-text-gray-500 hx-border dark:hx-border-gray-100/20 dark:hx-bg-dark/50 contrast-more:hx-border-current contrast-more:hx-text-current contrast-more:dark:hx-border-current hx-items-center hx-gap-1 hx-transition-opacity hx-pointer-events-none hx-hidden sm:hx-flex"
    >
      CTRL K
    </kbd>
  </div>

  <div>
    <ul
      class="search-results hextra-scrollbar hx-hidden hx-border hx-border-gray-200 hx-bg-white hx-text-gray-100 dark:hx-border-neutral-800 dark:hx-bg-neutral-900 hx-absolute hx-top-full hx-z-20 hx-mt-2 hx-overflow-auto hx-overscroll-contain hx-rounded-xl hx-py-2.5 hx-shadow-xl hx-max-h-[min(calc(50vh-11rem-env(safe-area-inset-bottom)),400px)] md:hx-max-h-[min(calc(100vh-5rem-env(safe-area-inset-bottom)),400px)] hx-inset-x-0 ltr:md:hx-left-auto rtl:md:hx-right-auto contrast-more:hx-border contrast-more:hx-border-gray-900 contrast-more:dark:hx-border-gray-50 hx-w-screen hx-min-h-[100px] hx-max-w-[min(calc(100vw-2rem),calc(100%+20rem))]"
      style="transition: max-height 0.2s ease 0s;"
    ></ul>
  </div>
</div>
<button type="button" aria-label="Menu" class="hamburger-menu -hx-mr-2 hx-rounded hx-p-2 active:hx-bg-gray-400/20 md:hx-hidden"><svg height=24 fill="none" viewBox="0 0 24 24" stroke="currentColor"><g><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M4 8H20"></path></g><g><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M4 16H20"></path></g></svg></button>
  </nav>
</div>

  <div class='hx-mx-auto hx-flex hx-max-w-screen-xl'>
    <div class="mobile-menu-overlay [transition:background-color_1.5s_ease] hx-fixed hx-inset-0 hx-z-10 hx-bg-black/80 dark:hx-bg-black/60 hx-hidden"></div>
<aside class="sidebar-container hx-flex hx-flex-col print:hx-hidden md:hx-top-16 md:hx-shrink-0 md:hx-w-64 md:hx-self-start max-md:[transform:translate3d(0,-100%,0)] md:hx-sticky">
  
  <div class="hx-px-4 hx-pt-4 md:hx-hidden">
    <div class="search-wrapper hx-relative md:hx-w-64">
  <div class="hx-relative hx-flex hx-items-center hx-text-gray-900 contrast-more:hx-text-gray-800 dark:hx-text-gray-300 contrast-more:dark:hx-text-gray-300">
    <input
      placeholder="Search..."
      class="search-input hx-block hx-w-full hx-appearance-none hx-rounded-lg hx-px-3 hx-py-2 hx-transition-colors hx-text-base hx-leading-tight md:hx-text-sm hx-bg-black/[.05] dark:hx-bg-gray-50/10 focus:hx-bg-white dark:focus:hx-bg-dark placeholder:hx-text-gray-500 dark:placeholder:hx-text-gray-400 contrast-more:hx-border contrast-more:hx-border-current"
      type="search"
      value=""
      spellcheck="false"
    />
    <kbd
      class="hx-absolute hx-my-1.5 hx-select-none ltr:hx-right-1.5 rtl:hx-left-1.5 hx-h-5 hx-rounded hx-bg-white hx-px-1.5 hx-font-mono hx-text-[10px] hx-font-medium hx-text-gray-500 hx-border dark:hx-border-gray-100/20 dark:hx-bg-dark/50 contrast-more:hx-border-current contrast-more:hx-text-current contrast-more:dark:hx-border-current hx-items-center hx-gap-1 hx-transition-opacity hx-pointer-events-none hx-hidden sm:hx-flex"
    >
      CTRL K
    </kbd>
  </div>

  <div>
    <ul
      class="search-results hextra-scrollbar hx-hidden hx-border hx-border-gray-200 hx-bg-white hx-text-gray-100 dark:hx-border-neutral-800 dark:hx-bg-neutral-900 hx-absolute hx-top-full hx-z-20 hx-mt-2 hx-overflow-auto hx-overscroll-contain hx-rounded-xl hx-py-2.5 hx-shadow-xl hx-max-h-[min(calc(50vh-11rem-env(safe-area-inset-bottom)),400px)] md:hx-max-h-[min(calc(100vh-5rem-env(safe-area-inset-bottom)),400px)] hx-inset-x-0 ltr:md:hx-left-auto rtl:md:hx-right-auto contrast-more:hx-border contrast-more:hx-border-gray-900 contrast-more:dark:hx-border-gray-50 hx-w-screen hx-min-h-[100px] hx-max-w-[min(calc(100vw-2rem),calc(100%+20rem))]"
      style="transition: max-height 0.2s ease 0s;"
    ></ul>
  </div>
</div>

  </div>
  <div class="hextra-scrollbar hx-overflow-y-auto hx-overflow-x-hidden hx-p-4 hx-grow md:hx-h-[calc(100vh-var(--navbar-height)-var(--menu-height))]">
    <ul class="hx-flex hx-flex-col hx-gap-1 md:hx-hidden">
      
      
          <li class=""><a
    class="hx-flex hx-items-center hx-justify-between hx-gap-2 hx-cursor-pointer hx-rounded hx-px-2 hx-py-1.5 hx-text-sm hx-transition-colors [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] [word-break:break-word]
      hx-text-gray-500 hover:hx-bg-gray-100 hover:hx-text-gray-900 contrast-more:hx-border contrast-more:hx-border-transparent contrast-more:hx-text-gray-900 contrast-more:hover:hx-border-gray-900 dark:hx-text-neutral-400 dark:hover:hx-bg-primary-100/5 dark:hover:hx-text-gray-50 contrast-more:dark:hx-text-gray-50 contrast-more:dark:hover:hx-border-gray-50"
    href="/about/"
    
  >About
    </a></li>
          <li class=""><a
    class="hx-flex hx-items-center hx-justify-between hx-gap-2 hx-cursor-pointer hx-rounded hx-px-2 hx-py-1.5 hx-text-sm hx-transition-colors [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] [word-break:break-word]
      hx-text-gray-500 hover:hx-bg-gray-100 hover:hx-text-gray-900 contrast-more:hx-border contrast-more:hx-border-transparent contrast-more:hx-text-gray-900 contrast-more:hover:hx-border-gray-900 dark:hx-text-neutral-400 dark:hover:hx-bg-primary-100/5 dark:hover:hx-text-gray-50 contrast-more:dark:hx-text-gray-50 contrast-more:dark:hover:hx-border-gray-50"
    href="/blog/"
    
  >Blog
    </a></li>
          <li class="open"><a
    class="hx-flex hx-items-center hx-justify-between hx-gap-2 hx-cursor-pointer hx-rounded hx-px-2 hx-py-1.5 hx-text-sm hx-transition-colors [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] [word-break:break-word]
      hx-text-gray-500 hover:hx-bg-gray-100 hover:hx-text-gray-900 contrast-more:hx-border contrast-more:hx-border-transparent contrast-more:hx-text-gray-900 contrast-more:hover:hx-border-gray-900 dark:hx-text-neutral-400 dark:hover:hx-bg-primary-100/5 dark:hover:hx-text-gray-50 contrast-more:dark:hx-text-gray-50 contrast-more:dark:hover:hx-border-gray-50"
    href="/docs/"
    
  >Docs
        <span class="hextra-sidebar-collapsible-button"><svg fill="none" viewBox="0 0 24 24" stroke="currentColor" class="hx-h-[18px] hx-min-w-[18px] hx-rounded-sm hx-p-0.5 hover:hx-bg-gray-800/5 dark:hover:hx-bg-gray-100/5"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M9 5l7 7-7 7" class="hx-origin-center hx-transition-transform rtl:-hx-rotate-180"></path></svg></span>
    </a><div class="ltr:hx-pr-0 hx-overflow-hidden">
        <ul class='hx-relative hx-flex hx-flex-col hx-gap-1 before:hx-absolute before:hx-inset-y-1 before:hx-w-px before:hx-bg-gray-200 before:hx-content-[""] ltr:hx-ml-3 ltr:hx-pl-3 ltr:before:hx-left-0 rtl:hx-mr-3 rtl:hx-pr-3 rtl:before:hx-right-0 dark:before:hx-bg-neutral-800'><li class="hx-flex hx-flex-col open"><a
    class="hx-flex hx-items-center hx-justify-between hx-gap-2 hx-cursor-pointer hx-rounded hx-px-2 hx-py-1.5 hx-text-sm hx-transition-colors [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] [word-break:break-word]
      sidebar-active-item hx-bg-primary-100 hx-font-semibold hx-text-primary-800 contrast-more:hx-border contrast-more:hx-border-primary-500 dark:hx-bg-primary-400/10 dark:hx-text-primary-600 contrast-more:dark:hx-border-primary-500"
    href="/docs/deeplearning/"
    
  >Deeplearning
    </a>
  
    <ul class='hx-flex hx-flex-col hx-gap-1 hx-relative before:hx-absolute before:hx-inset-y-1 before:hx-w-px before:hx-bg-gray-200 before:hx-content-[""] dark:before:hx-bg-neutral-800 ltr:hx-pl-3 ltr:before:hx-left-0 rtl:hx-pr-3 rtl:before:hx-right-0 ltr:hx-ml-3 rtl:hx-mr-3'><li>
              <a
                href="#lenet"
                class="hx-flex hx-rounded hx-px-2 hx-py-1.5 hx-text-sm hx-transition-colors [word-break:break-word] hx-cursor-pointer [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] contrast-more:hx-border hx-gap-2 before:hx-opacity-25 before:hx-content-['#'] hx-text-gray-500 hover:hx-bg-gray-100 hover:hx-text-gray-900 dark:hx-text-neutral-400 dark:hover:hx-bg-primary-100/5 dark:hover:hx-text-gray-50 contrast-more:hx-text-gray-900 contrast-more:dark:hx-text-gray-50 contrast-more:hx-border-transparent contrast-more:hover:hx-border-gray-900 contrast-more:dark:hover:hx-border-gray-50"
              >LeNet</a>
            </li>
          <li>
              <a
                href="#alexnet"
                class="hx-flex hx-rounded hx-px-2 hx-py-1.5 hx-text-sm hx-transition-colors [word-break:break-word] hx-cursor-pointer [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] contrast-more:hx-border hx-gap-2 before:hx-opacity-25 before:hx-content-['#'] hx-text-gray-500 hover:hx-bg-gray-100 hover:hx-text-gray-900 dark:hx-text-neutral-400 dark:hover:hx-bg-primary-100/5 dark:hover:hx-text-gray-50 contrast-more:hx-text-gray-900 contrast-more:dark:hx-text-gray-50 contrast-more:hx-border-transparent contrast-more:hover:hx-border-gray-900 contrast-more:dark:hover:hx-border-gray-50"
              >AlexNet</a>
            </li>
          <li>
              <a
                href="#vggnet"
                class="hx-flex hx-rounded hx-px-2 hx-py-1.5 hx-text-sm hx-transition-colors [word-break:break-word] hx-cursor-pointer [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] contrast-more:hx-border hx-gap-2 before:hx-opacity-25 before:hx-content-['#'] hx-text-gray-500 hover:hx-bg-gray-100 hover:hx-text-gray-900 dark:hx-text-neutral-400 dark:hover:hx-bg-primary-100/5 dark:hover:hx-text-gray-50 contrast-more:hx-text-gray-900 contrast-more:dark:hx-text-gray-50 contrast-more:hx-border-transparent contrast-more:hover:hx-border-gray-900 contrast-more:dark:hover:hx-border-gray-50"
              >VGGNet</a>
            </li>
          <li>
              <a
                href="#nin"
                class="hx-flex hx-rounded hx-px-2 hx-py-1.5 hx-text-sm hx-transition-colors [word-break:break-word] hx-cursor-pointer [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] contrast-more:hx-border hx-gap-2 before:hx-opacity-25 before:hx-content-['#'] hx-text-gray-500 hover:hx-bg-gray-100 hover:hx-text-gray-900 dark:hx-text-neutral-400 dark:hover:hx-bg-primary-100/5 dark:hover:hx-text-gray-50 contrast-more:hx-text-gray-900 contrast-more:dark:hx-text-gray-50 contrast-more:hx-border-transparent contrast-more:hover:hx-border-gray-900 contrast-more:dark:hover:hx-border-gray-50"
              >NiN</a>
            </li>
          <li>
              <a
                href="#googlenet"
                class="hx-flex hx-rounded hx-px-2 hx-py-1.5 hx-text-sm hx-transition-colors [word-break:break-word] hx-cursor-pointer [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] contrast-more:hx-border hx-gap-2 before:hx-opacity-25 before:hx-content-['#'] hx-text-gray-500 hover:hx-bg-gray-100 hover:hx-text-gray-900 dark:hx-text-neutral-400 dark:hover:hx-bg-primary-100/5 dark:hover:hx-text-gray-50 contrast-more:hx-text-gray-900 contrast-more:dark:hx-text-gray-50 contrast-more:hx-border-transparent contrast-more:hover:hx-border-gray-900 contrast-more:dark:hover:hx-border-gray-50"
              >GoogLeNet</a>
            </li>
          <li>
              <a
                href="#resnet"
                class="hx-flex hx-rounded hx-px-2 hx-py-1.5 hx-text-sm hx-transition-colors [word-break:break-word] hx-cursor-pointer [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] contrast-more:hx-border hx-gap-2 before:hx-opacity-25 before:hx-content-['#'] hx-text-gray-500 hover:hx-bg-gray-100 hover:hx-text-gray-900 dark:hx-text-neutral-400 dark:hover:hx-bg-primary-100/5 dark:hover:hx-text-gray-50 contrast-more:hx-text-gray-900 contrast-more:dark:hx-text-gray-50 contrast-more:hx-border-transparent contrast-more:hover:hx-border-gray-900 contrast-more:dark:hover:hx-border-gray-50"
              >ResNet</a>
            </li>
          <li>
              <a
                href="#%e6%95%b0%e6%8d%ae%e5%a2%9e%e5%bc%ba"
                class="hx-flex hx-rounded hx-px-2 hx-py-1.5 hx-text-sm hx-transition-colors [word-break:break-word] hx-cursor-pointer [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] contrast-more:hx-border hx-gap-2 before:hx-opacity-25 before:hx-content-['#'] hx-text-gray-500 hover:hx-bg-gray-100 hover:hx-text-gray-900 dark:hx-text-neutral-400 dark:hover:hx-bg-primary-100/5 dark:hover:hx-text-gray-50 contrast-more:hx-text-gray-900 contrast-more:dark:hx-text-gray-50 contrast-more:hx-border-transparent contrast-more:hover:hx-border-gray-900 contrast-more:dark:hover:hx-border-gray-50"
              >数据增强</a>
            </li>
          <li>
              <a
                href="#%e5%be%ae%e8%b0%83"
                class="hx-flex hx-rounded hx-px-2 hx-py-1.5 hx-text-sm hx-transition-colors [word-break:break-word] hx-cursor-pointer [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] contrast-more:hx-border hx-gap-2 before:hx-opacity-25 before:hx-content-['#'] hx-text-gray-500 hover:hx-bg-gray-100 hover:hx-text-gray-900 dark:hx-text-neutral-400 dark:hover:hx-bg-primary-100/5 dark:hover:hx-text-gray-50 contrast-more:hx-text-gray-900 contrast-more:dark:hx-text-gray-50 contrast-more:hx-border-transparent contrast-more:hover:hx-border-gray-900 contrast-more:dark:hover:hx-border-gray-50"
              >微调</a>
            </li>
          <li>
              <a
                href="#%e7%9b%ae%e6%a0%87%e6%a3%80%e6%b5%8b"
                class="hx-flex hx-rounded hx-px-2 hx-py-1.5 hx-text-sm hx-transition-colors [word-break:break-word] hx-cursor-pointer [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] contrast-more:hx-border hx-gap-2 before:hx-opacity-25 before:hx-content-['#'] hx-text-gray-500 hover:hx-bg-gray-100 hover:hx-text-gray-900 dark:hx-text-neutral-400 dark:hover:hx-bg-primary-100/5 dark:hover:hx-text-gray-50 contrast-more:hx-text-gray-900 contrast-more:dark:hx-text-gray-50 contrast-more:hx-border-transparent contrast-more:hover:hx-border-gray-900 contrast-more:dark:hover:hx-border-gray-50"
              >目标检测</a>
            </li>
          <li>
              <a
                href="#%e7%89%a9%e4%bd%93%e6%a3%80%e6%b5%8b%e7%ae%97%e6%b3%95"
                class="hx-flex hx-rounded hx-px-2 hx-py-1.5 hx-text-sm hx-transition-colors [word-break:break-word] hx-cursor-pointer [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] contrast-more:hx-border hx-gap-2 before:hx-opacity-25 before:hx-content-['#'] hx-text-gray-500 hover:hx-bg-gray-100 hover:hx-text-gray-900 dark:hx-text-neutral-400 dark:hover:hx-bg-primary-100/5 dark:hover:hx-text-gray-50 contrast-more:hx-text-gray-900 contrast-more:dark:hx-text-gray-50 contrast-more:hx-border-transparent contrast-more:hover:hx-border-gray-900 contrast-more:dark:hover:hx-border-gray-50"
              >物体检测算法</a>
            </li>
          <li>
              <a
                href="#%e8%af%ad%e4%b9%89%e5%88%86%e5%89%b2"
                class="hx-flex hx-rounded hx-px-2 hx-py-1.5 hx-text-sm hx-transition-colors [word-break:break-word] hx-cursor-pointer [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] contrast-more:hx-border hx-gap-2 before:hx-opacity-25 before:hx-content-['#'] hx-text-gray-500 hover:hx-bg-gray-100 hover:hx-text-gray-900 dark:hx-text-neutral-400 dark:hover:hx-bg-primary-100/5 dark:hover:hx-text-gray-50 contrast-more:hx-text-gray-900 contrast-more:dark:hx-text-gray-50 contrast-more:hx-border-transparent contrast-more:hover:hx-border-gray-900 contrast-more:dark:hover:hx-border-gray-50"
              >语义分割</a>
            </li>
          <li>
              <a
                href="#%e8%bd%ac%e7%bd%ae%e5%8d%b7%e7%a7%af"
                class="hx-flex hx-rounded hx-px-2 hx-py-1.5 hx-text-sm hx-transition-colors [word-break:break-word] hx-cursor-pointer [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] contrast-more:hx-border hx-gap-2 before:hx-opacity-25 before:hx-content-['#'] hx-text-gray-500 hover:hx-bg-gray-100 hover:hx-text-gray-900 dark:hx-text-neutral-400 dark:hover:hx-bg-primary-100/5 dark:hover:hx-text-gray-50 contrast-more:hx-text-gray-900 contrast-more:dark:hx-text-gray-50 contrast-more:hx-border-transparent contrast-more:hover:hx-border-gray-900 contrast-more:dark:hover:hx-border-gray-50"
              >转置卷积</a>
            </li>
          <li>
              <a
                href="#%e5%85%a8%e8%bf%9e%e6%8e%a5%e5%8d%b7%e7%a7%af%e7%a5%9e%e7%bb%8f%e7%bd%91%e7%bb%9cfcn"
                class="hx-flex hx-rounded hx-px-2 hx-py-1.5 hx-text-sm hx-transition-colors [word-break:break-word] hx-cursor-pointer [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] contrast-more:hx-border hx-gap-2 before:hx-opacity-25 before:hx-content-['#'] hx-text-gray-500 hover:hx-bg-gray-100 hover:hx-text-gray-900 dark:hx-text-neutral-400 dark:hover:hx-bg-primary-100/5 dark:hover:hx-text-gray-50 contrast-more:hx-text-gray-900 contrast-more:dark:hx-text-gray-50 contrast-more:hx-border-transparent contrast-more:hover:hx-border-gray-900 contrast-more:dark:hover:hx-border-gray-50"
              >全连接卷积神经网络（FCN）</a>
            </li>
          <li>
              <a
                href="#%e6%a0%b7%e5%bc%8f%e8%bf%81%e7%a7%bb"
                class="hx-flex hx-rounded hx-px-2 hx-py-1.5 hx-text-sm hx-transition-colors [word-break:break-word] hx-cursor-pointer [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] contrast-more:hx-border hx-gap-2 before:hx-opacity-25 before:hx-content-['#'] hx-text-gray-500 hover:hx-bg-gray-100 hover:hx-text-gray-900 dark:hx-text-neutral-400 dark:hover:hx-bg-primary-100/5 dark:hover:hx-text-gray-50 contrast-more:hx-text-gray-900 contrast-more:dark:hx-text-gray-50 contrast-more:hx-border-transparent contrast-more:hover:hx-border-gray-900 contrast-more:dark:hover:hx-border-gray-50"
              >样式迁移</a>
            </li>
          <li>
              <a
                href="#%e5%ba%8f%e5%88%97%e6%a8%a1%e5%9e%8b"
                class="hx-flex hx-rounded hx-px-2 hx-py-1.5 hx-text-sm hx-transition-colors [word-break:break-word] hx-cursor-pointer [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] contrast-more:hx-border hx-gap-2 before:hx-opacity-25 before:hx-content-['#'] hx-text-gray-500 hover:hx-bg-gray-100 hover:hx-text-gray-900 dark:hx-text-neutral-400 dark:hover:hx-bg-primary-100/5 dark:hover:hx-text-gray-50 contrast-more:hx-text-gray-900 contrast-more:dark:hx-text-gray-50 contrast-more:hx-border-transparent contrast-more:hover:hx-border-gray-900 contrast-more:dark:hover:hx-border-gray-50"
              >序列模型</a>
            </li>
          <li>
              <a
                href="#%e6%96%87%e6%9c%ac%e9%a2%84%e5%a4%84%e7%90%86"
                class="hx-flex hx-rounded hx-px-2 hx-py-1.5 hx-text-sm hx-transition-colors [word-break:break-word] hx-cursor-pointer [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] contrast-more:hx-border hx-gap-2 before:hx-opacity-25 before:hx-content-['#'] hx-text-gray-500 hover:hx-bg-gray-100 hover:hx-text-gray-900 dark:hx-text-neutral-400 dark:hover:hx-bg-primary-100/5 dark:hover:hx-text-gray-50 contrast-more:hx-text-gray-900 contrast-more:dark:hx-text-gray-50 contrast-more:hx-border-transparent contrast-more:hover:hx-border-gray-900 contrast-more:dark:hover:hx-border-gray-50"
              >文本预处理</a>
            </li>
          <li>
              <a
                href="#%e8%af%ad%e8%a8%80%e6%a8%a1%e5%9e%8b"
                class="hx-flex hx-rounded hx-px-2 hx-py-1.5 hx-text-sm hx-transition-colors [word-break:break-word] hx-cursor-pointer [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] contrast-more:hx-border hx-gap-2 before:hx-opacity-25 before:hx-content-['#'] hx-text-gray-500 hover:hx-bg-gray-100 hover:hx-text-gray-900 dark:hx-text-neutral-400 dark:hover:hx-bg-primary-100/5 dark:hover:hx-text-gray-50 contrast-more:hx-text-gray-900 contrast-more:dark:hx-text-gray-50 contrast-more:hx-border-transparent contrast-more:hover:hx-border-gray-900 contrast-more:dark:hover:hx-border-gray-50"
              >语言模型</a>
            </li>
          <li>
              <a
                href="#rnn"
                class="hx-flex hx-rounded hx-px-2 hx-py-1.5 hx-text-sm hx-transition-colors [word-break:break-word] hx-cursor-pointer [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] contrast-more:hx-border hx-gap-2 before:hx-opacity-25 before:hx-content-['#'] hx-text-gray-500 hover:hx-bg-gray-100 hover:hx-text-gray-900 dark:hx-text-neutral-400 dark:hover:hx-bg-primary-100/5 dark:hover:hx-text-gray-50 contrast-more:hx-text-gray-900 contrast-more:dark:hx-text-gray-50 contrast-more:hx-border-transparent contrast-more:hover:hx-border-gray-900 contrast-more:dark:hover:hx-border-gray-50"
              >RNN</a>
            </li>
          <li>
              <a
                href="#%e9%97%a8%e6%8e%a7%e5%be%aa%e7%8e%af%e5%8d%95%e5%85%83gru"
                class="hx-flex hx-rounded hx-px-2 hx-py-1.5 hx-text-sm hx-transition-colors [word-break:break-word] hx-cursor-pointer [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] contrast-more:hx-border hx-gap-2 before:hx-opacity-25 before:hx-content-['#'] hx-text-gray-500 hover:hx-bg-gray-100 hover:hx-text-gray-900 dark:hx-text-neutral-400 dark:hover:hx-bg-primary-100/5 dark:hover:hx-text-gray-50 contrast-more:hx-text-gray-900 contrast-more:dark:hx-text-gray-50 contrast-more:hx-border-transparent contrast-more:hover:hx-border-gray-900 contrast-more:dark:hover:hx-border-gray-50"
              >门控循环单元（GRU）</a>
            </li>
          <li>
              <a
                href="#%e9%95%bf%e7%9f%ad%e6%9c%9f%e8%ae%b0%e5%bf%86%e7%bd%91%e7%bb%9clstm"
                class="hx-flex hx-rounded hx-px-2 hx-py-1.5 hx-text-sm hx-transition-colors [word-break:break-word] hx-cursor-pointer [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] contrast-more:hx-border hx-gap-2 before:hx-opacity-25 before:hx-content-['#'] hx-text-gray-500 hover:hx-bg-gray-100 hover:hx-text-gray-900 dark:hx-text-neutral-400 dark:hover:hx-bg-primary-100/5 dark:hover:hx-text-gray-50 contrast-more:hx-text-gray-900 contrast-more:dark:hx-text-gray-50 contrast-more:hx-border-transparent contrast-more:hover:hx-border-gray-900 contrast-more:dark:hover:hx-border-gray-50"
              >长短期记忆网络（LSTM）</a>
            </li>
          <li>
              <a
                href="#%e6%b7%b1%e5%b1%82%e5%be%aa%e7%8e%af%e7%a5%9e%e7%bb%8f%e7%bd%91%e7%bb%9c"
                class="hx-flex hx-rounded hx-px-2 hx-py-1.5 hx-text-sm hx-transition-colors [word-break:break-word] hx-cursor-pointer [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] contrast-more:hx-border hx-gap-2 before:hx-opacity-25 before:hx-content-['#'] hx-text-gray-500 hover:hx-bg-gray-100 hover:hx-text-gray-900 dark:hx-text-neutral-400 dark:hover:hx-bg-primary-100/5 dark:hover:hx-text-gray-50 contrast-more:hx-text-gray-900 contrast-more:dark:hx-text-gray-50 contrast-more:hx-border-transparent contrast-more:hover:hx-border-gray-900 contrast-more:dark:hover:hx-border-gray-50"
              >深层循环神经网络</a>
            </li>
          <li>
              <a
                href="#%e5%8f%8c%e5%90%91%e5%be%aa%e7%8e%af%e7%a5%9e%e7%bb%8f%e7%bd%91%e7%bb%9c"
                class="hx-flex hx-rounded hx-px-2 hx-py-1.5 hx-text-sm hx-transition-colors [word-break:break-word] hx-cursor-pointer [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] contrast-more:hx-border hx-gap-2 before:hx-opacity-25 before:hx-content-['#'] hx-text-gray-500 hover:hx-bg-gray-100 hover:hx-text-gray-900 dark:hx-text-neutral-400 dark:hover:hx-bg-primary-100/5 dark:hover:hx-text-gray-50 contrast-more:hx-text-gray-900 contrast-more:dark:hx-text-gray-50 contrast-more:hx-border-transparent contrast-more:hover:hx-border-gray-900 contrast-more:dark:hover:hx-border-gray-50"
              >双向循环神经网络</a>
            </li>
          <li>
              <a
                href="#%e6%9c%ba%e5%99%a8%e7%bf%bb%e8%af%91%e4%b8%8e%e6%95%b0%e6%8d%ae%e9%9b%86"
                class="hx-flex hx-rounded hx-px-2 hx-py-1.5 hx-text-sm hx-transition-colors [word-break:break-word] hx-cursor-pointer [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] contrast-more:hx-border hx-gap-2 before:hx-opacity-25 before:hx-content-['#'] hx-text-gray-500 hover:hx-bg-gray-100 hover:hx-text-gray-900 dark:hx-text-neutral-400 dark:hover:hx-bg-primary-100/5 dark:hover:hx-text-gray-50 contrast-more:hx-text-gray-900 contrast-more:dark:hx-text-gray-50 contrast-more:hx-border-transparent contrast-more:hover:hx-border-gray-900 contrast-more:dark:hover:hx-border-gray-50"
              >机器翻译与数据集</a>
            </li>
          <li>
              <a
                href="#%e5%ba%8f%e5%88%97%e5%88%b0%e5%ba%8f%e5%88%97%e5%ad%a6%e4%b9%a0seq2seq"
                class="hx-flex hx-rounded hx-px-2 hx-py-1.5 hx-text-sm hx-transition-colors [word-break:break-word] hx-cursor-pointer [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] contrast-more:hx-border hx-gap-2 before:hx-opacity-25 before:hx-content-['#'] hx-text-gray-500 hover:hx-bg-gray-100 hover:hx-text-gray-900 dark:hx-text-neutral-400 dark:hover:hx-bg-primary-100/5 dark:hover:hx-text-gray-50 contrast-more:hx-text-gray-900 contrast-more:dark:hx-text-gray-50 contrast-more:hx-border-transparent contrast-more:hover:hx-border-gray-900 contrast-more:dark:hover:hx-border-gray-50"
              >序列到序列学习（seq2seq）</a>
            </li>
          <li>
              <a
                href="#%e6%9d%9f%e6%90%9c%e7%b4%a2"
                class="hx-flex hx-rounded hx-px-2 hx-py-1.5 hx-text-sm hx-transition-colors [word-break:break-word] hx-cursor-pointer [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] contrast-more:hx-border hx-gap-2 before:hx-opacity-25 before:hx-content-['#'] hx-text-gray-500 hover:hx-bg-gray-100 hover:hx-text-gray-900 dark:hx-text-neutral-400 dark:hover:hx-bg-primary-100/5 dark:hover:hx-text-gray-50 contrast-more:hx-text-gray-900 contrast-more:dark:hx-text-gray-50 contrast-more:hx-border-transparent contrast-more:hover:hx-border-gray-900 contrast-more:dark:hover:hx-border-gray-50"
              >束搜索</a>
            </li>
          <li>
              <a
                href="#%e6%b3%a8%e6%84%8f%e5%8a%9b%e5%88%86%e6%95%b0"
                class="hx-flex hx-rounded hx-px-2 hx-py-1.5 hx-text-sm hx-transition-colors [word-break:break-word] hx-cursor-pointer [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] contrast-more:hx-border hx-gap-2 before:hx-opacity-25 before:hx-content-['#'] hx-text-gray-500 hover:hx-bg-gray-100 hover:hx-text-gray-900 dark:hx-text-neutral-400 dark:hover:hx-bg-primary-100/5 dark:hover:hx-text-gray-50 contrast-more:hx-text-gray-900 contrast-more:dark:hx-text-gray-50 contrast-more:hx-border-transparent contrast-more:hover:hx-border-gray-900 contrast-more:dark:hover:hx-border-gray-50"
              >注意力分数</a>
            </li>
          <li>
              <a
                href="#%e8%87%aa%e6%b3%a8%e6%84%8f%e5%8a%9b"
                class="hx-flex hx-rounded hx-px-2 hx-py-1.5 hx-text-sm hx-transition-colors [word-break:break-word] hx-cursor-pointer [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] contrast-more:hx-border hx-gap-2 before:hx-opacity-25 before:hx-content-['#'] hx-text-gray-500 hover:hx-bg-gray-100 hover:hx-text-gray-900 dark:hx-text-neutral-400 dark:hover:hx-bg-primary-100/5 dark:hover:hx-text-gray-50 contrast-more:hx-text-gray-900 contrast-more:dark:hx-text-gray-50 contrast-more:hx-border-transparent contrast-more:hover:hx-border-gray-900 contrast-more:dark:hover:hx-border-gray-50"
              >自注意力</a>
            </li>
          <li>
              <a
                href="#transformer"
                class="hx-flex hx-rounded hx-px-2 hx-py-1.5 hx-text-sm hx-transition-colors [word-break:break-word] hx-cursor-pointer [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] contrast-more:hx-border hx-gap-2 before:hx-opacity-25 before:hx-content-['#'] hx-text-gray-500 hover:hx-bg-gray-100 hover:hx-text-gray-900 dark:hx-text-neutral-400 dark:hover:hx-bg-primary-100/5 dark:hover:hx-text-gray-50 contrast-more:hx-text-gray-900 contrast-more:dark:hx-text-gray-50 contrast-more:hx-border-transparent contrast-more:hover:hx-border-gray-900 contrast-more:dark:hover:hx-border-gray-50"
              >Transformer</a>
            </li>
          <li>
              <a
                href="#bert"
                class="hx-flex hx-rounded hx-px-2 hx-py-1.5 hx-text-sm hx-transition-colors [word-break:break-word] hx-cursor-pointer [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] contrast-more:hx-border hx-gap-2 before:hx-opacity-25 before:hx-content-['#'] hx-text-gray-500 hover:hx-bg-gray-100 hover:hx-text-gray-900 dark:hx-text-neutral-400 dark:hover:hx-bg-primary-100/5 dark:hover:hx-text-gray-50 contrast-more:hx-text-gray-900 contrast-more:dark:hx-text-gray-50 contrast-more:hx-border-transparent contrast-more:hover:hx-border-gray-900 contrast-more:dark:hover:hx-border-gray-50"
              >BERT</a>
            </li>
          <li>
              <a
                href="#%e6%a2%af%e5%ba%a6%e4%b8%8b%e9%99%8d"
                class="hx-flex hx-rounded hx-px-2 hx-py-1.5 hx-text-sm hx-transition-colors [word-break:break-word] hx-cursor-pointer [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] contrast-more:hx-border hx-gap-2 before:hx-opacity-25 before:hx-content-['#'] hx-text-gray-500 hover:hx-bg-gray-100 hover:hx-text-gray-900 dark:hx-text-neutral-400 dark:hover:hx-bg-primary-100/5 dark:hover:hx-text-gray-50 contrast-more:hx-text-gray-900 contrast-more:dark:hx-text-gray-50 contrast-more:hx-border-transparent contrast-more:hover:hx-border-gray-900 contrast-more:dark:hover:hx-border-gray-50"
              >梯度下降</a>
            </li>
          <li>
              <a
                href="#%e5%86%b2%e9%87%8f%e6%b3%95%e5%8a%a8%e9%87%8f"
                class="hx-flex hx-rounded hx-px-2 hx-py-1.5 hx-text-sm hx-transition-colors [word-break:break-word] hx-cursor-pointer [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] contrast-more:hx-border hx-gap-2 before:hx-opacity-25 before:hx-content-['#'] hx-text-gray-500 hover:hx-bg-gray-100 hover:hx-text-gray-900 dark:hx-text-neutral-400 dark:hover:hx-bg-primary-100/5 dark:hover:hx-text-gray-50 contrast-more:hx-text-gray-900 contrast-more:dark:hx-text-gray-50 contrast-more:hx-border-transparent contrast-more:hover:hx-border-gray-900 contrast-more:dark:hover:hx-border-gray-50"
              >冲量法（动量）</a>
            </li>
          <li>
              <a
                href="#adam"
                class="hx-flex hx-rounded hx-px-2 hx-py-1.5 hx-text-sm hx-transition-colors [word-break:break-word] hx-cursor-pointer [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] contrast-more:hx-border hx-gap-2 before:hx-opacity-25 before:hx-content-['#'] hx-text-gray-500 hover:hx-bg-gray-100 hover:hx-text-gray-900 dark:hx-text-neutral-400 dark:hover:hx-bg-primary-100/5 dark:hover:hx-text-gray-50 contrast-more:hx-text-gray-900 contrast-more:dark:hx-text-gray-50 contrast-more:hx-border-transparent contrast-more:hover:hx-border-gray-900 contrast-more:dark:hover:hx-border-gray-50"
              >Adam</a>
            </li>
          <li>
              <a
                href="#machine-learning"
                class="hx-flex hx-rounded hx-px-2 hx-py-1.5 hx-text-sm hx-transition-colors [word-break:break-word] hx-cursor-pointer [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] contrast-more:hx-border hx-gap-2 before:hx-opacity-25 before:hx-content-['#'] hx-text-gray-500 hover:hx-bg-gray-100 hover:hx-text-gray-900 dark:hx-text-neutral-400 dark:hover:hx-bg-primary-100/5 dark:hover:hx-text-gray-50 contrast-more:hx-text-gray-900 contrast-more:dark:hx-text-gray-50 contrast-more:hx-border-transparent contrast-more:hover:hx-border-gray-900 contrast-more:dark:hover:hx-border-gray-50"
              >Machine Learning</a>
            </li>
          <li>
              <a
                href="#%e4%b8%89%e4%b8%aa%e6%9c%ba%e5%99%a8%e5%ad%a6%e4%b9%a0%e4%bb%bb%e5%8a%a1"
                class="hx-flex hx-rounded hx-px-2 hx-py-1.5 hx-text-sm hx-transition-colors [word-break:break-word] hx-cursor-pointer [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] contrast-more:hx-border hx-gap-2 before:hx-opacity-25 before:hx-content-['#'] hx-text-gray-500 hover:hx-bg-gray-100 hover:hx-text-gray-900 dark:hx-text-neutral-400 dark:hover:hx-bg-primary-100/5 dark:hover:hx-text-gray-50 contrast-more:hx-text-gray-900 contrast-more:dark:hx-text-gray-50 contrast-more:hx-border-transparent contrast-more:hover:hx-border-gray-900 contrast-more:dark:hover:hx-border-gray-50"
              >三个机器学习任务</a>
            </li>
          <li>
              <a
                href="#%e6%89%be%e5%87%bd%e5%bc%8f%e7%9a%84%e8%bf%87%e7%a8%8b%e4%b8%89%e4%b8%aa%e6%ad%a5%e9%aa%a4"
                class="hx-flex hx-rounded hx-px-2 hx-py-1.5 hx-text-sm hx-transition-colors [word-break:break-word] hx-cursor-pointer [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] contrast-more:hx-border hx-gap-2 before:hx-opacity-25 before:hx-content-['#'] hx-text-gray-500 hover:hx-bg-gray-100 hover:hx-text-gray-900 dark:hx-text-neutral-400 dark:hover:hx-bg-primary-100/5 dark:hover:hx-text-gray-50 contrast-more:hx-text-gray-900 contrast-more:dark:hx-text-gray-50 contrast-more:hx-border-transparent contrast-more:hover:hx-border-gray-900 contrast-more:dark:hover:hx-border-gray-50"
              >找函式的过程：三个步骤</a>
            </li>
          <li>
              <a
                href="#liner-model%e7%ba%bf%e6%80%a7%e6%a8%a1%e5%9e%8b"
                class="hx-flex hx-rounded hx-px-2 hx-py-1.5 hx-text-sm hx-transition-colors [word-break:break-word] hx-cursor-pointer [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] contrast-more:hx-border hx-gap-2 before:hx-opacity-25 before:hx-content-['#'] hx-text-gray-500 hover:hx-bg-gray-100 hover:hx-text-gray-900 dark:hx-text-neutral-400 dark:hover:hx-bg-primary-100/5 dark:hover:hx-text-gray-50 contrast-more:hx-text-gray-900 contrast-more:dark:hx-text-gray-50 contrast-more:hx-border-transparent contrast-more:hover:hx-border-gray-900 contrast-more:dark:hover:hx-border-gray-50"
              >Liner Model（线性模型）</a>
            </li>
          <li>
              <a
                href="#%e5%a6%82%e4%bd%95%e4%bd%bf%e6%a8%a1%e5%9e%8b%e8%be%be%e5%88%b0%e6%9b%b4%e5%a5%bd%e7%9a%84%e6%95%88%e6%9e%9c"
                class="hx-flex hx-rounded hx-px-2 hx-py-1.5 hx-text-sm hx-transition-colors [word-break:break-word] hx-cursor-pointer [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] contrast-more:hx-border hx-gap-2 before:hx-opacity-25 before:hx-content-['#'] hx-text-gray-500 hover:hx-bg-gray-100 hover:hx-text-gray-900 dark:hx-text-neutral-400 dark:hover:hx-bg-primary-100/5 dark:hover:hx-text-gray-50 contrast-more:hx-text-gray-900 contrast-more:dark:hx-text-gray-50 contrast-more:hx-border-transparent contrast-more:hover:hx-border-gray-900 contrast-more:dark:hover:hx-border-gray-50"
              >如何使模型达到更好的效果？</a>
            </li>
          <li>
              <a
                href="#%e6%9d%83%e9%87%8d%e8%a1%b0%e9%80%80"
                class="hx-flex hx-rounded hx-px-2 hx-py-1.5 hx-text-sm hx-transition-colors [word-break:break-word] hx-cursor-pointer [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] contrast-more:hx-border hx-gap-2 before:hx-opacity-25 before:hx-content-['#'] hx-text-gray-500 hover:hx-bg-gray-100 hover:hx-text-gray-900 dark:hx-text-neutral-400 dark:hover:hx-bg-primary-100/5 dark:hover:hx-text-gray-50 contrast-more:hx-text-gray-900 contrast-more:dark:hx-text-gray-50 contrast-more:hx-border-transparent contrast-more:hover:hx-border-gray-900 contrast-more:dark:hover:hx-border-gray-50"
              >权重衰退</a>
            </li>
          <li>
              <a
                href="#%e4%b8%a2%e5%bc%83%e6%b3%95"
                class="hx-flex hx-rounded hx-px-2 hx-py-1.5 hx-text-sm hx-transition-colors [word-break:break-word] hx-cursor-pointer [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] contrast-more:hx-border hx-gap-2 before:hx-opacity-25 before:hx-content-['#'] hx-text-gray-500 hover:hx-bg-gray-100 hover:hx-text-gray-900 dark:hx-text-neutral-400 dark:hover:hx-bg-primary-100/5 dark:hover:hx-text-gray-50 contrast-more:hx-text-gray-900 contrast-more:dark:hx-text-gray-50 contrast-more:hx-border-transparent contrast-more:hover:hx-border-gray-900 contrast-more:dark:hover:hx-border-gray-50"
              >丢弃法</a>
            </li>
          <li>
              <a
                href="#%e6%89%b9%e9%87%8f%e5%bd%92%e4%b8%80%e5%8c%96"
                class="hx-flex hx-rounded hx-px-2 hx-py-1.5 hx-text-sm hx-transition-colors [word-break:break-word] hx-cursor-pointer [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] contrast-more:hx-border hx-gap-2 before:hx-opacity-25 before:hx-content-['#'] hx-text-gray-500 hover:hx-bg-gray-100 hover:hx-text-gray-900 dark:hx-text-neutral-400 dark:hover:hx-bg-primary-100/5 dark:hover:hx-text-gray-50 contrast-more:hx-text-gray-900 contrast-more:dark:hx-text-gray-50 contrast-more:hx-border-transparent contrast-more:hover:hx-border-gray-900 contrast-more:dark:hover:hx-border-gray-50"
              >批量归一化</a>
            </li>
          <li>
              <a
                href="#critical-point-%e6%a6%82%e8%bf%b0"
                class="hx-flex hx-rounded hx-px-2 hx-py-1.5 hx-text-sm hx-transition-colors [word-break:break-word] hx-cursor-pointer [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] contrast-more:hx-border hx-gap-2 before:hx-opacity-25 before:hx-content-['#'] hx-text-gray-500 hover:hx-bg-gray-100 hover:hx-text-gray-900 dark:hx-text-neutral-400 dark:hover:hx-bg-primary-100/5 dark:hover:hx-text-gray-50 contrast-more:hx-text-gray-900 contrast-more:dark:hx-text-gray-50 contrast-more:hx-border-transparent contrast-more:hover:hx-border-gray-900 contrast-more:dark:hover:hx-border-gray-50"
              >critical point 概述</a>
            </li>
          <li>
              <a
                href="#classification-as-regression"
                class="hx-flex hx-rounded hx-px-2 hx-py-1.5 hx-text-sm hx-transition-colors [word-break:break-word] hx-cursor-pointer [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] contrast-more:hx-border hx-gap-2 before:hx-opacity-25 before:hx-content-['#'] hx-text-gray-500 hover:hx-bg-gray-100 hover:hx-text-gray-900 dark:hx-text-neutral-400 dark:hover:hx-bg-primary-100/5 dark:hover:hx-text-gray-50 contrast-more:hx-text-gray-900 contrast-more:dark:hx-text-gray-50 contrast-more:hx-border-transparent contrast-more:hover:hx-border-gray-900 contrast-more:dark:hover:hx-border-gray-50"
              >Classification as Regression</a>
            </li>
          <li>
              <a
                href="#%e4%bc%98%e5%8c%96%e7%9b%ae%e6%a0%87%e5%87%8f%e5%b0%8fy%e5%92%8cy%e4%b9%8b%e9%97%b4%e7%9a%84%e5%b7%ae%e8%b7%9de"
                class="hx-flex hx-rounded hx-px-2 hx-py-1.5 hx-text-sm hx-transition-colors [word-break:break-word] hx-cursor-pointer [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] contrast-more:hx-border hx-gap-2 before:hx-opacity-25 before:hx-content-['#'] hx-text-gray-500 hover:hx-bg-gray-100 hover:hx-text-gray-900 dark:hx-text-neutral-400 dark:hover:hx-bg-primary-100/5 dark:hover:hx-text-gray-50 contrast-more:hx-text-gray-900 contrast-more:dark:hx-text-gray-50 contrast-more:hx-border-transparent contrast-more:hover:hx-border-gray-900 contrast-more:dark:hover:hx-border-gray-50"
              >优化目标：减小y^和y&amp;rsquo;之间的差距e</a>
            </li>
          <li>
              <a
                href="#%e5%9c%ba%e6%99%af-%e5%9b%be%e7%89%87%e5%88%86%e7%b1%bb"
                class="hx-flex hx-rounded hx-px-2 hx-py-1.5 hx-text-sm hx-transition-colors [word-break:break-word] hx-cursor-pointer [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] contrast-more:hx-border hx-gap-2 before:hx-opacity-25 before:hx-content-['#'] hx-text-gray-500 hover:hx-bg-gray-100 hover:hx-text-gray-900 dark:hx-text-neutral-400 dark:hover:hx-bg-primary-100/5 dark:hover:hx-text-gray-50 contrast-more:hx-text-gray-900 contrast-more:dark:hx-text-gray-50 contrast-more:hx-border-transparent contrast-more:hover:hx-border-gray-900 contrast-more:dark:hover:hx-border-gray-50"
              >场景： 图片分类</a>
            </li>
          <li>
              <a
                href="#%e7%a5%9e%e7%bb%8f%e5%85%83%e8%a7%92%e5%ba%a6"
                class="hx-flex hx-rounded hx-px-2 hx-py-1.5 hx-text-sm hx-transition-colors [word-break:break-word] hx-cursor-pointer [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] contrast-more:hx-border hx-gap-2 before:hx-opacity-25 before:hx-content-['#'] hx-text-gray-500 hover:hx-bg-gray-100 hover:hx-text-gray-900 dark:hx-text-neutral-400 dark:hover:hx-bg-primary-100/5 dark:hover:hx-text-gray-50 contrast-more:hx-text-gray-900 contrast-more:dark:hx-text-gray-50 contrast-more:hx-border-transparent contrast-more:hover:hx-border-gray-900 contrast-more:dark:hover:hx-border-gray-50"
              >神经元角度</a>
            </li>
          <li>
              <a
                href="#%e6%bb%a4%e6%b3%a2%e5%99%a8%e8%a7%92%e5%ba%a6"
                class="hx-flex hx-rounded hx-px-2 hx-py-1.5 hx-text-sm hx-transition-colors [word-break:break-word] hx-cursor-pointer [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] contrast-more:hx-border hx-gap-2 before:hx-opacity-25 before:hx-content-['#'] hx-text-gray-500 hover:hx-bg-gray-100 hover:hx-text-gray-900 dark:hx-text-neutral-400 dark:hover:hx-bg-primary-100/5 dark:hover:hx-text-gray-50 contrast-more:hx-text-gray-900 contrast-more:dark:hx-text-gray-50 contrast-more:hx-border-transparent contrast-more:hover:hx-border-gray-900 contrast-more:dark:hover:hx-border-gray-50"
              >滤波器角度</a>
            </li>
          <li>
              <a
                href="#%e6%80%bb%e7%bb%93-1"
                class="hx-flex hx-rounded hx-px-2 hx-py-1.5 hx-text-sm hx-transition-colors [word-break:break-word] hx-cursor-pointer [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] contrast-more:hx-border hx-gap-2 before:hx-opacity-25 before:hx-content-['#'] hx-text-gray-500 hover:hx-bg-gray-100 hover:hx-text-gray-900 dark:hx-text-neutral-400 dark:hover:hx-bg-primary-100/5 dark:hover:hx-text-gray-50 contrast-more:hx-text-gray-900 contrast-more:dark:hx-text-gray-50 contrast-more:hx-border-transparent contrast-more:hover:hx-border-gray-900 contrast-more:dark:hover:hx-border-gray-50"
              >总结</a>
            </li>
          <li>
              <a
                href="#%e6%b1%a0%e5%8c%96%e5%b1%82-pooling"
                class="hx-flex hx-rounded hx-px-2 hx-py-1.5 hx-text-sm hx-transition-colors [word-break:break-word] hx-cursor-pointer [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] contrast-more:hx-border hx-gap-2 before:hx-opacity-25 before:hx-content-['#'] hx-text-gray-500 hover:hx-bg-gray-100 hover:hx-text-gray-900 dark:hx-text-neutral-400 dark:hover:hx-bg-primary-100/5 dark:hover:hx-text-gray-50 contrast-more:hx-text-gray-900 contrast-more:dark:hx-text-gray-50 contrast-more:hx-border-transparent contrast-more:hover:hx-border-gray-900 contrast-more:dark:hover:hx-border-gray-50"
              >池化层 Pooling</a>
            </li>
          <li>
              <a
                href="#the-whole-cnn%e5%85%b8%e5%9e%8b%e5%88%86%e7%b1%bb%e7%bd%91%e7%bb%9c%e7%bb%93%e6%9e%84"
                class="hx-flex hx-rounded hx-px-2 hx-py-1.5 hx-text-sm hx-transition-colors [word-break:break-word] hx-cursor-pointer [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] contrast-more:hx-border hx-gap-2 before:hx-opacity-25 before:hx-content-['#'] hx-text-gray-500 hover:hx-bg-gray-100 hover:hx-text-gray-900 dark:hx-text-neutral-400 dark:hover:hx-bg-primary-100/5 dark:hover:hx-text-gray-50 contrast-more:hx-text-gray-900 contrast-more:dark:hx-text-gray-50 contrast-more:hx-border-transparent contrast-more:hover:hx-border-gray-900 contrast-more:dark:hover:hx-border-gray-50"
              >The whole CNN（典型分类网络结构）</a>
            </li>
          <li>
              <a
                href="#attention"
                class="hx-flex hx-rounded hx-px-2 hx-py-1.5 hx-text-sm hx-transition-colors [word-break:break-word] hx-cursor-pointer [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] contrast-more:hx-border hx-gap-2 before:hx-opacity-25 before:hx-content-['#'] hx-text-gray-500 hover:hx-bg-gray-100 hover:hx-text-gray-900 dark:hx-text-neutral-400 dark:hover:hx-bg-primary-100/5 dark:hover:hx-text-gray-50 contrast-more:hx-text-gray-900 contrast-more:dark:hx-text-gray-50 contrast-more:hx-border-transparent contrast-more:hover:hx-border-gray-900 contrast-more:dark:hover:hx-border-gray-50"
              >attention</a>
            </li>
          <li>
              <a
                href="#self-attention-vs-cnn"
                class="hx-flex hx-rounded hx-px-2 hx-py-1.5 hx-text-sm hx-transition-colors [word-break:break-word] hx-cursor-pointer [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] contrast-more:hx-border hx-gap-2 before:hx-opacity-25 before:hx-content-['#'] hx-text-gray-500 hover:hx-bg-gray-100 hover:hx-text-gray-900 dark:hx-text-neutral-400 dark:hover:hx-bg-primary-100/5 dark:hover:hx-text-gray-50 contrast-more:hx-text-gray-900 contrast-more:dark:hx-text-gray-50 contrast-more:hx-border-transparent contrast-more:hover:hx-border-gray-900 contrast-more:dark:hover:hx-border-gray-50"
              >Self-attention v.s. CNN</a>
            </li>
          <li>
              <a
                href="#self-attention-vs-rnn%e5%be%aa%e7%8e%af%e7%a5%9e%e7%bb%8f%e7%bd%91%e7%bb%9c"
                class="hx-flex hx-rounded hx-px-2 hx-py-1.5 hx-text-sm hx-transition-colors [word-break:break-word] hx-cursor-pointer [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] contrast-more:hx-border hx-gap-2 before:hx-opacity-25 before:hx-content-['#'] hx-text-gray-500 hover:hx-bg-gray-100 hover:hx-text-gray-900 dark:hx-text-neutral-400 dark:hover:hx-bg-primary-100/5 dark:hover:hx-text-gray-50 contrast-more:hx-text-gray-900 contrast-more:dark:hx-text-gray-50 contrast-more:hx-border-transparent contrast-more:hover:hx-border-gray-900 contrast-more:dark:hover:hx-border-gray-50"
              >Self-attention v.s. RNN（循环神经网络）</a>
            </li>
          <li>
              <a
                href="#%e5%ba%94%e7%94%a8"
                class="hx-flex hx-rounded hx-px-2 hx-py-1.5 hx-text-sm hx-transition-colors [word-break:break-word] hx-cursor-pointer [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] contrast-more:hx-border hx-gap-2 before:hx-opacity-25 before:hx-content-['#'] hx-text-gray-500 hover:hx-bg-gray-100 hover:hx-text-gray-900 dark:hx-text-neutral-400 dark:hover:hx-bg-primary-100/5 dark:hover:hx-text-gray-50 contrast-more:hx-text-gray-900 contrast-more:dark:hx-text-gray-50 contrast-more:hx-border-transparent contrast-more:hover:hx-border-gray-900 contrast-more:dark:hover:hx-border-gray-50"
              >应用</a>
            </li>
          <li>
              <a
                href="#%e8%a7%a3%e5%86%b3%e7%9a%84%e9%97%ae%e9%a2%98"
                class="hx-flex hx-rounded hx-px-2 hx-py-1.5 hx-text-sm hx-transition-colors [word-break:break-word] hx-cursor-pointer [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] contrast-more:hx-border hx-gap-2 before:hx-opacity-25 before:hx-content-['#'] hx-text-gray-500 hover:hx-bg-gray-100 hover:hx-text-gray-900 dark:hx-text-neutral-400 dark:hover:hx-bg-primary-100/5 dark:hover:hx-text-gray-50 contrast-more:hx-text-gray-900 contrast-more:dark:hx-text-gray-50 contrast-more:hx-border-transparent contrast-more:hover:hx-border-gray-900 contrast-more:dark:hover:hx-border-gray-50"
              >解决的问题</a>
            </li>
          <li>
              <a
                href="#%e6%9c%ac%e8%b4%a8"
                class="hx-flex hx-rounded hx-px-2 hx-py-1.5 hx-text-sm hx-transition-colors [word-break:break-word] hx-cursor-pointer [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] contrast-more:hx-border hx-gap-2 before:hx-opacity-25 before:hx-content-['#'] hx-text-gray-500 hover:hx-bg-gray-100 hover:hx-text-gray-900 dark:hx-text-neutral-400 dark:hover:hx-bg-primary-100/5 dark:hover:hx-text-gray-50 contrast-more:hx-text-gray-900 contrast-more:dark:hx-text-gray-50 contrast-more:hx-border-transparent contrast-more:hover:hx-border-gray-900 contrast-more:dark:hover:hx-border-gray-50"
              >本质</a>
            </li>
          <li>
              <a
                href="#%e4%bc%98%e7%bc%ba%e7%82%b9"
                class="hx-flex hx-rounded hx-px-2 hx-py-1.5 hx-text-sm hx-transition-colors [word-break:break-word] hx-cursor-pointer [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] contrast-more:hx-border hx-gap-2 before:hx-opacity-25 before:hx-content-['#'] hx-text-gray-500 hover:hx-bg-gray-100 hover:hx-text-gray-900 dark:hx-text-neutral-400 dark:hover:hx-bg-primary-100/5 dark:hover:hx-text-gray-50 contrast-more:hx-text-gray-900 contrast-more:dark:hx-text-gray-50 contrast-more:hx-border-transparent contrast-more:hover:hx-border-gray-900 contrast-more:dark:hover:hx-border-gray-50"
              >优缺点</a>
            </li>
          <li>
              <a
                href="#seq2seq%e5%ba%8f%e5%88%97%e5%88%b0%e5%ba%8f%e5%88%97"
                class="hx-flex hx-rounded hx-px-2 hx-py-1.5 hx-text-sm hx-transition-colors [word-break:break-word] hx-cursor-pointer [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] contrast-more:hx-border hx-gap-2 before:hx-opacity-25 before:hx-content-['#'] hx-text-gray-500 hover:hx-bg-gray-100 hover:hx-text-gray-900 dark:hx-text-neutral-400 dark:hover:hx-bg-primary-100/5 dark:hover:hx-text-gray-50 contrast-more:hx-text-gray-900 contrast-more:dark:hx-text-gray-50 contrast-more:hx-border-transparent contrast-more:hover:hx-border-gray-900 contrast-more:dark:hover:hx-border-gray-50"
              >Seq2Seq（&lt;em&gt;序列到序列&lt;/em&gt;）</a>
            </li>
          <li>
              <a
                href="#%e5%ba%94%e7%94%a8-1"
                class="hx-flex hx-rounded hx-px-2 hx-py-1.5 hx-text-sm hx-transition-colors [word-break:break-word] hx-cursor-pointer [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] contrast-more:hx-border hx-gap-2 before:hx-opacity-25 before:hx-content-['#'] hx-text-gray-500 hover:hx-bg-gray-100 hover:hx-text-gray-900 dark:hx-text-neutral-400 dark:hover:hx-bg-primary-100/5 dark:hover:hx-text-gray-50 contrast-more:hx-text-gray-900 contrast-more:dark:hx-text-gray-50 contrast-more:hx-border-transparent contrast-more:hover:hx-border-gray-900 contrast-more:dark:hover:hx-border-gray-50"
              >应用</a>
            </li>
          <li>
              <a
                href="#%e7%bb%93%e6%9e%84"
                class="hx-flex hx-rounded hx-px-2 hx-py-1.5 hx-text-sm hx-transition-colors [word-break:break-word] hx-cursor-pointer [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] contrast-more:hx-border hx-gap-2 before:hx-opacity-25 before:hx-content-['#'] hx-text-gray-500 hover:hx-bg-gray-100 hover:hx-text-gray-900 dark:hx-text-neutral-400 dark:hover:hx-bg-primary-100/5 dark:hover:hx-text-gray-50 contrast-more:hx-text-gray-900 contrast-more:dark:hx-text-gray-50 contrast-more:hx-border-transparent contrast-more:hover:hx-border-gray-900 contrast-more:dark:hover:hx-border-gray-50"
              >结构</a>
            </li>
          <li>
              <a
                href="#%e8%ae%ad%e7%bb%83"
                class="hx-flex hx-rounded hx-px-2 hx-py-1.5 hx-text-sm hx-transition-colors [word-break:break-word] hx-cursor-pointer [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] contrast-more:hx-border hx-gap-2 before:hx-opacity-25 before:hx-content-['#'] hx-text-gray-500 hover:hx-bg-gray-100 hover:hx-text-gray-900 dark:hx-text-neutral-400 dark:hover:hx-bg-primary-100/5 dark:hover:hx-text-gray-50 contrast-more:hx-text-gray-900 contrast-more:dark:hx-text-gray-50 contrast-more:hx-border-transparent contrast-more:hover:hx-border-gray-900 contrast-more:dark:hover:hx-border-gray-50"
              >训练</a>
            </li>
          <li>
              <a
                href="#%e7%94%9f%e6%88%90%e5%99%a8%e8%af%84%e4%bc%b0"
                class="hx-flex hx-rounded hx-px-2 hx-py-1.5 hx-text-sm hx-transition-colors [word-break:break-word] hx-cursor-pointer [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] contrast-more:hx-border hx-gap-2 before:hx-opacity-25 before:hx-content-['#'] hx-text-gray-500 hover:hx-bg-gray-100 hover:hx-text-gray-900 dark:hx-text-neutral-400 dark:hover:hx-bg-primary-100/5 dark:hover:hx-text-gray-50 contrast-more:hx-text-gray-900 contrast-more:dark:hx-text-gray-50 contrast-more:hx-border-transparent contrast-more:hover:hx-border-gray-900 contrast-more:dark:hover:hx-border-gray-50"
              >生成器评估</a>
            </li>
          <li>
              <a
                href="#%e4%b8%be%e4%be%8b"
                class="hx-flex hx-rounded hx-px-2 hx-py-1.5 hx-text-sm hx-transition-colors [word-break:break-word] hx-cursor-pointer [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] contrast-more:hx-border hx-gap-2 before:hx-opacity-25 before:hx-content-['#'] hx-text-gray-500 hover:hx-bg-gray-100 hover:hx-text-gray-900 dark:hx-text-neutral-400 dark:hover:hx-bg-primary-100/5 dark:hover:hx-text-gray-50 contrast-more:hx-text-gray-900 contrast-more:dark:hx-text-gray-50 contrast-more:hx-border-transparent contrast-more:hover:hx-border-gray-900 contrast-more:dark:hover:hx-border-gray-50"
              >举例</a>
            </li>
          <li>
              <a
                href="#masking-input"
                class="hx-flex hx-rounded hx-px-2 hx-py-1.5 hx-text-sm hx-transition-colors [word-break:break-word] hx-cursor-pointer [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] contrast-more:hx-border hx-gap-2 before:hx-opacity-25 before:hx-content-['#'] hx-text-gray-500 hover:hx-bg-gray-100 hover:hx-text-gray-900 dark:hx-text-neutral-400 dark:hover:hx-bg-primary-100/5 dark:hover:hx-text-gray-50 contrast-more:hx-text-gray-900 contrast-more:dark:hx-text-gray-50 contrast-more:hx-border-transparent contrast-more:hover:hx-border-gray-900 contrast-more:dark:hover:hx-border-gray-50"
              >Masking Input</a>
            </li>
          <li>
              <a
                href="#%e8%af%84%e4%bb%b7%e4%bb%bb%e5%8a%a1%e9%9b%86glue"
                class="hx-flex hx-rounded hx-px-2 hx-py-1.5 hx-text-sm hx-transition-colors [word-break:break-word] hx-cursor-pointer [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] contrast-more:hx-border hx-gap-2 before:hx-opacity-25 before:hx-content-['#'] hx-text-gray-500 hover:hx-bg-gray-100 hover:hx-text-gray-900 dark:hx-text-neutral-400 dark:hover:hx-bg-primary-100/5 dark:hover:hx-text-gray-50 contrast-more:hx-text-gray-900 contrast-more:dark:hx-text-gray-50 contrast-more:hx-border-transparent contrast-more:hover:hx-border-gray-900 contrast-more:dark:hover:hx-border-gray-50"
              >评价任务集——GLUE</a>
            </li>
          </ul>
  
              
            </li></ul>
      </div></li>
          <li class=""><a
    class="hx-flex hx-items-center hx-justify-between hx-gap-2 hx-cursor-pointer hx-rounded hx-px-2 hx-py-1.5 hx-text-sm hx-transition-colors [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] [word-break:break-word]
      hx-text-gray-500 hover:hx-bg-gray-100 hover:hx-text-gray-900 contrast-more:hx-border contrast-more:hx-border-transparent contrast-more:hx-text-gray-900 contrast-more:hover:hx-border-gray-900 dark:hx-text-neutral-400 dark:hover:hx-bg-primary-100/5 dark:hover:hx-text-gray-50 contrast-more:dark:hx-text-gray-50 contrast-more:dark:hover:hx-border-gray-50"
    href="/project/"
    
  >Project
    </a></li>
      <li class="[word-break:break-word] hx-mt-5 hx-mb-2 hx-px-2 hx-py-1.5 hx-text-sm hx-font-semibold hx-text-gray-900 first:hx-mt-0 dark:hx-text-gray-100">
        <span class="hx-cursor-default">More</span>
      </li>
    
      <li><a
    class="hx-flex hx-items-center hx-justify-between hx-gap-2 hx-cursor-pointer hx-rounded hx-px-2 hx-py-1.5 hx-text-sm hx-transition-colors [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] [word-break:break-word]
      hx-text-gray-500 hover:hx-bg-gray-100 hover:hx-text-gray-900 contrast-more:hx-border contrast-more:hx-border-transparent contrast-more:hx-text-gray-900 contrast-more:hover:hx-border-gray-900 dark:hx-text-neutral-400 dark:hover:hx-bg-primary-100/5 dark:hover:hx-text-gray-50 contrast-more:dark:hx-text-gray-50 contrast-more:dark:hover:hx-border-gray-50"
    href="/about/"
    
  >About</a></li>
    
      <li><a
    class="hx-flex hx-items-center hx-justify-between hx-gap-2 hx-cursor-pointer hx-rounded hx-px-2 hx-py-1.5 hx-text-sm hx-transition-colors [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] [word-break:break-word]
      hx-text-gray-500 hover:hx-bg-gray-100 hover:hx-text-gray-900 contrast-more:hx-border contrast-more:hx-border-transparent contrast-more:hx-text-gray-900 contrast-more:hover:hx-border-gray-900 dark:hx-text-neutral-400 dark:hover:hx-bg-primary-100/5 dark:hover:hx-text-gray-50 contrast-more:dark:hx-text-gray-50 contrast-more:dark:hover:hx-border-gray-50"
    href="https://gohugo.io/documentation/"
    target="_blank" rel="noreferer"
  >Hugo Docs ↗</a></li>
    
    </ul>

    <ul class="hx-flex hx-flex-col hx-gap-1 max-md:hx-hidden">
        
          <li class="open"><a
    class="hx-flex hx-items-center hx-justify-between hx-gap-2 hx-cursor-pointer hx-rounded hx-px-2 hx-py-1.5 hx-text-sm hx-transition-colors [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] [word-break:break-word]
      sidebar-active-item hx-bg-primary-100 hx-font-semibold hx-text-primary-800 contrast-more:hx-border contrast-more:hx-border-primary-500 dark:hx-bg-primary-400/10 dark:hx-text-primary-600 contrast-more:dark:hx-border-primary-500"
    href="/docs/deeplearning/"
    
  >Deeplearning
    </a></li>
        
      <li class="[word-break:break-word] hx-mt-5 hx-mb-2 hx-px-2 hx-py-1.5 hx-text-sm hx-font-semibold hx-text-gray-900 first:hx-mt-0 dark:hx-text-gray-100">
        <span class="hx-cursor-default">More</span>
      </li>
    
      <li><a
    class="hx-flex hx-items-center hx-justify-between hx-gap-2 hx-cursor-pointer hx-rounded hx-px-2 hx-py-1.5 hx-text-sm hx-transition-colors [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] [word-break:break-word]
      hx-text-gray-500 hover:hx-bg-gray-100 hover:hx-text-gray-900 contrast-more:hx-border contrast-more:hx-border-transparent contrast-more:hx-text-gray-900 contrast-more:hover:hx-border-gray-900 dark:hx-text-neutral-400 dark:hover:hx-bg-primary-100/5 dark:hover:hx-text-gray-50 contrast-more:dark:hx-text-gray-50 contrast-more:dark:hover:hx-border-gray-50"
    href="/about/"
    
  >About</a></li>
    
      <li><a
    class="hx-flex hx-items-center hx-justify-between hx-gap-2 hx-cursor-pointer hx-rounded hx-px-2 hx-py-1.5 hx-text-sm hx-transition-colors [-webkit-tap-highlight-color:transparent] [-webkit-touch-callout:none] [word-break:break-word]
      hx-text-gray-500 hover:hx-bg-gray-100 hover:hx-text-gray-900 contrast-more:hx-border contrast-more:hx-border-transparent contrast-more:hx-text-gray-900 contrast-more:hover:hx-border-gray-900 dark:hx-text-neutral-400 dark:hover:hx-bg-primary-100/5 dark:hover:hx-text-gray-50 contrast-more:dark:hx-text-gray-50 contrast-more:dark:hover:hx-border-gray-50"
    href="https://gohugo.io/documentation/"
    target="_blank" rel="noreferer"
  >Hugo Docs ↗</a></li>
    
      </ul>
    </div>
  
  
    <div class=" hx-justify-end hx-sticky hx-bottom-0 hx-bg-white dark:hx-bg-dark hx-mx-4 hx-py-4 hx-shadow-[0_-12px_16px_#fff] hx-flex hx-items-center hx-gap-2 dark:hx-border-neutral-800 dark:hx-shadow-[0_-12px_16px_#111] contrast-more:hx-border-neutral-400 contrast-more:hx-shadow-none contrast-more:dark:hx-shadow-none hx-border-t" data-toggle-animation="show"><div class="hx-flex hx-justify-items-start hx-grow">
    <button
      title="Change language"
      data-state="closed"
      class="language-switcher hx-h-7 hx-rounded-md hx-px-2 hx-text-left hx-text-xs hx-font-medium hx-text-gray-600 hx-transition-colors dark:hx-text-gray-400 hover:hx-bg-gray-100 hover:hx-text-gray-900 dark:hover:hx-bg-primary-100/5 dark:hover:hx-text-gray-50 hx-grow"
      type="button"
      aria-label="Change language"
    >
      <div class="hx-flex hx-items-center hx-gap-2 hx-capitalize"><svg height=12 xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" aria-hidden="true"><path stroke-linecap="round" stroke-linejoin="round" d="M21 12a9 9 0 01-9 9m9-9a9 9 0 00-9-9m9 9H3m9 9a9 9 0 01-9-9m9 9c1.657 0 3-4.03 3-9s-1.343-9-3-9m0 18c-1.657 0-3-4.03-3-9s1.343-9 3-9m-9 9a9 9 0 019-9"/></svg><span>English</span></div>
    </button>
    <ul
      class="language-options hx-hidden hx-z-20 hx-max-h-64 hx-overflow-auto hx-rounded-md hx-ring-1 hx-ring-black/5 hx-bg-white hx-py-1 hx-text-sm hx-shadow-lg dark:hx-ring-white/20 dark:hx-bg-neutral-800"
      style="position: fixed; inset: auto auto 0px 0px; margin: 0px; min-width: 100px;"
    >
      
        
        <li class="hx-flex hx-flex-col">
          <a
            href="/docs/deeplearning/"
            class="hx-text-gray-800 dark:hx-text-gray-100 hover:hx-bg-primary-50 hover:hx-text-primary-600 hover:dark:hx-bg-primary-500/10 hover:dark:hx-text-primary-600 hx-relative hx-cursor-pointer hx-whitespace-nowrap hx-py-1.5 hx-transition-colors ltr:hx-pl-3 ltr:hx-pr-9 rtl:hx-pr-3 rtl:hx-pl-9"
          >English<span class="hx-absolute hx-inset-y-0 hx-flex hx-items-center ltr:hx-right-3 rtl:hx-left-3"><svg height=1em width=1em xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" aria-hidden="true"><path stroke-linecap="round" stroke-linejoin="round" d="M5 13l4 4L19 7"/></svg></span></a>
        </li>
      
        
        <li class="hx-flex hx-flex-col">
          <a
            href="/zh-cn/"
            class="hx-text-gray-800 dark:hx-text-gray-100 hover:hx-bg-primary-50 hover:hx-text-primary-600 hover:dark:hx-bg-primary-500/10 hover:dark:hx-text-primary-600 hx-relative hx-cursor-pointer hx-whitespace-nowrap hx-py-1.5 hx-transition-colors ltr:hx-pl-3 ltr:hx-pr-9 rtl:hx-pr-3 rtl:hx-pl-9"
          >简体中文</a>
        </li>
      </ul>
  </div><button
  title="Change theme"
  data-theme="light"
  class="theme-toggle hx-group hx-h-7 hx-rounded-md hx-px-2 hx-text-left hx-text-xs hx-font-medium hx-text-gray-600 hx-transition-colors dark:hx-text-gray-400 hover:hx-bg-gray-100 hover:hx-text-gray-900 dark:hover:hx-bg-primary-100/5 dark:hover:hx-text-gray-50"
  type="button"
  aria-label="Change theme"
>
  <div class="hx-flex hx-items-center hx-gap-2 hx-capitalize"><svg height=12 class="group-data-[theme=light]:hx-hidden" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" aria-hidden="true"><path stroke-linecap="round" stroke-linejoin="round" d="M12 3v1m0 16v1m9-9h-1M4 12H3m15.364 6.364l-.707-.707M6.343 6.343l-.707-.707m12.728 0l-.707.707M6.343 17.657l-.707.707M16 12a4 4 0 11-8 0 4 4 0 018 0z"/></svg><svg height=12 class="group-data-[theme=dark]:hx-hidden" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" aria-hidden="true"><path stroke-linecap="round" stroke-linejoin="round" d="M20.354 15.354A9 9 0 018.646 3.646 9.003 9.003 0 0012 21a9.003 9.003 0 008.354-5.646z"/></svg></div>
</button>
</div></aside>
    
<nav class="hextra-toc hx-order-last hx-hidden hx-w-64 hx-shrink-0 xl:hx-block print:hx-hidden hx-px-4" aria-label="table of contents">
    <div class="hextra-scrollbar hx-sticky hx-top-16 hx-overflow-y-auto hx-pr-4 hx-pt-6 hx-text-sm [hyphens:auto] hx-max-h-[calc(100vh-var(--navbar-height)-env(safe-area-inset-bottom))] ltr:hx--mr-4 rtl:hx--ml-4"><p class="hx-mb-4 hx-font-semibold hx-tracking-tight">On this page</p><ul>
      <li class="hx-my-2 hx-scroll-my-6 hx-scroll-py-6">
        <a class="hx-font-semibold hx-inline-block hx-text-gray-500 hover:hx-text-gray-900 dark:hx-text-gray-400 dark:hover:hx-text-gray-300 contrast-more:hx-text-gray-900 contrast-more:hx-underline contrast-more:dark:hx-text-gray-50 hx-w-full hx-break-words" href="#lenet">LeNet
        </a>
      </li>
      <li class="hx-my-2 hx-scroll-my-6 hx-scroll-py-6">
        <a class="hx-font-semibold hx-inline-block hx-text-gray-500 hover:hx-text-gray-900 dark:hx-text-gray-400 dark:hover:hx-text-gray-300 contrast-more:hx-text-gray-900 contrast-more:hx-underline contrast-more:dark:hx-text-gray-50 hx-w-full hx-break-words" href="#alexnet">AlexNet
        </a>
      </li>
      <li class="hx-my-2 hx-scroll-my-6 hx-scroll-py-6">
        <a class="hx-font-semibold hx-inline-block hx-text-gray-500 hover:hx-text-gray-900 dark:hx-text-gray-400 dark:hover:hx-text-gray-300 contrast-more:hx-text-gray-900 contrast-more:hx-underline contrast-more:dark:hx-text-gray-50 hx-w-full hx-break-words" href="#vggnet">VGGNet
        </a>
      </li>
      <li class="hx-my-2 hx-scroll-my-6 hx-scroll-py-6">
        <a class="hx-font-semibold hx-inline-block hx-text-gray-500 hover:hx-text-gray-900 dark:hx-text-gray-400 dark:hover:hx-text-gray-300 contrast-more:hx-text-gray-900 contrast-more:hx-underline contrast-more:dark:hx-text-gray-50 hx-w-full hx-break-words" href="#nin">NiN
        </a>
      </li>
      <li class="hx-my-2 hx-scroll-my-6 hx-scroll-py-6">
        <a class="hx-font-semibold hx-inline-block hx-text-gray-500 hover:hx-text-gray-900 dark:hx-text-gray-400 dark:hover:hx-text-gray-300 contrast-more:hx-text-gray-900 contrast-more:hx-underline contrast-more:dark:hx-text-gray-50 hx-w-full hx-break-words" href="#googlenet">GoogLeNet
        </a>
      </li>
      <li class="hx-my-2 hx-scroll-my-6 hx-scroll-py-6">
        <a class="hx-font-semibold hx-inline-block hx-text-gray-500 hover:hx-text-gray-900 dark:hx-text-gray-400 dark:hover:hx-text-gray-300 contrast-more:hx-text-gray-900 contrast-more:hx-underline contrast-more:dark:hx-text-gray-50 hx-w-full hx-break-words" href="#resnet">ResNet
        </a>
      </li></ul><ul>
      <li class="hx-my-2 hx-scroll-my-6 hx-scroll-py-6">
        <a class="hx-font-semibold hx-inline-block hx-text-gray-500 hover:hx-text-gray-900 dark:hx-text-gray-400 dark:hover:hx-text-gray-300 contrast-more:hx-text-gray-900 contrast-more:hx-underline contrast-more:dark:hx-text-gray-50 hx-w-full hx-break-words" href="#%e6%95%b0%e6%8d%ae%e5%a2%9e%e5%bc%ba">数据增强
        </a>
      </li>
      <li class="hx-my-2 hx-scroll-my-6 hx-scroll-py-6">
        <a class="hx-font-semibold hx-inline-block hx-text-gray-500 hover:hx-text-gray-900 dark:hx-text-gray-400 dark:hover:hx-text-gray-300 contrast-more:hx-text-gray-900 contrast-more:hx-underline contrast-more:dark:hx-text-gray-50 hx-w-full hx-break-words" href="#%e5%be%ae%e8%b0%83">微调
        </a>
      </li>
      <li class="hx-my-2 hx-scroll-my-6 hx-scroll-py-6">
        <a class="hx-font-semibold hx-inline-block hx-text-gray-500 hover:hx-text-gray-900 dark:hx-text-gray-400 dark:hover:hx-text-gray-300 contrast-more:hx-text-gray-900 contrast-more:hx-underline contrast-more:dark:hx-text-gray-50 hx-w-full hx-break-words" href="#%e7%9b%ae%e6%a0%87%e6%a3%80%e6%b5%8b">目标检测
        </a>
      </li>
      <li class="hx-my-2 hx-scroll-my-6 hx-scroll-py-6">
        <a class="ltr:hx-pl-4 rtl:hx-pr-4 hx-inline-block hx-text-gray-500 hover:hx-text-gray-900 dark:hx-text-gray-400 dark:hover:hx-text-gray-300 contrast-more:hx-text-gray-900 contrast-more:hx-underline contrast-more:dark:hx-text-gray-50 hx-w-full hx-break-words" href="#%e9%94%9a%e6%a1%86">锚框
        </a>
      </li>
      <li class="hx-my-2 hx-scroll-my-6 hx-scroll-py-6">
        <a class="hx-font-semibold hx-inline-block hx-text-gray-500 hover:hx-text-gray-900 dark:hx-text-gray-400 dark:hover:hx-text-gray-300 contrast-more:hx-text-gray-900 contrast-more:hx-underline contrast-more:dark:hx-text-gray-50 hx-w-full hx-break-words" href="#%e7%89%a9%e4%bd%93%e6%a3%80%e6%b5%8b%e7%ae%97%e6%b3%95">物体检测算法
        </a>
      </li>
      <li class="hx-my-2 hx-scroll-my-6 hx-scroll-py-6">
        <a class="ltr:hx-pl-4 rtl:hx-pr-4 hx-inline-block hx-text-gray-500 hover:hx-text-gray-900 dark:hx-text-gray-400 dark:hover:hx-text-gray-300 contrast-more:hx-text-gray-900 contrast-more:hx-underline contrast-more:dark:hx-text-gray-50 hx-w-full hx-break-words" href="#r-cnn">R-CNN
        </a>
      </li>
      <li class="hx-my-2 hx-scroll-my-6 hx-scroll-py-6">
        <a class="ltr:hx-pl-4 rtl:hx-pr-4 hx-inline-block hx-text-gray-500 hover:hx-text-gray-900 dark:hx-text-gray-400 dark:hover:hx-text-gray-300 contrast-more:hx-text-gray-900 contrast-more:hx-underline contrast-more:dark:hx-text-gray-50 hx-w-full hx-break-words" href="#fast-r-cnn">Fast R-CNN
        </a>
      </li>
      <li class="hx-my-2 hx-scroll-my-6 hx-scroll-py-6">
        <a class="ltr:hx-pl-4 rtl:hx-pr-4 hx-inline-block hx-text-gray-500 hover:hx-text-gray-900 dark:hx-text-gray-400 dark:hover:hx-text-gray-300 contrast-more:hx-text-gray-900 contrast-more:hx-underline contrast-more:dark:hx-text-gray-50 hx-w-full hx-break-words" href="#faster-r-cnn">Faster R-CNN
        </a>
      </li>
      <li class="hx-my-2 hx-scroll-my-6 hx-scroll-py-6">
        <a class="ltr:hx-pl-4 rtl:hx-pr-4 hx-inline-block hx-text-gray-500 hover:hx-text-gray-900 dark:hx-text-gray-400 dark:hover:hx-text-gray-300 contrast-more:hx-text-gray-900 contrast-more:hx-underline contrast-more:dark:hx-text-gray-50 hx-w-full hx-break-words" href="#mask-r-cnn">Mask R-CNN
        </a>
      </li>
      <li class="hx-my-2 hx-scroll-my-6 hx-scroll-py-6">
        <a class="ltr:hx-pl-4 rtl:hx-pr-4 hx-inline-block hx-text-gray-500 hover:hx-text-gray-900 dark:hx-text-gray-400 dark:hover:hx-text-gray-300 contrast-more:hx-text-gray-900 contrast-more:hx-underline contrast-more:dark:hx-text-gray-50 hx-w-full hx-break-words" href="#r-cnn%e6%80%bb%e7%bb%93">R-CNN总结
        </a>
      </li>
      <li class="hx-my-2 hx-scroll-my-6 hx-scroll-py-6">
        <a class="ltr:hx-pl-4 rtl:hx-pr-4 hx-inline-block hx-text-gray-500 hover:hx-text-gray-900 dark:hx-text-gray-400 dark:hover:hx-text-gray-300 contrast-more:hx-text-gray-900 contrast-more:hx-underline contrast-more:dark:hx-text-gray-50 hx-w-full hx-break-words" href="#ssd">SSD
        </a>
      </li>
      <li class="hx-my-2 hx-scroll-my-6 hx-scroll-py-6">
        <a class="ltr:hx-pl-4 rtl:hx-pr-4 hx-inline-block hx-text-gray-500 hover:hx-text-gray-900 dark:hx-text-gray-400 dark:hover:hx-text-gray-300 contrast-more:hx-text-gray-900 contrast-more:hx-underline contrast-more:dark:hx-text-gray-50 hx-w-full hx-break-words" href="#yolo">YOLO
        </a>
      </li>
      <li class="hx-my-2 hx-scroll-my-6 hx-scroll-py-6">
        <a class="hx-font-semibold hx-inline-block hx-text-gray-500 hover:hx-text-gray-900 dark:hx-text-gray-400 dark:hover:hx-text-gray-300 contrast-more:hx-text-gray-900 contrast-more:hx-underline contrast-more:dark:hx-text-gray-50 hx-w-full hx-break-words" href="#%e8%af%ad%e4%b9%89%e5%88%86%e5%89%b2">语义分割
        </a>
      </li>
      <li class="hx-my-2 hx-scroll-my-6 hx-scroll-py-6">
        <a class="hx-font-semibold hx-inline-block hx-text-gray-500 hover:hx-text-gray-900 dark:hx-text-gray-400 dark:hover:hx-text-gray-300 contrast-more:hx-text-gray-900 contrast-more:hx-underline contrast-more:dark:hx-text-gray-50 hx-w-full hx-break-words" href="#%e8%bd%ac%e7%bd%ae%e5%8d%b7%e7%a7%af">转置卷积
        </a>
      </li>
      <li class="hx-my-2 hx-scroll-my-6 hx-scroll-py-6">
        <a class="hx-font-semibold hx-inline-block hx-text-gray-500 hover:hx-text-gray-900 dark:hx-text-gray-400 dark:hover:hx-text-gray-300 contrast-more:hx-text-gray-900 contrast-more:hx-underline contrast-more:dark:hx-text-gray-50 hx-w-full hx-break-words" href="#%e5%85%a8%e8%bf%9e%e6%8e%a5%e5%8d%b7%e7%a7%af%e7%a5%9e%e7%bb%8f%e7%bd%91%e7%bb%9cfcn">全连接卷积神经网络（FCN）
        </a>
      </li>
      <li class="hx-my-2 hx-scroll-my-6 hx-scroll-py-6">
        <a class="hx-font-semibold hx-inline-block hx-text-gray-500 hover:hx-text-gray-900 dark:hx-text-gray-400 dark:hover:hx-text-gray-300 contrast-more:hx-text-gray-900 contrast-more:hx-underline contrast-more:dark:hx-text-gray-50 hx-w-full hx-break-words" href="#%e6%a0%b7%e5%bc%8f%e8%bf%81%e7%a7%bb">样式迁移
        </a>
      </li></ul><ul>
      <li class="hx-my-2 hx-scroll-my-6 hx-scroll-py-6">
        <a class="hx-font-semibold hx-inline-block hx-text-gray-500 hover:hx-text-gray-900 dark:hx-text-gray-400 dark:hover:hx-text-gray-300 contrast-more:hx-text-gray-900 contrast-more:hx-underline contrast-more:dark:hx-text-gray-50 hx-w-full hx-break-words" href="#%e5%ba%8f%e5%88%97%e6%a8%a1%e5%9e%8b">序列模型
        </a>
      </li>
      <li class="hx-my-2 hx-scroll-my-6 hx-scroll-py-6">
        <a class="hx-font-semibold hx-inline-block hx-text-gray-500 hover:hx-text-gray-900 dark:hx-text-gray-400 dark:hover:hx-text-gray-300 contrast-more:hx-text-gray-900 contrast-more:hx-underline contrast-more:dark:hx-text-gray-50 hx-w-full hx-break-words" href="#%e6%96%87%e6%9c%ac%e9%a2%84%e5%a4%84%e7%90%86">文本预处理
        </a>
      </li>
      <li class="hx-my-2 hx-scroll-my-6 hx-scroll-py-6">
        <a class="hx-font-semibold hx-inline-block hx-text-gray-500 hover:hx-text-gray-900 dark:hx-text-gray-400 dark:hover:hx-text-gray-300 contrast-more:hx-text-gray-900 contrast-more:hx-underline contrast-more:dark:hx-text-gray-50 hx-w-full hx-break-words" href="#%e8%af%ad%e8%a8%80%e6%a8%a1%e5%9e%8b">语言模型
        </a>
      </li>
      <li class="hx-my-2 hx-scroll-my-6 hx-scroll-py-6">
        <a class="hx-font-semibold hx-inline-block hx-text-gray-500 hover:hx-text-gray-900 dark:hx-text-gray-400 dark:hover:hx-text-gray-300 contrast-more:hx-text-gray-900 contrast-more:hx-underline contrast-more:dark:hx-text-gray-50 hx-w-full hx-break-words" href="#rnn">RNN
        </a>
      </li>
      <li class="hx-my-2 hx-scroll-my-6 hx-scroll-py-6">
        <a class="ltr:hx-pl-4 rtl:hx-pr-4 hx-inline-block hx-text-gray-500 hover:hx-text-gray-900 dark:hx-text-gray-400 dark:hover:hx-text-gray-300 contrast-more:hx-text-gray-900 contrast-more:hx-underline contrast-more:dark:hx-text-gray-50 hx-w-full hx-break-words" href="#%e6%a2%af%e5%ba%a6%e8%a3%81%e5%89%aa">梯度裁剪
        </a>
      </li>
      <li class="hx-my-2 hx-scroll-my-6 hx-scroll-py-6">
        <a class="hx-font-semibold hx-inline-block hx-text-gray-500 hover:hx-text-gray-900 dark:hx-text-gray-400 dark:hover:hx-text-gray-300 contrast-more:hx-text-gray-900 contrast-more:hx-underline contrast-more:dark:hx-text-gray-50 hx-w-full hx-break-words" href="#%e9%97%a8%e6%8e%a7%e5%be%aa%e7%8e%af%e5%8d%95%e5%85%83gru">门控循环单元（GRU）
        </a>
      </li>
      <li class="hx-my-2 hx-scroll-my-6 hx-scroll-py-6">
        <a class="hx-font-semibold hx-inline-block hx-text-gray-500 hover:hx-text-gray-900 dark:hx-text-gray-400 dark:hover:hx-text-gray-300 contrast-more:hx-text-gray-900 contrast-more:hx-underline contrast-more:dark:hx-text-gray-50 hx-w-full hx-break-words" href="#%e9%95%bf%e7%9f%ad%e6%9c%9f%e8%ae%b0%e5%bf%86%e7%bd%91%e7%bb%9clstm">长短期记忆网络（LSTM）
        </a>
      </li>
      <li class="hx-my-2 hx-scroll-my-6 hx-scroll-py-6">
        <a class="hx-font-semibold hx-inline-block hx-text-gray-500 hover:hx-text-gray-900 dark:hx-text-gray-400 dark:hover:hx-text-gray-300 contrast-more:hx-text-gray-900 contrast-more:hx-underline contrast-more:dark:hx-text-gray-50 hx-w-full hx-break-words" href="#%e6%b7%b1%e5%b1%82%e5%be%aa%e7%8e%af%e7%a5%9e%e7%bb%8f%e7%bd%91%e7%bb%9c">深层循环神经网络
        </a>
      </li>
      <li class="hx-my-2 hx-scroll-my-6 hx-scroll-py-6">
        <a class="hx-font-semibold hx-inline-block hx-text-gray-500 hover:hx-text-gray-900 dark:hx-text-gray-400 dark:hover:hx-text-gray-300 contrast-more:hx-text-gray-900 contrast-more:hx-underline contrast-more:dark:hx-text-gray-50 hx-w-full hx-break-words" href="#%e5%8f%8c%e5%90%91%e5%be%aa%e7%8e%af%e7%a5%9e%e7%bb%8f%e7%bd%91%e7%bb%9c">双向循环神经网络
        </a>
      </li>
      <li class="hx-my-2 hx-scroll-my-6 hx-scroll-py-6">
        <a class="hx-font-semibold hx-inline-block hx-text-gray-500 hover:hx-text-gray-900 dark:hx-text-gray-400 dark:hover:hx-text-gray-300 contrast-more:hx-text-gray-900 contrast-more:hx-underline contrast-more:dark:hx-text-gray-50 hx-w-full hx-break-words" href="#%e6%9c%ba%e5%99%a8%e7%bf%bb%e8%af%91%e4%b8%8e%e6%95%b0%e6%8d%ae%e9%9b%86">机器翻译与数据集
        </a>
      </li></ul><ul>
      <li class="hx-my-2 hx-scroll-my-6 hx-scroll-py-6">
        <a class="hx-font-semibold hx-inline-block hx-text-gray-500 hover:hx-text-gray-900 dark:hx-text-gray-400 dark:hover:hx-text-gray-300 contrast-more:hx-text-gray-900 contrast-more:hx-underline contrast-more:dark:hx-text-gray-50 hx-w-full hx-break-words" href="#%e5%ba%8f%e5%88%97%e5%88%b0%e5%ba%8f%e5%88%97%e5%ad%a6%e4%b9%a0seq2seq">序列到序列学习（seq2seq）
        </a>
      </li>
      <li class="hx-my-2 hx-scroll-my-6 hx-scroll-py-6">
        <a class="hx-font-semibold hx-inline-block hx-text-gray-500 hover:hx-text-gray-900 dark:hx-text-gray-400 dark:hover:hx-text-gray-300 contrast-more:hx-text-gray-900 contrast-more:hx-underline contrast-more:dark:hx-text-gray-50 hx-w-full hx-break-words" href="#%e6%9d%9f%e6%90%9c%e7%b4%a2">束搜索
        </a>
      </li></ul><ul>
      <li class="hx-my-2 hx-scroll-my-6 hx-scroll-py-6">
        <a class="hx-font-semibold hx-inline-block hx-text-gray-500 hover:hx-text-gray-900 dark:hx-text-gray-400 dark:hover:hx-text-gray-300 contrast-more:hx-text-gray-900 contrast-more:hx-underline contrast-more:dark:hx-text-gray-50 hx-w-full hx-break-words" href="#%e6%b3%a8%e6%84%8f%e5%8a%9b%e5%88%86%e6%95%b0">注意力分数
        </a>
      </li>
      <li class="hx-my-2 hx-scroll-my-6 hx-scroll-py-6">
        <a class="hx-font-semibold hx-inline-block hx-text-gray-500 hover:hx-text-gray-900 dark:hx-text-gray-400 dark:hover:hx-text-gray-300 contrast-more:hx-text-gray-900 contrast-more:hx-underline contrast-more:dark:hx-text-gray-50 hx-w-full hx-break-words" href="#%e8%87%aa%e6%b3%a8%e6%84%8f%e5%8a%9b">自注意力
        </a>
      </li>
      <li class="hx-my-2 hx-scroll-my-6 hx-scroll-py-6">
        <a class="hx-font-semibold hx-inline-block hx-text-gray-500 hover:hx-text-gray-900 dark:hx-text-gray-400 dark:hover:hx-text-gray-300 contrast-more:hx-text-gray-900 contrast-more:hx-underline contrast-more:dark:hx-text-gray-50 hx-w-full hx-break-words" href="#transformer">Transformer
        </a>
      </li>
      <li class="hx-my-2 hx-scroll-my-6 hx-scroll-py-6">
        <a class="ltr:hx-pl-4 rtl:hx-pr-4 hx-inline-block hx-text-gray-500 hover:hx-text-gray-900 dark:hx-text-gray-400 dark:hover:hx-text-gray-300 contrast-more:hx-text-gray-900 contrast-more:hx-underline contrast-more:dark:hx-text-gray-50 hx-w-full hx-break-words" href="#%e5%a4%9a%e5%a4%b4%e6%b3%a8%e6%84%8f%e5%8a%9b">多头注意力
        </a>
      </li>
      <li class="hx-my-2 hx-scroll-my-6 hx-scroll-py-6">
        <a class="ltr:hx-pl-4 rtl:hx-pr-4 hx-inline-block hx-text-gray-500 hover:hx-text-gray-900 dark:hx-text-gray-400 dark:hover:hx-text-gray-300 contrast-more:hx-text-gray-900 contrast-more:hx-underline contrast-more:dark:hx-text-gray-50 hx-w-full hx-break-words" href="#%e5%9f%ba%e4%ba%8e%e4%bd%8d%e7%bd%ae%e7%9a%84%e5%89%8d%e9%a6%88%e7%bd%91%e7%bb%9c">基于位置的前馈网络
        </a>
      </li>
      <li class="hx-my-2 hx-scroll-my-6 hx-scroll-py-6">
        <a class="hx-font-semibold hx-inline-block hx-text-gray-500 hover:hx-text-gray-900 dark:hx-text-gray-400 dark:hover:hx-text-gray-300 contrast-more:hx-text-gray-900 contrast-more:hx-underline contrast-more:dark:hx-text-gray-50 hx-w-full hx-break-words" href="#bert">BERT
        </a>
      </li>
      <li class="hx-my-2 hx-scroll-my-6 hx-scroll-py-6">
        <a class="ltr:hx-pl-4 rtl:hx-pr-4 hx-inline-block hx-text-gray-500 hover:hx-text-gray-900 dark:hx-text-gray-400 dark:hover:hx-text-gray-300 contrast-more:hx-text-gray-900 contrast-more:hx-underline contrast-more:dark:hx-text-gray-50 hx-w-full hx-break-words" href="#%e5%be%ae%e8%b0%83-1">微调
        </a>
      </li></ul><ul>
      <li class="hx-my-2 hx-scroll-my-6 hx-scroll-py-6">
        <a class="hx-font-semibold hx-inline-block hx-text-gray-500 hover:hx-text-gray-900 dark:hx-text-gray-400 dark:hover:hx-text-gray-300 contrast-more:hx-text-gray-900 contrast-more:hx-underline contrast-more:dark:hx-text-gray-50 hx-w-full hx-break-words" href="#%e6%a2%af%e5%ba%a6%e4%b8%8b%e9%99%8d">梯度下降
        </a>
      </li>
      <li class="hx-my-2 hx-scroll-my-6 hx-scroll-py-6">
        <a class="hx-font-semibold hx-inline-block hx-text-gray-500 hover:hx-text-gray-900 dark:hx-text-gray-400 dark:hover:hx-text-gray-300 contrast-more:hx-text-gray-900 contrast-more:hx-underline contrast-more:dark:hx-text-gray-50 hx-w-full hx-break-words" href="#%e5%86%b2%e9%87%8f%e6%b3%95%e5%8a%a8%e9%87%8f">冲量法（动量）
        </a>
      </li>
      <li class="hx-my-2 hx-scroll-my-6 hx-scroll-py-6">
        <a class="hx-font-semibold hx-inline-block hx-text-gray-500 hover:hx-text-gray-900 dark:hx-text-gray-400 dark:hover:hx-text-gray-300 contrast-more:hx-text-gray-900 contrast-more:hx-underline contrast-more:dark:hx-text-gray-50 hx-w-full hx-break-words" href="#adam">Adam
        </a>
      </li></ul><ul>
      <li class="hx-my-2 hx-scroll-my-6 hx-scroll-py-6">
        <a class="hx-font-semibold hx-inline-block hx-text-gray-500 hover:hx-text-gray-900 dark:hx-text-gray-400 dark:hover:hx-text-gray-300 contrast-more:hx-text-gray-900 contrast-more:hx-underline contrast-more:dark:hx-text-gray-50 hx-w-full hx-break-words" href="#machine-learning">Machine Learning
        </a>
      </li>
      <li class="hx-my-2 hx-scroll-my-6 hx-scroll-py-6">
        <a class="hx-font-semibold hx-inline-block hx-text-gray-500 hover:hx-text-gray-900 dark:hx-text-gray-400 dark:hover:hx-text-gray-300 contrast-more:hx-text-gray-900 contrast-more:hx-underline contrast-more:dark:hx-text-gray-50 hx-w-full hx-break-words" href="#%e4%b8%89%e4%b8%aa%e6%9c%ba%e5%99%a8%e5%ad%a6%e4%b9%a0%e4%bb%bb%e5%8a%a1">三个机器学习任务
        </a>
      </li>
      <li class="hx-my-2 hx-scroll-my-6 hx-scroll-py-6">
        <a class="hx-font-semibold hx-inline-block hx-text-gray-500 hover:hx-text-gray-900 dark:hx-text-gray-400 dark:hover:hx-text-gray-300 contrast-more:hx-text-gray-900 contrast-more:hx-underline contrast-more:dark:hx-text-gray-50 hx-w-full hx-break-words" href="#%e6%89%be%e5%87%bd%e5%bc%8f%e7%9a%84%e8%bf%87%e7%a8%8b%e4%b8%89%e4%b8%aa%e6%ad%a5%e9%aa%a4">找函式的过程：三个步骤
        </a>
      </li>
      <li class="hx-my-2 hx-scroll-my-6 hx-scroll-py-6">
        <a class="hx-font-semibold hx-inline-block hx-text-gray-500 hover:hx-text-gray-900 dark:hx-text-gray-400 dark:hover:hx-text-gray-300 contrast-more:hx-text-gray-900 contrast-more:hx-underline contrast-more:dark:hx-text-gray-50 hx-w-full hx-break-words" href="#liner-model%e7%ba%bf%e6%80%a7%e6%a8%a1%e5%9e%8b">Liner Model（线性模型）
        </a>
      </li></ul><ul>
      <li class="hx-my-2 hx-scroll-my-6 hx-scroll-py-6">
        <a class="hx-font-semibold hx-inline-block hx-text-gray-500 hover:hx-text-gray-900 dark:hx-text-gray-400 dark:hover:hx-text-gray-300 contrast-more:hx-text-gray-900 contrast-more:hx-underline contrast-more:dark:hx-text-gray-50 hx-w-full hx-break-words" href="#%e5%a6%82%e4%bd%95%e4%bd%bf%e6%a8%a1%e5%9e%8b%e8%be%be%e5%88%b0%e6%9b%b4%e5%a5%bd%e7%9a%84%e6%95%88%e6%9e%9c">如何使模型达到更好的效果？
        </a>
      </li>
      <li class="hx-my-2 hx-scroll-my-6 hx-scroll-py-6">
        <a class="hx-font-semibold hx-inline-block hx-text-gray-500 hover:hx-text-gray-900 dark:hx-text-gray-400 dark:hover:hx-text-gray-300 contrast-more:hx-text-gray-900 contrast-more:hx-underline contrast-more:dark:hx-text-gray-50 hx-w-full hx-break-words" href="#%e6%9d%83%e9%87%8d%e8%a1%b0%e9%80%80">权重衰退
        </a>
      </li>
      <li class="hx-my-2 hx-scroll-my-6 hx-scroll-py-6">
        <a class="hx-font-semibold hx-inline-block hx-text-gray-500 hover:hx-text-gray-900 dark:hx-text-gray-400 dark:hover:hx-text-gray-300 contrast-more:hx-text-gray-900 contrast-more:hx-underline contrast-more:dark:hx-text-gray-50 hx-w-full hx-break-words" href="#%e4%b8%a2%e5%bc%83%e6%b3%95">丢弃法
        </a>
      </li>
      <li class="hx-my-2 hx-scroll-my-6 hx-scroll-py-6">
        <a class="hx-font-semibold hx-inline-block hx-text-gray-500 hover:hx-text-gray-900 dark:hx-text-gray-400 dark:hover:hx-text-gray-300 contrast-more:hx-text-gray-900 contrast-more:hx-underline contrast-more:dark:hx-text-gray-50 hx-w-full hx-break-words" href="#%e6%89%b9%e9%87%8f%e5%bd%92%e4%b8%80%e5%8c%96">批量归一化
        </a>
      </li></ul><ul>
      <li class="hx-my-2 hx-scroll-my-6 hx-scroll-py-6">
        <a class="hx-font-semibold hx-inline-block hx-text-gray-500 hover:hx-text-gray-900 dark:hx-text-gray-400 dark:hover:hx-text-gray-300 contrast-more:hx-text-gray-900 contrast-more:hx-underline contrast-more:dark:hx-text-gray-50 hx-w-full hx-break-words" href="#critical-point-%e6%a6%82%e8%bf%b0">critical point 概述
        </a>
      </li>
      <li class="hx-my-2 hx-scroll-my-6 hx-scroll-py-6">
        <a class="ltr:hx-pl-4 rtl:hx-pr-4 hx-inline-block hx-text-gray-500 hover:hx-text-gray-900 dark:hx-text-gray-400 dark:hover:hx-text-gray-300 contrast-more:hx-text-gray-900 contrast-more:hx-underline contrast-more:dark:hx-text-gray-50 hx-w-full hx-break-words" href="#small-batch-vs-large-batch">Small Batch v.s. Large Batch
        </a>
      </li>
      <li class="hx-my-2 hx-scroll-my-6 hx-scroll-py-6">
        <a class="ltr:hx-pl-4 rtl:hx-pr-4 hx-inline-block hx-text-gray-500 hover:hx-text-gray-900 dark:hx-text-gray-400 dark:hover:hx-text-gray-300 contrast-more:hx-text-gray-900 contrast-more:hx-underline contrast-more:dark:hx-text-gray-50 hx-w-full hx-break-words" href="#momentum%e5%8a%a8%e9%87%8f">Momentum（动量）
        </a>
      </li>
      <li class="hx-my-2 hx-scroll-my-6 hx-scroll-py-6">
        <a class="ltr:hx-pl-4 rtl:hx-pr-4 hx-inline-block hx-text-gray-500 hover:hx-text-gray-900 dark:hx-text-gray-400 dark:hover:hx-text-gray-300 contrast-more:hx-text-gray-900 contrast-more:hx-underline contrast-more:dark:hx-text-gray-50 hx-w-full hx-break-words" href="#%e6%80%bb%e7%bb%93---%e5%85%b3%e4%ba%8e%e5%b0%8f%e6%a2%af%e5%ba%a6">总结 - 关于“小梯度”
        </a>
      </li>
      <li class="hx-my-2 hx-scroll-my-6 hx-scroll-py-6">
        <a class="ltr:hx-pl-4 rtl:hx-pr-4 hx-inline-block hx-text-gray-500 hover:hx-text-gray-900 dark:hx-text-gray-400 dark:hover:hx-text-gray-300 contrast-more:hx-text-gray-900 contrast-more:hx-underline contrast-more:dark:hx-text-gray-50 hx-w-full hx-break-words" href="#%e8%87%aa%e9%80%82%e5%ba%94%e5%ad%a6%e4%b9%a0%e7%8e%87">自适应学习率
        </a>
      </li>
      <li class="hx-my-2 hx-scroll-my-6 hx-scroll-py-6">
        <a class="ltr:hx-pl-4 rtl:hx-pr-4 hx-inline-block hx-text-gray-500 hover:hx-text-gray-900 dark:hx-text-gray-400 dark:hover:hx-text-gray-300 contrast-more:hx-text-gray-900 contrast-more:hx-underline contrast-more:dark:hx-text-gray-50 hx-w-full hx-break-words" href="#%e6%80%bb%e7%bb%93">总结
        </a>
      </li>
      <li class="hx-my-2 hx-scroll-my-6 hx-scroll-py-6">
        <a class="ltr:hx-pl-4 rtl:hx-pr-4 hx-inline-block hx-text-gray-500 hover:hx-text-gray-900 dark:hx-text-gray-400 dark:hover:hx-text-gray-300 contrast-more:hx-text-gray-900 contrast-more:hx-underline contrast-more:dark:hx-text-gray-50 hx-w-full hx-break-words" href="#%e5%8f%a6%e4%b8%80%e7%a7%8d%e6%80%9d%e8%b7%af">另一种思路
        </a>
      </li></ul><ul>
      <li class="hx-my-2 hx-scroll-my-6 hx-scroll-py-6">
        <a class="hx-font-semibold hx-inline-block hx-text-gray-500 hover:hx-text-gray-900 dark:hx-text-gray-400 dark:hover:hx-text-gray-300 contrast-more:hx-text-gray-900 contrast-more:hx-underline contrast-more:dark:hx-text-gray-50 hx-w-full hx-break-words" href="#classification-as-regression">Classification as Regression
        </a>
      </li>
      <li class="hx-my-2 hx-scroll-my-6 hx-scroll-py-6">
        <a class="hx-font-semibold hx-inline-block hx-text-gray-500 hover:hx-text-gray-900 dark:hx-text-gray-400 dark:hover:hx-text-gray-300 contrast-more:hx-text-gray-900 contrast-more:hx-underline contrast-more:dark:hx-text-gray-50 hx-w-full hx-break-words" href="#%e4%bc%98%e5%8c%96%e7%9b%ae%e6%a0%87%e5%87%8f%e5%b0%8fy%e5%92%8cy%e4%b9%8b%e9%97%b4%e7%9a%84%e5%b7%ae%e8%b7%9de">优化目标：减小y^和y’之间的差距e
        </a>
      </li></ul><ul>
      <li class="hx-my-2 hx-scroll-my-6 hx-scroll-py-6">
        <a class="hx-font-semibold hx-inline-block hx-text-gray-500 hover:hx-text-gray-900 dark:hx-text-gray-400 dark:hover:hx-text-gray-300 contrast-more:hx-text-gray-900 contrast-more:hx-underline contrast-more:dark:hx-text-gray-50 hx-w-full hx-break-words" href="#%e5%9c%ba%e6%99%af-%e5%9b%be%e7%89%87%e5%88%86%e7%b1%bb">场景： 图片分类
        </a>
      </li>
      <li class="hx-my-2 hx-scroll-my-6 hx-scroll-py-6">
        <a class="hx-font-semibold hx-inline-block hx-text-gray-500 hover:hx-text-gray-900 dark:hx-text-gray-400 dark:hover:hx-text-gray-300 contrast-more:hx-text-gray-900 contrast-more:hx-underline contrast-more:dark:hx-text-gray-50 hx-w-full hx-break-words" href="#%e7%a5%9e%e7%bb%8f%e5%85%83%e8%a7%92%e5%ba%a6">神经元角度
        </a>
      </li>
      <li class="hx-my-2 hx-scroll-my-6 hx-scroll-py-6">
        <a class="ltr:hx-pl-4 rtl:hx-pr-4 hx-inline-block hx-text-gray-500 hover:hx-text-gray-900 dark:hx-text-gray-400 dark:hover:hx-text-gray-300 contrast-more:hx-text-gray-900 contrast-more:hx-underline contrast-more:dark:hx-text-gray-50 hx-w-full hx-break-words" href="#%e5%8d%b7%e7%a7%af%e5%b1%82%e7%9a%84%e4%bc%98%e5%8a%bf">卷积层的优势
        </a>
      </li>
      <li class="hx-my-2 hx-scroll-my-6 hx-scroll-py-6">
        <a class="hx-font-semibold hx-inline-block hx-text-gray-500 hover:hx-text-gray-900 dark:hx-text-gray-400 dark:hover:hx-text-gray-300 contrast-more:hx-text-gray-900 contrast-more:hx-underline contrast-more:dark:hx-text-gray-50 hx-w-full hx-break-words" href="#%e6%bb%a4%e6%b3%a2%e5%99%a8%e8%a7%92%e5%ba%a6">滤波器角度
        </a>
      </li>
      <li class="hx-my-2 hx-scroll-my-6 hx-scroll-py-6">
        <a class="hx-font-semibold hx-inline-block hx-text-gray-500 hover:hx-text-gray-900 dark:hx-text-gray-400 dark:hover:hx-text-gray-300 contrast-more:hx-text-gray-900 contrast-more:hx-underline contrast-more:dark:hx-text-gray-50 hx-w-full hx-break-words" href="#%e6%80%bb%e7%bb%93-1">总结
        </a>
      </li>
      <li class="hx-my-2 hx-scroll-my-6 hx-scroll-py-6">
        <a class="hx-font-semibold hx-inline-block hx-text-gray-500 hover:hx-text-gray-900 dark:hx-text-gray-400 dark:hover:hx-text-gray-300 contrast-more:hx-text-gray-900 contrast-more:hx-underline contrast-more:dark:hx-text-gray-50 hx-w-full hx-break-words" href="#%e6%b1%a0%e5%8c%96%e5%b1%82-pooling">池化层 Pooling
        </a>
      </li>
      <li class="hx-my-2 hx-scroll-my-6 hx-scroll-py-6">
        <a class="hx-font-semibold hx-inline-block hx-text-gray-500 hover:hx-text-gray-900 dark:hx-text-gray-400 dark:hover:hx-text-gray-300 contrast-more:hx-text-gray-900 contrast-more:hx-underline contrast-more:dark:hx-text-gray-50 hx-w-full hx-break-words" href="#the-whole-cnn%e5%85%b8%e5%9e%8b%e5%88%86%e7%b1%bb%e7%bd%91%e7%bb%9c%e7%bb%93%e6%9e%84">The whole CNN（典型分类网络结构）
        </a>
      </li></ul><ul>
      <li class="hx-my-2 hx-scroll-my-6 hx-scroll-py-6">
        <a class="hx-font-semibold hx-inline-block hx-text-gray-500 hover:hx-text-gray-900 dark:hx-text-gray-400 dark:hover:hx-text-gray-300 contrast-more:hx-text-gray-900 contrast-more:hx-underline contrast-more:dark:hx-text-gray-50 hx-w-full hx-break-words" href="#attention">attention
        </a>
      </li>
      <li class="hx-my-2 hx-scroll-my-6 hx-scroll-py-6">
        <a class="hx-font-semibold hx-inline-block hx-text-gray-500 hover:hx-text-gray-900 dark:hx-text-gray-400 dark:hover:hx-text-gray-300 contrast-more:hx-text-gray-900 contrast-more:hx-underline contrast-more:dark:hx-text-gray-50 hx-w-full hx-break-words" href="#self-attention-vs-cnn">Self-attention v.s. CNN
        </a>
      </li>
      <li class="hx-my-2 hx-scroll-my-6 hx-scroll-py-6">
        <a class="hx-font-semibold hx-inline-block hx-text-gray-500 hover:hx-text-gray-900 dark:hx-text-gray-400 dark:hover:hx-text-gray-300 contrast-more:hx-text-gray-900 contrast-more:hx-underline contrast-more:dark:hx-text-gray-50 hx-w-full hx-break-words" href="#self-attention-vs-rnn%e5%be%aa%e7%8e%af%e7%a5%9e%e7%bb%8f%e7%bd%91%e7%bb%9c">Self-attention v.s. RNN（循环神经网络）
        </a>
      </li></ul><ul>
      <li class="hx-my-2 hx-scroll-my-6 hx-scroll-py-6">
        <a class="hx-font-semibold hx-inline-block hx-text-gray-500 hover:hx-text-gray-900 dark:hx-text-gray-400 dark:hover:hx-text-gray-300 contrast-more:hx-text-gray-900 contrast-more:hx-underline contrast-more:dark:hx-text-gray-50 hx-w-full hx-break-words" href="#%e5%ba%94%e7%94%a8">应用
        </a>
      </li>
      <li class="hx-my-2 hx-scroll-my-6 hx-scroll-py-6">
        <a class="hx-font-semibold hx-inline-block hx-text-gray-500 hover:hx-text-gray-900 dark:hx-text-gray-400 dark:hover:hx-text-gray-300 contrast-more:hx-text-gray-900 contrast-more:hx-underline contrast-more:dark:hx-text-gray-50 hx-w-full hx-break-words" href="#%e8%a7%a3%e5%86%b3%e7%9a%84%e9%97%ae%e9%a2%98">解决的问题
        </a>
      </li>
      <li class="hx-my-2 hx-scroll-my-6 hx-scroll-py-6">
        <a class="hx-font-semibold hx-inline-block hx-text-gray-500 hover:hx-text-gray-900 dark:hx-text-gray-400 dark:hover:hx-text-gray-300 contrast-more:hx-text-gray-900 contrast-more:hx-underline contrast-more:dark:hx-text-gray-50 hx-w-full hx-break-words" href="#%e6%9c%ac%e8%b4%a8">本质
        </a>
      </li>
      <li class="hx-my-2 hx-scroll-my-6 hx-scroll-py-6">
        <a class="hx-font-semibold hx-inline-block hx-text-gray-500 hover:hx-text-gray-900 dark:hx-text-gray-400 dark:hover:hx-text-gray-300 contrast-more:hx-text-gray-900 contrast-more:hx-underline contrast-more:dark:hx-text-gray-50 hx-w-full hx-break-words" href="#%e4%bc%98%e7%bc%ba%e7%82%b9">优缺点
        </a>
      </li>
      <li class="hx-my-2 hx-scroll-my-6 hx-scroll-py-6">
        <a class="hx-font-semibold hx-inline-block hx-text-gray-500 hover:hx-text-gray-900 dark:hx-text-gray-400 dark:hover:hx-text-gray-300 contrast-more:hx-text-gray-900 contrast-more:hx-underline contrast-more:dark:hx-text-gray-50 hx-w-full hx-break-words" href="#seq2seq%e5%ba%8f%e5%88%97%e5%88%b0%e5%ba%8f%e5%88%97">Seq2Seq（序列到序列）
        </a>
      </li></ul><ul>
      <li class="hx-my-2 hx-scroll-my-6 hx-scroll-py-6">
        <a class="hx-font-semibold hx-inline-block hx-text-gray-500 hover:hx-text-gray-900 dark:hx-text-gray-400 dark:hover:hx-text-gray-300 contrast-more:hx-text-gray-900 contrast-more:hx-underline contrast-more:dark:hx-text-gray-50 hx-w-full hx-break-words" href="#%e5%ba%94%e7%94%a8-1">应用
        </a>
      </li>
      <li class="hx-my-2 hx-scroll-my-6 hx-scroll-py-6">
        <a class="hx-font-semibold hx-inline-block hx-text-gray-500 hover:hx-text-gray-900 dark:hx-text-gray-400 dark:hover:hx-text-gray-300 contrast-more:hx-text-gray-900 contrast-more:hx-underline contrast-more:dark:hx-text-gray-50 hx-w-full hx-break-words" href="#%e7%bb%93%e6%9e%84">结构
        </a>
      </li>
      <li class="hx-my-2 hx-scroll-my-6 hx-scroll-py-6">
        <a class="hx-font-semibold hx-inline-block hx-text-gray-500 hover:hx-text-gray-900 dark:hx-text-gray-400 dark:hover:hx-text-gray-300 contrast-more:hx-text-gray-900 contrast-more:hx-underline contrast-more:dark:hx-text-gray-50 hx-w-full hx-break-words" href="#%e8%ae%ad%e7%bb%83">训练
        </a>
      </li>
      <li class="hx-my-2 hx-scroll-my-6 hx-scroll-py-6">
        <a class="ltr:hx-pl-4 rtl:hx-pr-4 hx-inline-block hx-text-gray-500 hover:hx-text-gray-900 dark:hx-text-gray-400 dark:hover:hx-text-gray-300 contrast-more:hx-text-gray-900 contrast-more:hx-underline contrast-more:dark:hx-text-gray-50 hx-w-full hx-break-words" href="#%e8%ae%ad%e7%bb%83%e7%9a%84%e9%9a%be%e7%82%b9">训练的难点
        </a>
      </li>
      <li class="hx-my-2 hx-scroll-my-6 hx-scroll-py-6">
        <a class="hx-font-semibold hx-inline-block hx-text-gray-500 hover:hx-text-gray-900 dark:hx-text-gray-400 dark:hover:hx-text-gray-300 contrast-more:hx-text-gray-900 contrast-more:hx-underline contrast-more:dark:hx-text-gray-50 hx-w-full hx-break-words" href="#%e7%94%9f%e6%88%90%e5%99%a8%e8%af%84%e4%bc%b0">生成器评估
        </a>
      </li>
      <li class="hx-my-2 hx-scroll-my-6 hx-scroll-py-6">
        <a class="hx-font-semibold hx-inline-block hx-text-gray-500 hover:hx-text-gray-900 dark:hx-text-gray-400 dark:hover:hx-text-gray-300 contrast-more:hx-text-gray-900 contrast-more:hx-underline contrast-more:dark:hx-text-gray-50 hx-w-full hx-break-words" href="#%e4%b8%be%e4%be%8b">举例
        </a>
      </li>
      <li class="hx-my-2 hx-scroll-my-6 hx-scroll-py-6">
        <a class="ltr:hx-pl-4 rtl:hx-pr-4 hx-inline-block hx-text-gray-500 hover:hx-text-gray-900 dark:hx-text-gray-400 dark:hover:hx-text-gray-300 contrast-more:hx-text-gray-900 contrast-more:hx-underline contrast-more:dark:hx-text-gray-50 hx-w-full hx-break-words" href="#case-1text-to-image">Case 1:Text-to-image
        </a>
      </li>
      <li class="hx-my-2 hx-scroll-my-6 hx-scroll-py-6">
        <a class="ltr:hx-pl-4 rtl:hx-pr-4 hx-inline-block hx-text-gray-500 hover:hx-text-gray-900 dark:hx-text-gray-400 dark:hover:hx-text-gray-300 contrast-more:hx-text-gray-900 contrast-more:hx-underline contrast-more:dark:hx-text-gray-50 hx-w-full hx-break-words" href="#case-2image-translationpix2pix">Case 2：Image Translation（pix2pix）
        </a>
      </li>
      <li class="hx-my-2 hx-scroll-my-6 hx-scroll-py-6">
        <a class="ltr:hx-pl-4 rtl:hx-pr-4 hx-inline-block hx-text-gray-500 hover:hx-text-gray-900 dark:hx-text-gray-400 dark:hover:hx-text-gray-300 contrast-more:hx-text-gray-900 contrast-more:hx-underline contrast-more:dark:hx-text-gray-50 hx-w-full hx-break-words" href="#case-3%e5%a3%b0%e9%9f%b3-%e5%9b%be%e7%89%87">Case 3：声音-图片
        </a>
      </li>
      <li class="hx-my-2 hx-scroll-my-6 hx-scroll-py-6">
        <a class="ltr:hx-pl-4 rtl:hx-pr-4 hx-inline-block hx-text-gray-500 hover:hx-text-gray-900 dark:hx-text-gray-400 dark:hover:hx-text-gray-300 contrast-more:hx-text-gray-900 contrast-more:hx-underline contrast-more:dark:hx-text-gray-50 hx-w-full hx-break-words" href="#case-4-%e4%ba%a7%e7%94%9f%e4%bc%9a%e5%8a%a8%e7%9a%84%e4%ba%ba%e5%83%8f">Case 4： 产生会动的人像
        </a>
      </li></ul><ul>
      <li class="hx-my-2 hx-scroll-my-6 hx-scroll-py-6">
        <a class="hx-font-semibold hx-inline-block hx-text-gray-500 hover:hx-text-gray-900 dark:hx-text-gray-400 dark:hover:hx-text-gray-300 contrast-more:hx-text-gray-900 contrast-more:hx-underline contrast-more:dark:hx-text-gray-50 hx-w-full hx-break-words" href="#masking-input">Masking Input
        </a>
      </li>
      <li class="hx-my-2 hx-scroll-my-6 hx-scroll-py-6">
        <a class="hx-font-semibold hx-inline-block hx-text-gray-500 hover:hx-text-gray-900 dark:hx-text-gray-400 dark:hover:hx-text-gray-300 contrast-more:hx-text-gray-900 contrast-more:hx-underline contrast-more:dark:hx-text-gray-50 hx-w-full hx-break-words" href="#%e8%af%84%e4%bb%b7%e4%bb%bb%e5%8a%a1%e9%9b%86glue">评价任务集——GLUE
        </a>
      </li></ul>
      <div class="hx-mt-8 hx-border-t hx-bg-white hx-pt-8 hx-shadow-[0_-12px_16px_white] dark:hx-bg-dark dark:hx-shadow-[0_-12px_16px_#111] hx-sticky hx-bottom-0 hx-flex hx-flex-col hx-items-start hx-gap-2 hx-pb-8 dark:hx-border-neutral-800 contrast-more:hx-border-t contrast-more:hx-border-neutral-400 contrast-more:hx-shadow-none contrast-more:dark:hx-border-neutral-400">
        <button aria-hidden="true" id="backToTop" onClick="scrollUp();" class="hx-transition-all hx-duration-75 hx-opacity-0 hx-text-xs hx-font-medium hx-text-gray-500 hover:hx-text-gray-900 dark:hx-text-gray-400 dark:hover:hx-text-gray-100 contrast-more:hx-text-gray-800 contrast-more:dark:hx-text-gray-50">
          <span>Scroll to top</span>
          <svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" class="hx-inline ltr:hx-ml-1 rtl:hx-mr-1 hx-h-3.5 hx-w-3.5 hx-border hx-rounded-full hx-border-gray-500 hover:hx-border-gray-900 dark:hx-border-gray-400 dark:hover:hx-border-gray-100 contrast-more:hx-border-gray-800 contrast-more:dark:hx-border-gray-50">
            <path stroke-linecap="round" stroke-linejoin="round" d="M4.5 15.75l7.5-7.5 7.5 7.5" />
          </svg>
        </button>
      </div>
    </div>
  </nav>


    <article class="hx-w-full hx-break-words hx-flex hx-min-h-[calc(100vh-var(--navbar-height))] hx-min-w-0 hx-justify-center hx-pb-8 hx-pr-[calc(env(safe-area-inset-right)-1.5rem)]">
      <main class="hx-w-full hx-min-w-0 hx-max-w-6xl hx-px-6 hx-pt-4 md:hx-px-12">
        
  <div class="hx-mt-1.5 hx-flex hx-items-center hx-gap-1 hx-overflow-hidden hx-text-sm hx-text-gray-500 dark:hx-text-gray-400 contrast-more:hx-text-current">
        <div class="hx-whitespace-nowrap hx-transition-colors hx-min-w-[24px] hx-overflow-hidden hx-text-ellipsis hover:hx-text-gray-900 dark:hover:hx-text-gray-100">
          <a href="/docs/">Docs</a>
        </div><svg class="hx-w-3.5 hx-shrink-0 rtl:-hx-rotate-180" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" aria-hidden="true"><path stroke-linecap="round" stroke-linejoin="round" d="M9 5l7 7-7 7"/></svg><div class="hx-whitespace-nowrap hx-transition-colors hx-font-medium hx-text-gray-700 contrast-more:hx-font-bold contrast-more:hx-text-current dark:hx-text-gray-100 contrast-more:dark:hx-text-current">Deeplearning</div>
  </div>

        <div class="content">
          <h1>Deeplearning</h1>
          <h1>网络模型</h1><h2>LeNet<span class="hx-absolute -hx-mt-20" id="lenet"></span>
    <a href="#lenet" class="subheading-anchor" aria-label="Permalink for this section"></a></h2><p>它是最早发布的卷积神经网络之一，因其在计算机视觉任务中的高效性能而受到广泛关注。 这个模型是由AT&amp;T贝尔实验室的研究员Yann LeCun在1989年提出的（并以其命名），目的是识别图像 <code>LeCun.Bottou.Bengio.ea.1998</code>中的手写数字。 当时，Yann LeCun发表了第一篇通过反向传播成功训练卷积神经网络的研究，这项工作代表了十多年来神经网络研究开发的成果。</p>
<p>总体来看，(<strong>LeNet（LeNet-5）由两个部分组成：</strong>)(卷积编码器和全连接层密集块)</p>
<ul>
<li>卷积编码器：由两个卷积层组成;</li>
<li>全连接层密集块：由三个全连接层组成。</li>
</ul>
<p><code>架构图</code></p>
<img src="https://zh-v2.d2l.ai/_images/lenet.svg" alt="../_images/lenet.svg" style="zoom: 50%;" />
<div class="hextra-code-block hx-relative hx-mt-6 first:hx-mt-0 hx-group/code">
  

<div><div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="c1"># 网络结构</span>
</span></span><span class="line"><span class="cl"><span class="n">net</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">    	<span class="n">nn</span><span class="o">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="n">channels</span><span class="o">=</span><span class="mi">6</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;sigmoid&#39;</span><span class="p">),</span>
</span></span><span class="line"><span class="cl">        <span class="n">nn</span><span class="o">.</span><span class="n">AvgPool2D</span><span class="p">(</span><span class="n">pool_size</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">strides</span><span class="o">=</span><span class="mi">2</span><span class="p">),</span>
</span></span><span class="line"><span class="cl">        <span class="n">nn</span><span class="o">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="n">channels</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;sigmoid&#39;</span><span class="p">),</span>
</span></span><span class="line"><span class="cl">        <span class="n">nn</span><span class="o">.</span><span class="n">AvgPool2D</span><span class="p">(</span><span class="n">pool_size</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">strides</span><span class="o">=</span><span class="mi">2</span><span class="p">),</span>
</span></span><span class="line"><span class="cl">        <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">16</span> <span class="o">*</span> <span class="mi">5</span> <span class="o">*</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">120</span><span class="p">),</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sigmoid</span><span class="p">(),</span>
</span></span><span class="line"><span class="cl">    	<span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">120</span><span class="p">,</span> <span class="mi">84</span><span class="p">),</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sigmoid</span><span class="p">(),</span>
</span></span><span class="line"><span class="cl">    	<span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">84</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span></span></span></code></pre></div></div><div class="hextra-code-copy-btn-container hx-opacity-0 hx-transition group-hover/code:hx-opacity-100 hx-flex hx-gap-1 hx-absolute hx-m-[11px] hx-right-0 hx-top-0">
  <button
    class="hextra-code-copy-btn hx-group/copybtn hx-transition-all active:hx-opacity-50 hx-bg-primary-700/5 hx-border hx-border-black/5 hx-text-gray-600 hover:hx-text-gray-900 hx-rounded-md hx-p-1.5 dark:hx-bg-primary-300/10 dark:hx-border-white/10 dark:hx-text-gray-400 dark:hover:hx-text-gray-50"
    title="Copy code"
  >
    <div class="copy-icon group-[.copied]/copybtn:hx-hidden hx-pointer-events-none hx-h-4 hx-w-4"></div>
    <div class="success-icon hx-hidden group-[.copied]/copybtn:hx-block hx-pointer-events-none hx-h-4 hx-w-4"></div>
  </button>
</div>

  
</div>
<p><code>小结</code></p>
<ul>
<li>卷积神经网络（CNN）是一类使用卷积层的网络。</li>
<li>在卷积神经网络中，我们组合使用卷积层、非线性激活函数和汇聚层。</li>
<li>为了构造高性能的卷积神经网络，我们通常对卷积层进行排列，逐渐降低其表示的空间分辨率，同时增加通道数。</li>
<li>在传统的卷积神经网络中，卷积块编码得到的表征在输出之前需由一个或多个全连接层进行处理。</li>
<li>LeNet是最早发布的卷积神经网络之一。</li>
</ul>
<h2>AlexNet<span class="hx-absolute -hx-mt-20" id="alexnet"></span>
    <a href="#alexnet" class="subheading-anchor" aria-label="Permalink for this section"></a></h2><p><code>对比及改进</code></p>
<ul>
<li>更深更大的LeNet</li>
<li>主要改进：
<ul>
<li>丢弃法（dropout）</li>
<li>ReLU</li>
<li>MaxPooling</li>
<li>数据增强</li>
</ul>
</li>
<li>计算机视觉方法论的改变</li>
</ul>
<p>2012年，AlexNet横空出世。它首次证明了学习到的特征可以超越手工设计的特征。它一举打破了计算机视觉研究的现状。 AlexNet使用了8层卷积神经网络，并以很大的优势赢得了2012年ImageNet图像识别挑战赛。</p>
<p>AlexNet和LeNet的架构非常相似，注意，这里我们提供了一个稍微精简版本的AlexNet，去除了当年需要两个小型GPU同时运算的设计特点。</p>
<p><code>架构图</code></p>
<img src="https://zh-v2.d2l.ai/_images/alexnet.svg" alt="../_images/alexnet.svg" style="zoom:67%;" />
<p>AlexNet和LeNet的设计理念非常相似，但也存在显著差异。 首先，AlexNet比相对较小的LeNet5要深得多。 AlexNet由八层组成：五个卷积层、两个全连接隐藏层和一个全连接输出层。 其次，AlexNet使用ReLU而不是sigmoid作为其激活函数。</p>
<div class="hextra-code-block hx-relative hx-mt-6 first:hx-mt-0 hx-group/code">
  

<div><div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="c1"># 网络结构</span>
</span></span><span class="line"><span class="cl"><span class="n">net</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># 这里，我们使用一个11*11的更大窗口来捕捉对象。</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># 同时，步幅为4，以减少输出的高度和宽度。</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># 另外，输出通道的数目远大于LeNet</span>
</span></span><span class="line"><span class="cl">    <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">96</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">11</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
</span></span><span class="line"><span class="cl">    <span class="n">nn</span><span class="o">.</span><span class="n">MaxPool2d</span><span class="p">(</span><span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">),</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># 减小卷积窗口，使用填充为2来使得输入与输出的高和宽一致，且增大输出通道数</span>
</span></span><span class="line"><span class="cl">    <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">96</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">2</span><span class="p">),</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
</span></span><span class="line"><span class="cl">    <span class="n">nn</span><span class="o">.</span><span class="n">MaxPool2d</span><span class="p">(</span><span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">),</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># 使用三个连续的卷积层和较小的卷积窗口。</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># 除了最后的卷积层，输出通道的数量进一步增加。</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># 在前两个卷积层之后，汇聚层不用于减少输入的高度和宽度</span>
</span></span><span class="line"><span class="cl">    <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="mi">384</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
</span></span><span class="line"><span class="cl">    <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">384</span><span class="p">,</span> <span class="mi">384</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
</span></span><span class="line"><span class="cl">    <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">384</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
</span></span><span class="line"><span class="cl">    <span class="n">nn</span><span class="o">.</span><span class="n">MaxPool2d</span><span class="p">(</span><span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">),</span>
</span></span><span class="line"><span class="cl">    <span class="n">nn</span><span class="o">.</span><span class="n">Flatten</span><span class="p">(),</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># 这里，全连接层的输出数量是LeNet中的好几倍。使用dropout层来减轻过拟合</span>
</span></span><span class="line"><span class="cl">    <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">6400</span><span class="p">,</span> <span class="mi">4096</span><span class="p">),</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
</span></span><span class="line"><span class="cl">    <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="mf">0.5</span><span class="p">),</span>
</span></span><span class="line"><span class="cl">    <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">4096</span><span class="p">,</span> <span class="mi">4096</span><span class="p">),</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
</span></span><span class="line"><span class="cl">    <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="mf">0.5</span><span class="p">),</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># 最后是输出层。由于这里使用Fashion-MNIST，所以用类别数为10，而非论文中的1000</span>
</span></span><span class="line"><span class="cl">    <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">4096</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span></span></span></code></pre></div></div><div class="hextra-code-copy-btn-container hx-opacity-0 hx-transition group-hover/code:hx-opacity-100 hx-flex hx-gap-1 hx-absolute hx-m-[11px] hx-right-0 hx-top-0">
  <button
    class="hextra-code-copy-btn hx-group/copybtn hx-transition-all active:hx-opacity-50 hx-bg-primary-700/5 hx-border hx-border-black/5 hx-text-gray-600 hover:hx-text-gray-900 hx-rounded-md hx-p-1.5 dark:hx-bg-primary-300/10 dark:hx-border-white/10 dark:hx-text-gray-400 dark:hover:hx-text-gray-50"
    title="Copy code"
  >
    <div class="copy-icon group-[.copied]/copybtn:hx-hidden hx-pointer-events-none hx-h-4 hx-w-4"></div>
    <div class="success-icon hx-hidden group-[.copied]/copybtn:hx-block hx-pointer-events-none hx-h-4 hx-w-4"></div>
  </button>
</div>

  
</div>
<p><code>小结</code></p>
<ul>
<li>AlexNet的架构与LeNet相似，但使用了更多的卷积层和更多的参数来拟合大规模的ImageNet数据集。</li>
<li>今天，AlexNet已经被更有效的架构所超越，但它是从浅层网络到深层网络的关键一步。</li>
<li>尽管AlexNet的代码只比LeNet多出几行，但学术界花了很多年才接受深度学习这一概念，并应用其出色的实验结果。这也是由于缺乏有效的计算工具。</li>
<li>Dropout、ReLU和预处理是提升计算机视觉任务性能的其他关键步骤。</li>
</ul>
<h2>VGGNet<span class="hx-absolute -hx-mt-20" id="vggnet"></span>
    <a href="#vggnet" class="subheading-anchor" aria-label="Permalink for this section"></a></h2><p><code>对比及改进</code></p>
<ul>
<li>更大更深的AlexNet（重复的VGG块）</li>
</ul>
<p>与AlexNet、LeNet一样，VGG网络可以分为两部分：第一部分主要由卷积层和汇聚层组成，第二部分由全连接层组成。</p>
<p><code>架构图</code></p>
<img src="https://zh-v2.d2l.ai/_images/vgg.svg" alt="../_images/vgg.svg" style="zoom:67%;" />
<ul>
<li>多个VGG块后接全连接层</li>
<li>不同次数的重复块得到不同的架构 VGG-16，VGG-19</li>
</ul>
<div class="hextra-code-block hx-relative hx-mt-6 first:hx-mt-0 hx-group/code">
  

<div><div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="c1"># vgg块</span>
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">vgg_block</span><span class="p">(</span><span class="n">num_convs</span><span class="p">,</span> <span class="n">in_channels</span><span class="p">,</span> <span class="n">out_channels</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="n">layers</span> <span class="o">=</span> <span class="p">[]</span>
</span></span><span class="line"><span class="cl">    <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_convs</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">in_channels</span><span class="p">,</span> <span class="n">out_channels</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                                <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">        <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">())</span>
</span></span><span class="line"><span class="cl">        <span class="n">in_channels</span> <span class="o">=</span> <span class="n">out_channels</span>
</span></span><span class="line"><span class="cl">    <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">MaxPool2d</span><span class="p">(</span><span class="n">kernel_size</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span><span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="o">*</span><span class="n">layers</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="c1"># 模型</span>
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">vgg</span><span class="p">(</span><span class="n">conv_arch</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="n">conv_blks</span> <span class="o">=</span> <span class="p">[]</span>
</span></span><span class="line"><span class="cl">    <span class="n">in_channels</span> <span class="o">=</span> <span class="mi">1</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># 卷积层部分</span>
</span></span><span class="line"><span class="cl">    <span class="k">for</span> <span class="p">(</span><span class="n">num_convs</span><span class="p">,</span> <span class="n">out_channels</span><span class="p">)</span> <span class="ow">in</span> <span class="n">conv_arch</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">        <span class="n">conv_blks</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">vgg_block</span><span class="p">(</span><span class="n">num_convs</span><span class="p">,</span> <span class="n">in_channels</span><span class="p">,</span> <span class="n">out_channels</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">        <span class="n">in_channels</span> <span class="o">=</span> <span class="n">out_channels</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">        <span class="o">*</span><span class="n">conv_blks</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">Flatten</span><span class="p">(),</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># 全连接层部分</span>
</span></span><span class="line"><span class="cl">        <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">out_channels</span> <span class="o">*</span> <span class="mi">7</span> <span class="o">*</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">4096</span><span class="p">),</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="mf">0.5</span><span class="p">),</span>
</span></span><span class="line"><span class="cl">        <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">4096</span><span class="p">,</span> <span class="mi">4096</span><span class="p">),</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="mf">0.5</span><span class="p">),</span>
</span></span><span class="line"><span class="cl">        <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">4096</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">net</span> <span class="o">=</span> <span class="n">vgg</span><span class="p">(</span><span class="n">conv_arch</span><span class="p">)</span></span></span></code></pre></div></div><div class="hextra-code-copy-btn-container hx-opacity-0 hx-transition group-hover/code:hx-opacity-100 hx-flex hx-gap-1 hx-absolute hx-m-[11px] hx-right-0 hx-top-0">
  <button
    class="hextra-code-copy-btn hx-group/copybtn hx-transition-all active:hx-opacity-50 hx-bg-primary-700/5 hx-border hx-border-black/5 hx-text-gray-600 hover:hx-text-gray-900 hx-rounded-md hx-p-1.5 dark:hx-bg-primary-300/10 dark:hx-border-white/10 dark:hx-text-gray-400 dark:hover:hx-text-gray-50"
    title="Copy code"
  >
    <div class="copy-icon group-[.copied]/copybtn:hx-hidden hx-pointer-events-none hx-h-4 hx-w-4"></div>
    <div class="success-icon hx-hidden group-[.copied]/copybtn:hx-block hx-pointer-events-none hx-h-4 hx-w-4"></div>
  </button>
</div>

  
</div>
<p><code>小结</code></p>
<ul>
<li>VGG-11使用可复用的卷积块构造网络。不同的VGG模型可通过每个块中卷积层数量和输出通道数量的差异来定义。</li>
<li>块的使用导致网络定义的非常简洁。使用块可以有效地设计复杂的网络。</li>
<li>在VGG论文中，Simonyan和Ziserman尝试了各种架构。特别是他们发现深层且窄的卷积（即3×3）比较浅层且宽的卷积更有效。</li>
</ul>
<h2>NiN<span class="hx-absolute -hx-mt-20" id="nin"></span>
    <a href="#nin" class="subheading-anchor" aria-label="Permalink for this section"></a></h2><p><code>网络中的网络</code></p>
<p>LeNet、AlexNet和VGG都有一个共同的设计模式：</p>
<ul>
<li>通过一系列的卷积层与汇聚层来提取空间结构特征；</li>
<li>然后通过全连接层对特征的表征进行处理。</li>
</ul>
<p>AlexNet和VGG对LeNet的改进主要在于如何扩大和加深这两个模块。 或者，可以想象在这个过程的早期使用全连接层。然而，如果使用了全连接层，可能会完全放弃表征的空间结构。</p>
<p><em>网络中的网络</em>（<em>NiN</em>）提供了一个非常简单的解决方案：<strong>在每个像素的通道上分别使用多层感知机</strong></p>
<p><code>架构图</code></p>
<img src="https://zh-v2.d2l.ai/_images/nin.svg" alt="../_images/nin.svg" style="zoom:67%;" />
<p>==NiN块==</p>
<ul>
<li>一个卷积层后跟两个FC
<ul>
<li>步幅1，无填充，输出形状和卷积层输出一样</li>
<li>充当全连接层</li>
</ul>
</li>
</ul>
<p><code>架构</code></p>
<ul>
<li>无全连接层</li>
<li>交替使用NiN块和步幅为2的MaxPooling
<ul>
<li>逐步减小高宽和增大通道数</li>
</ul>
</li>
<li>最后使用 全局平均池化得到输出
<ul>
<li>其输入通道数是类别数</li>
</ul>
</li>
</ul>
<p><code>对比及改进</code></p>
<ul>
<li>NiN和AlexNet之间的一个显著区别是NiN完全取消了全连接层。</li>
<li>相反，NiN使用一个NiN块，其输出通道数等于标签类别的数量。最后放一个<em>全局平均汇聚层</em>（global average pooling layer），生成一个对数几率 （logits）。</li>
<li>NiN设计的一个优点是，它显著减少了模型所需参数的数量。然而，在实践中，这种设计有时会增加训练模型的时间。</li>
</ul>
<div class="hextra-code-block hx-relative hx-mt-6 first:hx-mt-0 hx-group/code">
  

<div><div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="c1"># 网络结构</span>
</span></span><span class="line"><span class="cl"><span class="c1"># NiN块</span>
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">nin_block</span><span class="p">(</span><span class="n">in_channels</span><span class="p">,</span> <span class="n">out_channels</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">strides</span><span class="p">,</span> <span class="n">padding</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">        <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">in_channels</span><span class="p">,</span> <span class="n">out_channels</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">strides</span><span class="p">,</span> <span class="n">padding</span><span class="p">),</span>
</span></span><span class="line"><span class="cl">        <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
</span></span><span class="line"><span class="cl">        <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">out_channels</span><span class="p">,</span> <span class="n">out_channels</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
</span></span><span class="line"><span class="cl">        <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">out_channels</span><span class="p">,</span> <span class="n">out_channels</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">())</span>
</span></span><span class="line"><span class="cl"><span class="c1"># 模型</span>
</span></span><span class="line"><span class="cl"><span class="n">net</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">    <span class="n">nin_block</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">96</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">11</span><span class="p">,</span> <span class="n">strides</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">0</span><span class="p">),</span>
</span></span><span class="line"><span class="cl">    <span class="n">nn</span><span class="o">.</span><span class="n">MaxPool2d</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">),</span>
</span></span><span class="line"><span class="cl">    <span class="n">nin_block</span><span class="p">(</span><span class="mi">96</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">strides</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">2</span><span class="p">),</span>
</span></span><span class="line"><span class="cl">    <span class="n">nn</span><span class="o">.</span><span class="n">MaxPool2d</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">),</span>
</span></span><span class="line"><span class="cl">    <span class="n">nin_block</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="mi">384</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">strides</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>
</span></span><span class="line"><span class="cl">    <span class="n">nn</span><span class="o">.</span><span class="n">MaxPool2d</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">),</span>
</span></span><span class="line"><span class="cl">    <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="mf">0.5</span><span class="p">),</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># 标签类别数是10</span>
</span></span><span class="line"><span class="cl">    <span class="n">nin_block</span><span class="p">(</span><span class="mi">384</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">strides</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>
</span></span><span class="line"><span class="cl">    <span class="n">nn</span><span class="o">.</span><span class="n">AdaptiveAvgPool2d</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)),</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># 将四维的输出转成二维的输出，其形状为(批量大小,10)</span>
</span></span><span class="line"><span class="cl">    <span class="n">nn</span><span class="o">.</span><span class="n">Flatten</span><span class="p">())</span></span></span></code></pre></div></div><div class="hextra-code-copy-btn-container hx-opacity-0 hx-transition group-hover/code:hx-opacity-100 hx-flex hx-gap-1 hx-absolute hx-m-[11px] hx-right-0 hx-top-0">
  <button
    class="hextra-code-copy-btn hx-group/copybtn hx-transition-all active:hx-opacity-50 hx-bg-primary-700/5 hx-border hx-border-black/5 hx-text-gray-600 hover:hx-text-gray-900 hx-rounded-md hx-p-1.5 dark:hx-bg-primary-300/10 dark:hx-border-white/10 dark:hx-text-gray-400 dark:hover:hx-text-gray-50"
    title="Copy code"
  >
    <div class="copy-icon group-[.copied]/copybtn:hx-hidden hx-pointer-events-none hx-h-4 hx-w-4"></div>
    <div class="success-icon hx-hidden group-[.copied]/copybtn:hx-block hx-pointer-events-none hx-h-4 hx-w-4"></div>
  </button>
</div>

  
</div>
<p><code>总结</code></p>
<ul>
<li>NiN使用由一个卷积层和多个1×1卷积层组成的块。该块可以在卷积神经网络中使用，以允许更多的每像素非线性。</li>
<li>NiN去除了容易造成过拟合的全连接层，将它们替换为全局平均汇聚层（即在所有位置上进行求和）。该汇聚层通道数量为所需的输出数量（例如，Fashion-MNIST的输出为10）。</li>
<li>移除全连接层可减少过拟合，同时显著减少NiN的参数。</li>
<li>NiN的设计影响了许多后续卷积神经网络的设计。</li>
</ul>
<h2>GoogLeNet<span class="hx-absolute -hx-mt-20" id="googlenet"></span>
    <a href="#googlenet" class="subheading-anchor" aria-label="Permalink for this section"></a></h2><p><code>对比及改进</code></p>
<ul>
<li>这篇论文的一个重点是<strong>解决了什么样大小的卷积核最合适的问题</strong></li>
</ul>
<p><code>Inception块</code></p>
<p>在GoogLeNet中，基本的卷积块被称为<em>Inception块</em></p>
<p>下图中，蓝色1×1卷积 为抽取信息；白色1×1卷积为 改变通道数，减少通道数，降维，降低模型复杂性</p>
<img src="https://zh-v2.d2l.ai/_images/inception.svg" alt="../_images/inception.svg" style="zoom: 80%;" />
<p><code>架构</code></p>
<ul>
<li>GoogLeNet一共使用9个Inception块和全局平均汇聚层的堆叠来生成其估计值。</li>
<li>Inception块之间的最大汇聚层可降低维度。 第一个模块类似于AlexNet和LeNet，Inception块的组合从VGG继承，全局平均汇聚层避免了在最后使用全连接层。</li>
</ul>
<img src="https://zh-v2.d2l.ai/_images/inception-full.svg" alt="../_images/inception-full.svg" style="zoom:80%;" />
<p><code>小结</code></p>
<ul>
<li>Inception块相当于一个有4条路径的子网络。它通过不同窗口形状的卷积层和最大汇聚层来并行抽取信息
<ul>
<li>并使用1×1卷积层<strong>减少</strong>每像素级别上的<strong>通道维数</strong>从而<strong>降低模型复杂度</strong>，<strong>模型参数小</strong>。</li>
</ul>
</li>
<li>GoogLeNet将多个设计精细的Inception块与其他层（卷积层、全连接层）串联起来。其中Inception块的通道数分配之比是在ImageNet数据集上通过大量的实验得来的。</li>
<li>GoogLeNet和它的后继者们一度是ImageNet上最有效的模型之一：它以较低的计算复杂度提供了类似的测试精度。</li>
</ul>
<h2>ResNet<span class="hx-absolute -hx-mt-20" id="resnet"></span>
    <a href="#resnet" class="subheading-anchor" aria-label="Permalink for this section"></a></h2><blockquote>
<p>残差网络的核心思想是：<strong>每个附加层都应该更容易地包含原始函数作为其元素之一</strong>。 于是，<em>残差块</em>（residual blocks）便诞生了，这个设计对如何建立深层神经网络产生了深远的影响。 凭借它，ResNet赢得了2015年ImageNet大规模视觉识别挑战赛。</p>
</blockquote>
<p><code>残差块</code></p>
<ul>
<li>串联一个层改变函数类，我们希望扩大函数类</li>
<li>残差块加入快速通道（右边）来得到 f(x) = x + g(x)的结构</li>
</ul>
<p>右图是ResNet的基础架构–<em>残差块</em>（residual block）。 在残差块中，输入可通过跨层数据线路更快地向前传播。</p>
<img src="https://zh-v2.d2l.ai/_images/residual-block.svg" alt="../_images/residual-block.svg" style="zoom:67%;" />
<div class="hextra-code-block hx-relative hx-mt-6 first:hx-mt-0 hx-group/code">
  

<div><div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="k">class</span> <span class="nc">Residual</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>  <span class="c1">#@save</span>
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_channels</span><span class="p">,</span> <span class="n">num_channels</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                 <span class="n">use_1x1conv</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">strides</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">input_channels</span><span class="p">,</span> <span class="n">num_channels</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                               <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="n">strides</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">conv2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">num_channels</span><span class="p">,</span> <span class="n">num_channels</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                               <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># 1 × 1卷积，改变通道数</span>
</span></span><span class="line"><span class="cl">        <span class="k">if</span> <span class="n">use_1x1conv</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="bp">self</span><span class="o">.</span><span class="n">conv3</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">input_channels</span><span class="p">,</span> <span class="n">num_channels</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                                   <span class="n">kernel_size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="n">strides</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="k">else</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="bp">self</span><span class="o">.</span><span class="n">conv3</span> <span class="o">=</span> <span class="kc">None</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">bn1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm2d</span><span class="p">(</span><span class="n">num_channels</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">bn2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm2d</span><span class="p">(</span><span class="n">num_channels</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="n">Y</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">bn1</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">conv1</span><span class="p">(</span><span class="n">X</span><span class="p">)))</span>
</span></span><span class="line"><span class="cl">        <span class="n">Y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">bn2</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">conv2</span><span class="p">(</span><span class="n">Y</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv3</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="n">X</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv3</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">Y</span> <span class="o">+=</span> <span class="n">X</span>
</span></span><span class="line"><span class="cl">        <span class="k">return</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">Y</span><span class="p">)</span></span></span></code></pre></div></div><div class="hextra-code-copy-btn-container hx-opacity-0 hx-transition group-hover/code:hx-opacity-100 hx-flex hx-gap-1 hx-absolute hx-m-[11px] hx-right-0 hx-top-0">
  <button
    class="hextra-code-copy-btn hx-group/copybtn hx-transition-all active:hx-opacity-50 hx-bg-primary-700/5 hx-border hx-border-black/5 hx-text-gray-600 hover:hx-text-gray-900 hx-rounded-md hx-p-1.5 dark:hx-bg-primary-300/10 dark:hx-border-white/10 dark:hx-text-gray-400 dark:hover:hx-text-gray-50"
    title="Copy code"
  >
    <div class="copy-icon group-[.copied]/copybtn:hx-hidden hx-pointer-events-none hx-h-4 hx-w-4"></div>
    <div class="success-icon hx-hidden group-[.copied]/copybtn:hx-block hx-pointer-events-none hx-h-4 hx-w-4"></div>
  </button>
</div>

  
</div>
<p><code>块细节</code></p>
<ul>
<li>ResNet沿用了VGG完整的3×3卷积层设计。</li>
<li>每个卷积层后接一个批量规范化层和ReLU激活函数。</li>
</ul>
<p>如图，此代码生成两种类型的网络： 一种是当<code>use_1x1conv=False</code>时，应用ReLU非线性函数之前，将输入添加到输出。 另一种是当<code>use_1x1conv=True</code>时，添加通过1×1卷积调整通道和分辨率。</p>
<img src="https://zh-v2.d2l.ai/_images/resnet-block.svg" alt="../_images/resnet-block.svg" style="zoom:67%;" />
<div class="hextra-code-block hx-relative hx-mt-6 first:hx-mt-0 hx-group/code">
  

<div><div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">resnet_block</span><span class="p">(</span><span class="n">input_channels</span><span class="p">,</span> <span class="n">num_channels</span><span class="p">,</span> <span class="n">num_residuals</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                 <span class="n">first_block</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="n">blk</span> <span class="o">=</span> <span class="p">[]</span>
</span></span><span class="line"><span class="cl">    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_residuals</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="k">if</span> <span class="n">i</span> <span class="o">==</span> <span class="mi">0</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">first_block</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="n">blk</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">Residual</span><span class="p">(</span><span class="n">input_channels</span><span class="p">,</span> <span class="n">num_channels</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                                <span class="n">use_1x1conv</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">strides</span><span class="o">=</span><span class="mi">2</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">        <span class="k">else</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="n">blk</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">Residual</span><span class="p">(</span><span class="n">num_channels</span><span class="p">,</span> <span class="n">num_channels</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="n">blk</span></span></span></code></pre></div></div><div class="hextra-code-copy-btn-container hx-opacity-0 hx-transition group-hover/code:hx-opacity-100 hx-flex hx-gap-1 hx-absolute hx-m-[11px] hx-right-0 hx-top-0">
  <button
    class="hextra-code-copy-btn hx-group/copybtn hx-transition-all active:hx-opacity-50 hx-bg-primary-700/5 hx-border hx-border-black/5 hx-text-gray-600 hover:hx-text-gray-900 hx-rounded-md hx-p-1.5 dark:hx-bg-primary-300/10 dark:hx-border-white/10 dark:hx-text-gray-400 dark:hover:hx-text-gray-50"
    title="Copy code"
  >
    <div class="copy-icon group-[.copied]/copybtn:hx-hidden hx-pointer-events-none hx-h-4 hx-w-4"></div>
    <div class="success-icon hx-hidden group-[.copied]/copybtn:hx-block hx-pointer-events-none hx-h-4 hx-w-4"></div>
  </button>
</div>

  
</div>
<p><code>架构</code></p>
<ul>
<li>类似VGG和GoogLeNet的总体架构</li>
<li>Inception块替换成了ResNet块</li>
</ul>
<p>下图为ResNet-18 架构</p>
<img src="https://zh-v2.d2l.ai/_images/resnet18.svg" alt="../_images/resnet18.svg" style="zoom:67%;" />
<p><code>小结</code></p>
<ul>
<li>残差映射可以更容易地学习同一函数，例如将权重层中的参数近似为零。</li>
<li>利用残差块（residual blocks）可以训练出一个有效的深层神经网络
<ul>
<li>甚至可以训练一千层的网络</li>
<li>输入可以通过层间的残余连接更快地向前传播。</li>
</ul>
</li>
</ul>
<h1>计算机视觉（CV）</h1><h2>数据增强<span class="hx-absolute -hx-mt-20" id="数据增强"></span>
    <a href="#%e6%95%b0%e6%8d%ae%e5%a2%9e%e5%bc%ba" class="subheading-anchor" aria-label="Permalink for this section"></a></h2><p>大多数图像增广方法都具有一定的随机性。为了便于观察图像增广的效果，我们下面定义辅助函数<code>apply</code>。 此函数在输入图像<code>img</code>上多次运行图像增广方法<code>aug</code>并显示所有结果。</p>
<div class="hextra-code-block hx-relative hx-mt-6 first:hx-mt-0 hx-group/code">
  

<div><div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">apply</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">aug</span><span class="p">,</span> <span class="n">num_rows</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">num_cols</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="mf">1.5</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="n">Y</span> <span class="o">=</span> <span class="p">[</span><span class="n">aug</span><span class="p">(</span><span class="n">img</span><span class="p">)</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_rows</span> <span class="o">*</span> <span class="n">num_cols</span><span class="p">)]</span>
</span></span><span class="line"><span class="cl">    <span class="n">d2l</span><span class="o">.</span><span class="n">show_images</span><span class="p">(</span><span class="n">Y</span><span class="p">,</span> <span class="n">num_rows</span><span class="p">,</span> <span class="n">num_cols</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">scale</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    
</span></span><span class="line"><span class="cl"><span class="c1"># 水平方向随机反转</span>
</span></span><span class="line"><span class="cl"><span class="n">apply</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">torchvision</span><span class="o">.</span><span class="n">transforms</span><span class="o">.</span><span class="n">RandomHorizontalFlip</span><span class="p">())</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># 垂直翻转</span>
</span></span><span class="line"><span class="cl"><span class="n">apply</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">torchvision</span><span class="o">.</span><span class="n">transforms</span><span class="o">.</span><span class="n">RandomVerticalFlip</span><span class="p">())</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># 随机取部分并调整至规定大小</span>
</span></span><span class="line"><span class="cl"><span class="n">shape_aug</span> <span class="o">=</span> <span class="n">torchvision</span><span class="o">.</span><span class="n">transforms</span><span class="o">.</span><span class="n">RandomResizedCrop</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">    <span class="p">(</span><span class="mi">200</span><span class="p">,</span> <span class="mi">200</span><span class="p">),</span> <span class="n">scale</span><span class="o">=</span><span class="p">(</span><span class="mf">0.1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">ratio</span><span class="o">=</span><span class="p">(</span><span class="mf">0.5</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>
</span></span><span class="line"><span class="cl"><span class="n">apply</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">shape_aug</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># 亮度</span>
</span></span><span class="line"><span class="cl"><span class="n">apply</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">torchvision</span><span class="o">.</span><span class="n">transforms</span><span class="o">.</span><span class="n">ColorJitter</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">    <span class="n">brightness</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">contrast</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">saturation</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">hue</span><span class="o">=</span><span class="mi">0</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># 色相</span>
</span></span><span class="line"><span class="cl"><span class="n">apply</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">torchvision</span><span class="o">.</span><span class="n">transforms</span><span class="o">.</span><span class="n">ColorJitter</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">    <span class="n">brightness</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">contrast</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">saturation</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">hue</span><span class="o">=</span><span class="mf">0.5</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># 多个参数一起调</span>
</span></span><span class="line"><span class="cl"><span class="n">color_aug</span> <span class="o">=</span> <span class="n">torchvision</span><span class="o">.</span><span class="n">transforms</span><span class="o">.</span><span class="n">ColorJitter</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">    <span class="n">brightness</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">contrast</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">saturation</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">hue</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">apply</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">color_aug</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># 所有策略一起使用</span>
</span></span><span class="line"><span class="cl"><span class="n">augs</span> <span class="o">=</span> <span class="n">torchvision</span><span class="o">.</span><span class="n">transforms</span><span class="o">.</span><span class="n">Compose</span><span class="p">([</span>
</span></span><span class="line"><span class="cl">    <span class="n">torchvision</span><span class="o">.</span><span class="n">transforms</span><span class="o">.</span><span class="n">RandomVerticalFlip</span><span class="p">(),</span>
</span></span><span class="line"><span class="cl">    <span class="n">color_aug</span><span class="p">,</span> <span class="n">shape_aug</span><span class="p">])</span>
</span></span><span class="line"><span class="cl"><span class="n">apply</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">augs</span><span class="p">)</span></span></span></code></pre></div></div><div class="hextra-code-copy-btn-container hx-opacity-0 hx-transition group-hover/code:hx-opacity-100 hx-flex hx-gap-1 hx-absolute hx-m-[11px] hx-right-0 hx-top-0">
  <button
    class="hextra-code-copy-btn hx-group/copybtn hx-transition-all active:hx-opacity-50 hx-bg-primary-700/5 hx-border hx-border-black/5 hx-text-gray-600 hover:hx-text-gray-900 hx-rounded-md hx-p-1.5 dark:hx-bg-primary-300/10 dark:hx-border-white/10 dark:hx-text-gray-400 dark:hover:hx-text-gray-50"
    title="Copy code"
  >
    <div class="copy-icon group-[.copied]/copybtn:hx-hidden hx-pointer-events-none hx-h-4 hx-w-4"></div>
    <div class="success-icon hx-hidden group-[.copied]/copybtn:hx-block hx-pointer-events-none hx-h-4 hx-w-4"></div>
  </button>
</div>

  
</div>
<p><code>小结</code></p>
<ul>
<li>图像增广基于现有的训练数据生成随机图像，来提高模型的泛化能力。</li>
<li>为了在预测过程中得到确切的结果，我们通常对训练样本只进行图像增广，而在预测过程中不使用带随机操作的图像增广。</li>
<li>深度学习框架提供了许多不同的图像增广方法，这些方法可以被同时应用。</li>
<li>相比不增广，增广的train acc小，test acc大，某种程度上减轻了过拟合</li>
</ul>
<h2>微调<span class="hx-absolute -hx-mt-20" id="微调"></span>
    <a href="#%e5%be%ae%e8%b0%83" class="subheading-anchor" aria-label="Permalink for this section"></a></h2><blockquote>
<p>迁移学习中的常见技巧:<em>微调</em>（fine-tuning），从<em>源数据集</em>学到的知识迁移到<em>目标数据集</em></p>
</blockquote>
<p>微调包括以下四个步骤：</p>
<ol>
<li>在源数据集（例如ImageNet数据集）上<strong>预训练</strong>神经网络模型，即<em>源模型</em>。</li>
<li>创建一个新的神经网络模型，即<em>目标模型</em>。这将复制源模型上的所有模型设计及其参数（输出层除外）。我们假定这些模型参数包含从源数据集中学到的知识，这些知识也将适用于目标数据集。我们还假设源模型的输出层与源数据集的标签密切相关；因此不在目标模型中使用该层。</li>
<li>向目标模型添加输出层，其输出数是目标数据集中的类别数。然后随机初始化该层的模型参数。</li>
<li>在目标数据集（如椅子数据集）上训练目标模型。输出层将从头开始进行训练，而所有其他层的参数将根据源模型的参数进行微调。</li>
</ol>
<img src="https://zh-v2.d2l.ai/_images/finetune.svg" alt="../_images/finetune.svg" style="zoom: 80%;" />
<blockquote>
<p>当目标数据集比源数据集小得多时，微调有助于提高模型的泛化能力。</p>
</blockquote>
<p><code>训练</code></p>
<ul>
<li>是一个目标数据集上的正常训练任务，但使用更强的正则化
<ul>
<li>使用更小的学习率</li>
<li>更少的数据迭代</li>
</ul>
</li>
<li>源数据集远复杂于目标数据，通常微调效果更好</li>
</ul>
<p><code>小结</code></p>
<ul>
<li>微调通过使用在大数据集上得到的预训练好的模型来初始化模型权重来完成提升精度</li>
<li>预训练模型质量很重要</li>
<li>微调通常速度更快，精度更高</li>
</ul>
<h2>目标检测<span class="hx-absolute -hx-mt-20" id="目标检测"></span>
    <a href="#%e7%9b%ae%e6%a0%87%e6%a3%80%e6%b5%8b" class="subheading-anchor" aria-label="Permalink for this section"></a></h2><p><code>边界框</code></p>
<ul>
<li>目标检测不仅可以识别图像中所有感兴趣的物体，还能识别它们的位置，该位置通常由矩形边界框表示。</li>
<li>我们可以在两种常用的边界框表示（中间，宽度，高度）和（左上，右下）坐标之间进行转换。</li>
</ul>
<h3>锚框<span class="hx-absolute -hx-mt-20" id="锚框"></span>
    <a href="#%e9%94%9a%e6%a1%86" class="subheading-anchor" aria-label="Permalink for this section"></a></h3><p>一块区域，计算机的预测，而边缘框是真实标签</p>
<ul>
<li>两次预测
<ul>
<li>先预测锚框内是否含有物体</li>
<li>如果有，再预测锚框到真实边缘框的偏移</li>
</ul>
</li>
</ul>
<p><code>IoU-交互比</code></p>
<img src="https://zh-v2.d2l.ai/_images/iou.svg" alt="../_images/iou.svg" style="zoom:67%;" />
<ul>
<li>用来计算两个框之间的相似度
<ul>
<li>0表示无重叠，1表示重合</li>
</ul>
</li>
</ul>
<p><code>赋予锚框标号</code></p>
<ul>
<li>每个锚框都是一个训练样本</li>
<li>锚框要么标注成背景，要么关联一个真实边缘框</li>
<li>大量的锚框导致大量的负类样本</li>
</ul>
<p><code>非极大值抑制（NAS）</code></p>
<p>对于一个预测边界框B，目标检测模型会计算每个类别的预测概率。 假设最大的预测概率为p，则该概率所对应的类别B即为预测的类别。具体来说，我们将p称为预测边界框B的<em>置信度</em>（confidence）。在同一张图像中，所有预测的非背景边界框都按置信度降序排序，以生成列表L。</p>
<ul>
<li>每个锚框预测一个边缘框</li>
<li>NMS可以合并相似的预测
<ul>
<li>选中是非背景类的最大预测值</li>
<li>去掉所以其他和它IoU值大于θ的值</li>
<li>重复上述过程直到所有预测要么被选中,要么被去掉</li>
</ul>
</li>
</ul>
<p><code>总结</code></p>
<ul>
<li>我们以图像的每个像素为中心生成不同形状的锚框，一类目标检测算法基于锚框来预测。</li>
<li><strong>交并比</strong>（IoU）也被称为杰卡德系数，用于衡量两个边界框的相似性。它是相交面积与相并面积的比率。</li>
<li>在训练集中，我们需要给每个锚框两种类型的标签。一个是与锚框中目标检测的<strong>类别</strong>，另一个是锚框真实相对于边界框的<strong>偏移量</strong>。</li>
<li>在预测期间，我们可以使用非极大值抑制（NMS）来移除类似的预测边界框，从而简化输出，去掉冗余。</li>
</ul>
<h2>物体检测算法<span class="hx-absolute -hx-mt-20" id="物体检测算法"></span>
    <a href="#%e7%89%a9%e4%bd%93%e6%a3%80%e6%b5%8b%e7%ae%97%e6%b3%95" class="subheading-anchor" aria-label="Permalink for this section"></a></h2><h3>R-CNN<span class="hx-absolute -hx-mt-20" id="r-cnn"></span>
    <a href="#r-cnn" class="subheading-anchor" aria-label="Permalink for this section"></a></h3><p><em>R-CNN</em>首先从输入图像中选取若干（例如2000个）<em>提议区域</em>（如锚框也是一种选取方法），并标注它们的类别和边界框（如偏移量）。 [<a href="https://zh-v2.d2l.ai/chapter_references/zreferences.html#id43" target="_blank" rel="noopener">Girshick et al., 2014</a>]然后，用卷积神经网络对每个提议区域进行前向传播以抽取其特征。 接下来，我们用每个提议区域的特征来预测类别和边界框。</p>
<p><img src="https://zh-v2.d2l.ai/_images/r-cnn.svg" alt="../_images/r-cnn.svg" loading="lazy" /></p>
<p><code>四步骤</code></p>
<ul>
<li>使用启发式搜索算法来选择锚框</li>
<li>使用预训练模型来对每个锚框提取特征</li>
<li>训练一个SVM来对类别分类
<ul>
<li>训练一个线性回归模型来预测边缘框偏移</li>
</ul>
</li>
</ul>
<h3>Fast R-CNN<span class="hx-absolute -hx-mt-20" id="fast-r-cnn"></span>
    <a href="#fast-r-cnn" class="subheading-anchor" aria-label="Permalink for this section"></a></h3><p>R-CNN的主要性能瓶颈在于，对每个提议区域，卷积神经网络的前向传播是独立的，而没有共享计算。 由于这些区域通常有重叠，独立的特征抽取会导致重复的计算。 <em>Fast R-CNN</em> [<a href="https://zh-v2.d2l.ai/chapter_references/zreferences.html#id42" target="_blank" rel="noopener">Girshick, 2015</a>]对R-CNN的<strong>主要改进</strong>之一，是<strong>仅在整张图象上执行卷积神经网络的前向传播</strong>。</p>
<p><img src="https://zh-v2.d2l.ai/_images/fast-rcnn.svg" alt="../_images/fast-rcnn.svg" loading="lazy" /></p>
<p><code>兴趣区域（Rol）池化层</code>（对每个锚框生成固定长度的特征）</p>
<ul>
<li>给定一个锚框，均匀分成n×m块，输出每块里的最大值</li>
<li>无论锚框多大，总是输出nm个值</li>
</ul>
<p><img src="https://zh-v2.d2l.ai/_images/roi.svg" alt="../_images/roi.svg" loading="lazy" /></p>
<h3>Faster R-CNN<span class="hx-absolute -hx-mt-20" id="faster-r-cnn"></span>
    <a href="#faster-r-cnn" class="subheading-anchor" aria-label="Permalink for this section"></a></h3><ul>
<li>使用一个区域提议网络来替代启发式搜索来获得更好的锚框</li>
</ul>
<p><img src="https://zh-v2.d2l.ai/_images/faster-rcnn.svg" alt="../_images/faster-rcnn.svg" loading="lazy" /></p>
<p>与Fast R-CNN相比，Faster R-CNN只将生成提议区域的方法从选择性搜索改为了区域提议网络，模型的其余部分保持不变。</p>
<h3>Mask R-CNN<span class="hx-absolute -hx-mt-20" id="mask-r-cnn"></span>
    <a href="#mask-r-cnn" class="subheading-anchor" aria-label="Permalink for this section"></a></h3><ul>
<li>如果有像素级别的标号，使用FCN来利用这些信息</li>
</ul>
<p><img src="https://zh-v2.d2l.ai/_images/mask-rcnn.svg" alt="../_images/mask-rcnn.svg" loading="lazy" /></p>
<p>Mask R-CNN是基于Faster R-CNN修改而来的。 具体来说，Mask R-CNN将兴趣区域汇聚层替换为了 <strong><em>兴趣区域对齐</em>层</strong>，使用<em><strong>双线性插值</strong></em>（bilinear interpolation）来保留特征图上的空间信息，从而更适于像素级预测。 兴趣区域对齐层的输出包含了所有与兴趣区域的形状相同的特征图。 它们不仅被用于预测每个兴趣区域的类别和边界框，还通过额外的全卷积网络预测目标的像素级位置。</p>
<h3>R-CNN总结<span class="hx-absolute -hx-mt-20" id="r-cnn总结"></span>
    <a href="#r-cnn%e6%80%bb%e7%bb%93" class="subheading-anchor" aria-label="Permalink for this section"></a></h3><ul>
<li>最早且有名的一类基于锚框和CNN的目标检测算法</li>
<li>Faster R-CNN和Mask R-CNN是在求高精度场景下的常用算法
<ul>
<li>R-CNN对图像选取若干提议区域，使用卷积神经网络对每个提议区域执行前向传播以<strong>抽取其特征</strong>，然后再用这些特征来预测提议区域的类别和边界框。</li>
<li>Fast R-CNN对R-CNN的一个主要改进：只对<strong>整个图像</strong>做卷积神经网络的前向传播。它还引入了<strong>兴趣区域汇聚层</strong>，从而为具有不同形状的兴趣区域抽取相同形状的特征。</li>
<li>Faster R-CNN将Fast R-CNN中使用的选择性搜索替换为参与训练的<strong>区域提议网络</strong>，这样后者可以在减少提议区域数量的情况下仍保证目标检测的精度。</li>
<li>Mask R-CNN在Faster R-CNN的基础上引入了一个<strong>全卷积网络</strong>，从而借助目标的<strong>像素级</strong>位置进一步提升目标检测的精度。</li>
</ul>
</li>
</ul>
<h3>SSD<span class="hx-absolute -hx-mt-20" id="ssd"></span>
    <a href="#ssd" class="subheading-anchor" aria-label="Permalink for this section"></a></h3><blockquote>
<p>单发多框检测</p>
</blockquote>
<ul>
<li>一个基础网络提取特征，多个卷积层块来减半高宽</li>
<li>每段都生成锚框
<ul>
<li>底部段拟合小物体，顶部段拟合大物体</li>
</ul>
</li>
<li>对每个锚框预测类别和边缘框</li>
</ul>
<p><img src="https://zh-v2.d2l.ai/_images/ssd.svg" alt="../_images/ssd.svg" loading="lazy" /></p>
<p><code>小结</code></p>
<ul>
<li>单发多框检测是一种多尺度目标检测模型。基于基础网络块和各个多尺度特征块</li>
<li>以<strong>每个像素为中心的产生多个锚框</strong>，单发多框检测生成不同数量和不同大小的锚框，并通过预测这些锚框的类别和偏移量检测不同大小的目标。</li>
<li>在训练单发多框检测模型时，<strong>损失函数</strong>是根据锚框的类别和偏移量的预测及标注值计算得出的。</li>
</ul>
<h3>YOLO<span class="hx-absolute -hx-mt-20" id="yolo"></span>
    <a href="#yolo" class="subheading-anchor" aria-label="Permalink for this section"></a></h3><ul>
<li>
<p>因为SSD锚框大量重叠，浪费计算</p>
</li>
<li>
<p>YOLO将图片均匀分成S × S个锚框，每个锚框预测B个边缘框</p>
</li>
</ul>
<h2>语义分割<span class="hx-absolute -hx-mt-20" id="语义分割"></span>
    <a href="#%e8%af%ad%e4%b9%89%e5%88%86%e5%89%b2" class="subheading-anchor" aria-label="Permalink for this section"></a></h2><p>它重点关注于如何将图像分割成属于不同语义类别的区域。 与目标检测不同，语义分割可以识别并理解图像中每一个像素的内容：其语义区域的标注和预测是像素级的。与目标检测相比，语义分割标注的像素级的边框显然更加精细。</p>
<p><img src="https://zh-v2.d2l.ai/_images/segmentation.svg" alt="../_images/segmentation.svg" loading="lazy" /></p>
<p><code>Pascal VOC2012 语义分割数据集</code></p>
<p><code>小结</code></p>
<ul>
<li>
<p>语义分割通过将图像划分为属于不同语义类别的区域，来识别并理解图像中像素级别的内容。</p>
</li>
<li>
<p>语义分割的一个重要的数据集叫做Pascal VOC2012。</p>
</li>
<li>
<p>由于语义分割的输入图像和标签在像素上一一对应，输入图像会被随机裁剪为固定尺寸而不是缩放。</p>
</li>
<li>
<p>多应用于自动驾驶与医疗图像</p>
</li>
</ul>
<h2>转置卷积<span class="hx-absolute -hx-mt-20" id="转置卷积"></span>
    <a href="#%e8%bd%ac%e7%bd%ae%e5%8d%b7%e7%a7%af" class="subheading-anchor" aria-label="Permalink for this section"></a></h2><ul>
<li>卷积无法增大输入的高宽，通常要么不变，要么减半</li>
<li>转置卷积则用来增大输入的高宽</li>
</ul>
<p><code>2×2的输入张量计算卷积核为2×2的转置卷积</code></p>
<p><img src="https://zh-v2.d2l.ai/_images/trans_conv.svg" alt="../_images/trans_conv.svg" loading="lazy" /></p>
<p><code>填充，步幅，多通道</code></p>
<p>在转置卷积中</p>
<ul>
<li>
<p>填充被应用于的输出（常规卷积将填充应用于输入）。 例如，当将高和宽两侧的填充数指定为1时，转置卷积的输出中将删除第一和最后的行与列。</p>
</li>
<li>
<p>步幅被指定为中间结果（输出），而不是输入。</p>
<img src="https://zh-v2.d2l.ai/_images/trans_conv_stride2.svg" alt="../_images/trans_conv_stride2.svg" style="zoom:67%;" />
</li>
<li>
<p>卷积核为2×2，步幅为2的转置卷积。阴影部分是中间张量的一部分，也是用于计算的输入和卷积核张量元素。</p>
</li>
</ul>
<p><code>小结</code></p>
<ul>
<li>本质还是卷积，卷积使其变小，转置卷积相反，使其变大</li>
<li>转置卷积还原的是通道大小，即矩阵大小size，不是值的还原
<ul>
<li>例如，4×4输入卷积3×3卷积核得到2×2输出</li>
<li>反过来，输出变输入2×2，通过3×3，得到4×4</li>
<li>
<img src="https://img-blog.csdnimg.cn/1e7f5e8d17494f0b9104898ab345acdb.gif" alt="img" style="zoom: 80%;" />
</li>
</ul>
</li>
<li>与卷积是做下采样（缩小图像）不同，它通常用作上采样（放大图像）</li>
<li>与反卷积不同，反卷积是逆运算</li>
</ul>
<h2>全连接卷积神经网络（FCN）<span class="hx-absolute -hx-mt-20" id="全连接卷积神经网络fcn"></span>
    <a href="#%e5%85%a8%e8%bf%9e%e6%8e%a5%e5%8d%b7%e7%a7%af%e7%a5%9e%e7%bb%8f%e7%bd%91%e7%bb%9cfcn" class="subheading-anchor" aria-label="Permalink for this section"></a></h2><blockquote>
<p><em>全卷积网络</em>（fully convolutional network，FCN）采用卷积神经网络实现了从图像像素到像素类别的变换，全卷积网络将中间层特征图的高和宽变换回输入图像的尺寸：这是通过引入的<em>转置卷积</em>（transposed convolution）实现的。</p>
</blockquote>
<p><img src="https://zh-v2.d2l.ai/_images/fcn.svg" alt="../_images/fcn.svg" loading="lazy" /></p>
<ul>
<li>FCN是深度神经网络做语义分割的奠基性工作</li>
<li>它用转置卷积层替换CNN最后的全连接层，从而实现每个像素的预测</li>
</ul>
<p><code>小结</code></p>
<ul>
<li>全卷积网络先使用<strong>卷积神经网络抽取图像特征</strong>，然后通过<strong>1×1卷积层</strong>将通道数变换为<strong>类别个数</strong>，最后通过<strong>转置卷积层</strong>将特征图的高和宽变换为输入图像的尺寸。</li>
<li>在全卷积网络中，我们可以将转置卷积层<strong>初始化</strong>为<strong>双线性插值的上采样</strong>。</li>
</ul>
<h2>样式迁移<span class="hx-absolute -hx-mt-20" id="样式迁移"></span>
    <a href="#%e6%a0%b7%e5%bc%8f%e8%bf%81%e7%a7%bb" class="subheading-anchor" aria-label="Permalink for this section"></a></h2><blockquote>
<p>将样式图片中的样式迁移到内容图片上，得到合成图片</p>
</blockquote>
<ul>
<li>使用卷积神经网络，自动将一个图像中的风格应用在另一图像之上，即<em>风格迁移</em></li>
</ul>
<p><img src="https://zh-v2.d2l.ai/_images/style-transfer.svg" alt="../_images/style-transfer.svg" loading="lazy" /></p>
<p><code>方法</code></p>
<ol>
<li>首先，我们初始化合成图像，例如将其初始化为内容图像。 该合成图像是风格迁移过程中唯一需要更新的变量，即风格迁移所需迭代的模型参数。</li>
<li>然后，我们选择一个<strong>预训练的卷积</strong>神经网络来<strong>抽取图像的特征</strong>，其中的模型参数在训练中无须更新。</li>
<li>这个深度卷积神经网络凭借多个层逐级抽取图像的特征，我们可以选择其中某些层的输出作为内容特征或风格特征。</li>
</ol>
<p><img src="https://zh-v2.d2l.ai/_images/neural-style.svg" alt="../_images/neural-style.svg" loading="lazy" /></p>
<blockquote>
<p>实线箭头和虚线箭头分别表示前向传播和反向传播</p>
</blockquote>
<ul>
<li>前向传播（实线箭头方向）计算风格迁移的损失函数</li>
<li>反向传播（虚线箭头方向）迭代模型参数，即不断更新合成图像</li>
</ul>
<p>风格迁移损失函数由三部分组成：</p>
<ol>
<li><em>内容损失</em>使合成图像与内容图像在内容特征上接近；</li>
<li><em>风格损失</em>使合成图像与风格图像在风格特征上接近；</li>
<li><em>全变分损失</em>则有助于减少合成图像中的噪点</li>
</ol>
<h1>循环神经网络</h1><h2>序列模型<span class="hx-absolute -hx-mt-20" id="序列模型"></span>
    <a href="#%e5%ba%8f%e5%88%97%e6%a8%a1%e5%9e%8b" class="subheading-anchor" aria-label="Permalink for this section"></a></h2><p>处理序列数据需要<strong>统计工具</strong>和新的深度神经网络架构</p>
<p><code>自回归模型</code></p>
<p><img src="https://zh-v2.d2l.ai/_images/sequence-model.svg" alt="../_images/sequence-model.svg" loading="lazy" /></p>
<p><code>小结</code></p>
<ul>
<li><strong>内插法</strong>（在现有观测值之间进行估计）和<strong>外推法</strong>（对超出已知观测范围进行预测）在实践的难度上差别很大。因此，对于你所拥有的序列数据，在训练时始终要尊重其时间顺序，即最好<strong>不要基于未来的数据</strong>进行训练。</li>
<li>序列模型的估计需要专门的统计工具，两种较流行的选择是<strong>自回归模型</strong>和<strong>隐变量自回归模型</strong>。</li>
<li>对于时间是向前推进的因果模型，正向估计通常比反向估计更容易。</li>
<li>对于直到时间步t的观测序列，其在时间步t+k的预测输出是“k步预测”。随着我们对预测时间k值的增加，会造成误差的快速累积和预测质量的极速下降。</li>
</ul>
<h2>文本预处理<span class="hx-absolute -hx-mt-20" id="文本预处理"></span>
    <a href="#%e6%96%87%e6%9c%ac%e9%a2%84%e5%a4%84%e7%90%86" class="subheading-anchor" aria-label="Permalink for this section"></a></h2><ul>
<li>文本是序列数据的一种最常见的形式之一。</li>
<li>为了对文本进行预处理，我们通常将<strong>文本拆分为词元</strong>，构建词表将<strong>词元</strong>字符串映射为<strong>数字索引</strong>，并将<strong>文本数据</strong>转换为<strong>词元索引</strong>以供模型操作。</li>
</ul>
<h2>语言模型<span class="hx-absolute -hx-mt-20" id="语言模型"></span>
    <a href="#%e8%af%ad%e8%a8%80%e6%a8%a1%e5%9e%8b" class="subheading-anchor" aria-label="Permalink for this section"></a></h2><ul>
<li>给定文本序列，语言模型的目标是估计联合概率</li>
<li>应用
<ul>
<li>预训练模型（BERT，GPT-3）</li>
<li>生成文本，给定一些词，不断预测，持续生成后面的词汇</li>
<li>判断多个序列中哪个更常见，语音识别</li>
</ul>
</li>
</ul>
<p><code>小结</code></p>
<ul>
<li>语言模型是自然语言处理的关键。</li>
<li>n元语法通过截断相关性，为处理长序列提供了一种实用的模型。</li>
<li>长序列存在一个问题：它们很少出现或者从不出现。</li>
<li>齐普夫定律支配着单词的分布，这个分布不仅适用于一元语法，还适用于其他n元语法。</li>
<li>通过拉普拉斯平滑法可以有效地处理结构丰富而频率不足的低频词词组。</li>
<li>读取长序列的主要方式是随机采样和顺序分区。在迭代过程中，后者可以保证来自两个相邻的小批量中的子序列在原始序列上也是相邻的。</li>
</ul>
<h2>RNN<span class="hx-absolute -hx-mt-20" id="rnn"></span>
    <a href="#rnn" class="subheading-anchor" aria-label="Permalink for this section"></a></h2><blockquote>
<p><em>循环神经网络</em>（recurrent neural networks，RNNs） 是具有隐状态的神经网络。 在介绍循环神经网络模型之前， 我们首先回顾 <a href="https://zh-v2.d2l.ai/chapter_multilayer-perceptrons/mlp.html#sec-mlp" target="_blank" rel="noopener">4.1节</a>中介绍的多层感知机模型。</p>
</blockquote>
<p><code>困惑度</code>（衡量语言模型好坏的标准）</p>
<ul>
<li>使用平均交叉熵</li>
</ul>
<p>困惑度的最好的理解是“<strong>下一个词元的实际选择数的调和平均数</strong>”。 我们看看一些案例：</p>
<ul>
<li>在最好的情况下，模型总是完美地估计标签词元的概率为1。 在这种情况下，模型的困惑度为1。</li>
<li>在最坏的情况下，模型总是预测标签词元的概率为0。 在这种情况下，困惑度是<strong>正无穷大</strong>。</li>
<li>在基线上，该模型的预测是词表的所有可用词元上的均匀分布。 在这种情况下，困惑度等于词表中唯一词元的数量。 事实上，如果我们在没有任何压缩的情况下存储序列， 这将是我们能做的最好的编码方式。 因此，这种方式提供了一个重要的上限， 而任何实际模型都必须超越这个上限。</li>
</ul>
<h3>梯度裁剪<span class="hx-absolute -hx-mt-20" id="梯度裁剪"></span>
    <a href="#%e6%a2%af%e5%ba%a6%e8%a3%81%e5%89%aa" class="subheading-anchor" aria-label="Permalink for this section"></a></h3><p>梯度爆炸的一种常见且相对容易的解决方案是：</p>
<ul>
<li>在通过网络向后传播误差并使用其更新权重之前，<strong>更改误差的导数</strong>。 两种方法包括：
<ul>
<li>给定选定的向量范数（ vector norm）来重新缩放梯度；</li>
<li>以及裁剪超出预设范围的梯度值。 这些方法一起被称为梯度裁剪（gradient clipping）。</li>
</ul>
</li>
</ul>
<p><code>小结</code></p>
<ul>
<li>对隐状态使用循环计算的神经网络称为循环神经网络（RNN）。</li>
<li>循环神经网络的输出取决于输入和前一时间的隐变量</li>
<li>应用到语言模型中时，循环神经网络根据当前词预测下一次时刻词</li>
<li>使用困惑度来评价语言模型的质量。</li>
</ul>
<h2>门控循环单元（GRU）<span class="hx-absolute -hx-mt-20" id="门控循环单元gru"></span>
    <a href="#%e9%97%a8%e6%8e%a7%e5%be%aa%e7%8e%af%e5%8d%95%e5%85%83gru" class="subheading-anchor" aria-label="Permalink for this section"></a></h2><p><code>重置门和更新门</code></p>
<ul>
<li>
<p>重置门允许我们控制“可能还想记住”的过去状态的数量；（能关注）</p>
</li>
<li>
<p>更新门将允许我们控制新状态中有多少个是旧状态的副本。（能遗忘）</p>
</li>
</ul>
<p><img src="https://zh-v2.d2l.ai/_images/gru-1.svg" alt="../_images/gru-1.svg" loading="lazy" /></p>
<p>输入是由当前时间步的输入和前一时间步的隐状态给出。 两个门的输出是由使用sigmoid激活函数的两个全连接层给出。</p>
<p><code>候选隐状态</code></p>
<p><img src="https://zh-v2.d2l.ai/_images/gru-2.svg" alt="../_images/gru-2.svg" loading="lazy" /></p>
<p>总之，门控循环单元具有以下两个显著特征：</p>
<ul>
<li>重置门有助于捕获序列中的短期依赖关系。</li>
<li>更新门有助于捕获序列中的长期依赖关系。</li>
</ul>
<h2>长短期记忆网络（LSTM）<span class="hx-absolute -hx-mt-20" id="长短期记忆网络lstm"></span>
    <a href="#%e9%95%bf%e7%9f%ad%e6%9c%9f%e8%ae%b0%e5%bf%86%e7%bd%91%e7%bb%9clstm" class="subheading-anchor" aria-label="Permalink for this section"></a></h2><blockquote>
<p>长短期记忆网络的设计灵感来自于计算机的逻辑门;</p>
</blockquote>
<img src="https://zh-v2.d2l.ai/_images/lstm-0.svg" alt="../_images/lstm-0.svg" style="zoom: 80%;" />
<ul>
<li>忘记门：将值朝0减少</li>
<li>输入门：决定是否忽略掉数据</li>
<li>输出门：决定是不是使用隐状态</li>
</ul>
<p>就如在门控循环单元中一样， 当前时间步的输入和前一个时间步的<strong>隐状态</strong>作为数据送入长短期记忆网络的门中， 如图所示。 它们由三个具有sigmoid激活函数的全连接层处理， 以计算输入门、遗忘门和输出门的值。 因此，这三个门的值都在(0,1)的范围内。</p>
<p><code>隐状态</code></p>
<p><img src="https://zh-v2.d2l.ai/_images/lstm-3.svg" alt="../_images/lstm-3.svg" loading="lazy" /></p>
<p><code>小结</code></p>
<ul>
<li>长短期记忆网络有三种类型的门：输入门、遗忘门和输出门。</li>
<li>长短期记忆网络的隐藏层输出包括“隐状态”和“记忆元”。只有隐状态会传递到输出层，而记忆元完全属于内部信息。</li>
<li>长短期记忆网络可以缓解梯度消失和梯度爆炸。</li>
</ul>
<h2>深层循环神经网络<span class="hx-absolute -hx-mt-20" id="深层循环神经网络"></span>
    <a href="#%e6%b7%b1%e5%b1%82%e5%be%aa%e7%8e%af%e7%a5%9e%e7%bb%8f%e7%bd%91%e7%bb%9c" class="subheading-anchor" aria-label="Permalink for this section"></a></h2><p><img src="https://zh-v2.d2l.ai/_images/deep-rnn.svg" alt="../_images/deep-rnn.svg" loading="lazy" /></p>
<p>该图为深度循环神经网络结构，有多个隐藏层</p>
<p><code>总结</code></p>
<ul>
<li>
<p>深度循环神经网络使用多个隐藏层来获得更多的非线性性</p>
</li>
<li>
<p>在深度循环神经网络中，隐状态的信息被传递到当前层的下一时间步和下一层的当前时间步。</p>
</li>
<li>
<p>有许多不同风格的深度循环神经网络， 如长短期记忆网络、门控循环单元、或经典循环神经网络。 这些模型在深度学习框架的高级API中都有涵盖。</p>
</li>
<li>
<p>总体而言，深度循环神经网络需要大量的调参（如学习率和修剪） 来确保合适的收敛，模型的初始化也需要谨慎。</p>
</li>
</ul>
<h2>双向循环神经网络<span class="hx-absolute -hx-mt-20" id="双向循环神经网络"></span>
    <a href="#%e5%8f%8c%e5%90%91%e5%be%aa%e7%8e%af%e7%a5%9e%e7%bb%8f%e7%bd%91%e7%bb%9c" class="subheading-anchor" aria-label="Permalink for this section"></a></h2><p>如果我们希望在循环神经网络中拥有一种机制， 使之能够提供与隐马尔可夫模型类似的前瞻能力， 我们就需要修改循环神经网络的设计。</p>
<p>概念上， 只需要增加一个“从<strong>最后一个词元开始从后向前运行</strong>”的循环神经网络， 而不是只有一个在前向模式下“从第一个词元开始运行”的循环神经网络。</p>
<p><em>双向循环神经网络</em>（bidirectional RNNs） 添加了<strong>反向传递信息的隐藏层</strong>，以便更灵活地处理此类信息。</p>
<p><img src="https://zh-v2.d2l.ai/_images/birnn.svg" alt="../_images/birnn.svg" loading="lazy" /></p>
<p>该图为具有单个<strong>隐藏层</strong>的<strong>双向</strong>循环神经网络的架构。</p>
<ul>
<li>隐藏层有两个
<ul>
<li>前向RNN隐层</li>
<li>反向RNN隐层</li>
</ul>
</li>
<li>合并两个隐状态得到输出</li>
</ul>
<p><code>小结</code></p>
<ul>
<li>通过反向更新的隐藏层来利用方向时间信息</li>
<li>通常用来对序列抽取特征，填空，而不是预测未来</li>
<li>在双向循环神经网络中，每个时间步的隐状态由当前时间步的前后数据同时决定。</li>
<li>双向循环神经网络与概率图模型中的“前向-后向”算法具有相似性。</li>
<li>双向循环神经网络主要用于序列编码和给定双向上下文的观测估计。</li>
<li>由于梯度链更长，因此双向循环神经网络的训练代价非常高。</li>
</ul>
<h2>机器翻译与数据集<span class="hx-absolute -hx-mt-20" id="机器翻译与数据集"></span>
    <a href="#%e6%9c%ba%e5%99%a8%e7%bf%bb%e8%af%91%e4%b8%8e%e6%95%b0%e6%8d%ae%e9%9b%86" class="subheading-anchor" aria-label="Permalink for this section"></a></h2><blockquote>
<p><strong>语言模型</strong>是自然语言处理的关键， 而<em><strong>机器翻译</strong></em>是语言模型最成功的基准测试。 因为机器翻译正是将输入序列转换成输出序列的 <em>序列转换模型</em>（sequence transduction）的核心问题。</p>
<p><em><strong>机器翻译</strong></em>（machine translation）指的是 将序列从一种语言自动翻译成另一种语言。</p>
</blockquote>
<p><code>神经网络机器翻译方法</code></p>
<ul>
<li>强调的是端到端的学习</li>
<li>机器翻译的数据集是由源语言和目标语言的文本序列对组成的</li>
</ul>
<p><code>小结</code></p>
<ul>
<li>机器翻译指的是将文本序列从一种语言自动翻译成另一种语言。</li>
<li>使用单词级词元化时的词表大小，将明显大于使用字符级词元化时的词表大小。为了缓解这一问题，我们可以<strong>将低频词元视为相同的未知词元</strong>。</li>
<li>通过截断和填充文本序列，可以保证所有的文本序列都具有相同的长度，以便以小批量的方式加载。</li>
</ul>
<h1>编码器-解码器</h1><blockquote>
<p><em>编码器</em>（encoder）： 它接受一个长度可变的序列作为输入， 并将其转换为具有固定形状的编码状态。</p>
<p><em>解码器</em>（decoder）： 它将固定形状的编码状态映射到长度可变的序列。</p>
</blockquote>
<p><img src="https://zh-v2.d2l.ai/_images/encoder-decoder.svg" alt="../_images/encoder-decoder.svg" loading="lazy" /></p>
<ul>
<li>该模型中，编码器负责表示输入，解码器负责输出</li>
</ul>
<p><code>小结</code></p>
<ul>
<li>“编码器－解码器”架构可以将长度可变的序列作为输入和输出，因此适用于机器翻译等序列转换问题。</li>
<li>编码器将长度可变的序列作为输入，并将其转换为具有固定形状的编码状态。</li>
<li>解码器将具有固定形状的编码状态映射为长度可变的序列。</li>
</ul>
<blockquote>
<p>细节：</p>
<ul>
<li>编码器没有输出</li>
<li>编码器最后时间步的隐状态用作解码器的初始隐状态</li>
</ul>
</blockquote>
<h2>序列到序列学习（seq2seq）<span class="hx-absolute -hx-mt-20" id="序列到序列学习seq2seq"></span>
    <a href="#%e5%ba%8f%e5%88%97%e5%88%b0%e5%ba%8f%e5%88%97%e5%ad%a6%e4%b9%a0seq2seq" class="subheading-anchor" aria-label="Permalink for this section"></a></h2><p>在机器翻译中使用两个RNN进行seq2seq</p>
<p><img src="https://zh-v2.d2l.ai/_images/seq2seq.svg" alt="../_images/seq2seq.svg" loading="lazy" /></p>
<ul>
<li>编码器是一个RNN，读取输入句子
<ul>
<li>可以双向</li>
</ul>
</li>
<li>解码器使用另外一个RNN来输出</li>
</ul>
<p><code>衡量序列评估好坏</code></p>
<p>BLEU（bilingual evaluation understudy） 最先是用于评估机器翻译的结果， 但现在它已经被广泛用于测量许多应用的输出序列的质量。 原则上说，对于预测序列中的任意n元语法（n-grams）， BLEU的评估都是这个n元语法是否出现在标签序列中。</p>
<p>BLEU定义</p>
<img src="C:\Users\zzy\AppData\Roaming\Typora\typora-user-images\image-20221204111207068.png" alt="image-20221204111207068" style="zoom:80%;" />
<p><code>总结</code></p>
<ul>
<li>seq2seq从一个句子生成另一个句子</li>
<li>编码器和解码器都是RNN</li>
<li>编码器最后时间隐状态给到解码器初始隐状态来完成信息传递</li>
<li>使用BLEU来衡量生成序列的好坏</li>
</ul>
<h2>束搜索<span class="hx-absolute -hx-mt-20" id="束搜索"></span>
    <a href="#%e6%9d%9f%e6%90%9c%e7%b4%a2" class="subheading-anchor" aria-label="Permalink for this section"></a></h2><p>在seq2seq中使用<strong>贪心搜索</strong>来预测序列，即输出概率最大的词，但贪心不一定最优；</p>
<blockquote>
<p>贪心：速度快，效果不好</p>
<p>穷举：效果好但速度满，计算通常不可行</p>
</blockquote>
<p>因此推出 <strong>穷举搜索</strong> 和 <strong>束搜索</strong></p>
<ul>
<li>
<p>穷举：对所有可能的序列，计算其概率，然后选取最好的那个</p>
</li>
<li>
<p>束：</p>
<ul>
<li>
<p>保存最好的k个候选</p>
</li>
<li>
<p>每个时刻，对每个候选项加一项（n种可能），然后再在kn个选项里选最好的k个</p>
<img src="https://zh-v2.d2l.ai/_images/beam-search.svg" alt="../_images/beam-search.svg" style="zoom:67%;" />
</li>
</ul>
</li>
</ul>
<p><code>总结</code></p>
<ul>
<li>束搜索每次搜索时保存k个最好的候选
<ul>
<li>k=1时，为贪心搜索</li>
<li>k=n时，为穷举搜索</li>
</ul>
</li>
</ul>
<h1>注意力机制</h1><ul>
<li>
<p>卷积，全连接，池化层都只考虑不随意线索</p>
</li>
<li>
<p>注意力机制则显示的考虑随意线索</p>
<ul>
<li>随意线索又叫 查询（query）</li>
<li>每个输入是 一个值（value）和不随意线索（key）的对</li>
<li>通过注意力池化层来有偏向的选择某些输入</li>
</ul>
<img src="https://zh-v2.d2l.ai/_images/qkv.svg" alt="../_images/qkv.svg" style="zoom:80%;" />
</li>
</ul>
<p><code>小结</code></p>
<ul>
<li>注意力机制中，通过query（随意线索）和key（不随意线索）来有偏向性的选择输入</li>
<li>Nadaraya-Watson核回归是具有注意力机制的机器学习范例。</li>
<li>Nadaraya-Watson核回归的注意力汇聚是对训练数据中输出的加权平均。从注意力的角度来看，分配给每个值的注意力权重取决于将值所对应的键和查询作为输入的函数。</li>
<li>注意力汇聚可以分为非参数型和带参数型。</li>
</ul>
<h2>注意力分数<span class="hx-absolute -hx-mt-20" id="注意力分数"></span>
    <a href="#%e6%b3%a8%e6%84%8f%e5%8a%9b%e5%88%86%e6%95%b0" class="subheading-anchor" aria-label="Permalink for this section"></a></h2><p><img src="C:%5cUsers%5czzy%5cAppData%5cRoaming%5cTypora%5ctypora-user-images%5cimage-20221222131353674.png" alt="image-20221222131353674" loading="lazy" /></p>
<p><code>小结</code></p>
<ul>
<li>注意力分数是query和key的相似度，注意力权重是分数的softmax结果</li>
<li>两种常见的分数计算：
<ul>
<li>将query和key合并起来进入一个单输出单隐藏层的MLP</li>
<li>直接将query和key做内积（两者长度一致）</li>
</ul>
</li>
</ul>
<h2>自注意力<span class="hx-absolute -hx-mt-20" id="自注意力"></span>
    <a href="#%e8%87%aa%e6%b3%a8%e6%84%8f%e5%8a%9b" class="subheading-anchor" aria-label="Permalink for this section"></a></h2><p><strong>三者差别</strong></p>
<img src="https://zh-v2.d2l.ai/_images/cnn-rnn-self-attention.svg" alt="../_images/cnn-rnn-self-attention.svg" style="zoom:80%;" />
<p><code>位置编码</code></p>
<ul>
<li>不同与CNN，RNN，自注意力没有记录位置信息</li>
<li>将位置信息注入到输入里</li>
</ul>
<p><code>小结</code></p>
<ul>
<li>自注意力池化层将xi当作key，val，query来对序列抽取特征</li>
<li>完全并行，最长序列为1，但对长序列计算复杂度高</li>
<li>位置编码在输入中加入位置信息，使自注意力能记忆位置信息</li>
</ul>
<h2>Transformer<span class="hx-absolute -hx-mt-20" id="transformer"></span>
    <a href="#transformer" class="subheading-anchor" aria-label="Permalink for this section"></a></h2><p><code>架构</code></p>
<ul>
<li>基于编码器-解码器架构来处理序列对</li>
<li>与使用注意力的seq2seq不同，Transformer是纯基于注意力</li>
<li>
<img src="https://zh-v2.d2l.ai/_images/transformer.svg" alt="../_images/transformer.svg" style="zoom:67%;" />
</li>
</ul>
<h3>多头注意力<span class="hx-absolute -hx-mt-20" id="多头注意力"></span>
    <a href="#%e5%a4%9a%e5%a4%b4%e6%b3%a8%e6%84%8f%e5%8a%9b" class="subheading-anchor" aria-label="Permalink for this section"></a></h3><ul>
<li>对同一key，val，query，希望提取不同的特征
<ul>
<li>短距离关系和长距离关系</li>
</ul>
</li>
<li>多头注意力使用h个独立的注意力池化
<ul>
<li>合并各个头的输出得到最终输出</li>
</ul>
</li>
<li>
<img src="https://zh-v2.d2l.ai/_images/multi-head-attention.svg" alt="../_images/multi-head-attention.svg" style="zoom: 80%;" />
</li>
</ul>
<h3>基于位置的前馈网络<span class="hx-absolute -hx-mt-20" id="基于位置的前馈网络"></span>
    <a href="#%e5%9f%ba%e4%ba%8e%e4%bd%8d%e7%bd%ae%e7%9a%84%e5%89%8d%e9%a6%88%e7%bd%91%e7%bb%9c" class="subheading-anchor" aria-label="Permalink for this section"></a></h3><ul>
<li>将输入形状由（b,n,d）变换成（bn,d）</li>
<li>作用两个全连接层</li>
<li>输出形状由（bn,d）变化回（b,n,d）</li>
<li>等价于两层核窗口为1的一维卷积层</li>
</ul>
<p><code>小结</code></p>
<ul>
<li>Transformer是一个纯注意力机制的编码-解码器</li>
<li>编码器和解码器中都有transformer块</li>
<li>每个块里使用<strong>多头（自）注意力</strong>，<strong>基于位置的前馈网络</strong>，<strong>层归一化</strong></li>
</ul>
<h2>BERT<span class="hx-absolute -hx-mt-20" id="bert"></span>
    <a href="#bert" class="subheading-anchor" aria-label="Permalink for this section"></a></h2><p><code>动机</code></p>
<ul>
<li>基于微调的NLP模型</li>
<li>预训练的模型抽取了足够多的信息</li>
<li>新的任务只需要增加一个简单地输出层</li>
<li>
<img src="https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/raw/main/imgs/69/69-1.png" alt="image" style="zoom:67%;" />
</li>
</ul>
<p><code>架构</code></p>
<ul>
<li>只有编码器的Transformer</li>
<li>两个版本：
<ul>
<li>Base:#blocks=12,hidden size=768,#heads=12,#parameters=110M</li>
<li>Large:#blocks=24,hidden size=1024,#heads=16,#paramerter=340M</li>
</ul>
</li>
<li>在大规模数据上训练&gt;3B词</li>
</ul>
<p><code>预训练</code></p>
<ul>
<li>掩蔽语言模型</li>
<li>下一句预测
<ul>
<li>前者能够编码双向上下文来表示单词，而后者则显式地建模文本对之间的逻辑关系。</li>
</ul>
</li>
</ul>
<p><code>小结</code></p>
<ul>
<li>BERT针对微调设计</li>
<li>基于Transformer的编码器做了如下修改
<ul>
<li>模型更大，训练数据更多</li>
<li>输入句子对，片段嵌入，可学习的位置编码</li>
<li>训练时使用两个任务：
<ul>
<li>带掩码的语言模型</li>
<li>下一个句子预测</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3>微调<span class="hx-absolute -hx-mt-20" id="微调-1"></span>
    <a href="#%e5%be%ae%e8%b0%83-1" class="subheading-anchor" aria-label="Permalink for this section"></a></h3><p><code>应用</code></p>
<ul>
<li>句子分类
<ul>
<li>将句首的<CLS>token对应的向量输入到全连接层分类。对于一对句子也是同理，句子中间用<SEP>分开但仍只用第一个<CLS>对应的向量。</li>
</ul>
</li>
<li>命名实体识别
<ul>
<li>识别一个词元是不是命名实体，例如人名、机构、位置。</li>
<li>其方法是将每一个非特殊词元的向量放进全连接层分类（二分类多分类均可）。</li>
</ul>
</li>
<li>问题回答
<ul>
<li>给定一个问题和描述文字，找出一个判断作为回答。</li>
<li>微调方法为对片段中的每个词元预测它是不是回答的开头或结束。</li>
</ul>
</li>
</ul>
<p><code>小结</code></p>
<ul>
<li>即使下游任务各有不同，使用BERT微调时均只需要增加输出层</li>
<li>但根据任务的不同，输入的表示，和使用的BERT特征也会不一样</li>
</ul>
<h1>优化算法</h1><p><code>局部最小 vs 全局最小</code></p>
<img src="https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/raw/main/imgs/72/72-02.png" alt="image" style="zoom: 50%;" />
<p><code>凸集和凸函数</code></p>
<ul>
<li>
<p>凸集：形象化来说，就是这个集合上任意两个点连一条线，这个线在集合里面</p>
</li>
<li>
<p>凸函数：形象上来说函数上任取两个点连线，函数都在该线下面</p>
</li>
<li>
<p>凸优化问题：</p>
<ul>
<li>如果代价函数f是凸的，且限制集合C是凸的，则为凸优化问题，<strong>局部最小一定是全局最小</strong></li>
<li>严格凸优化问题有唯一的全局最小</li>
<li>凸：线性回归，softmax回归</li>
<li>非凸：其他（MLP,CNN,RNN,attention）</li>
</ul>
</li>
<li>
<p>第一组非凸，后两组凸</p>
<img src="https://zh-v2.d2l.ai/_images/pacman.svg" alt="../_images/pacman.svg" style="zoom:67%;" />
</li>
<li>
<p>余弦函数为非凸的，而抛物线函数和指数函数为凸的（1，3凸，2非凸）</p>
<img src="https://zh-v2.d2l.ai/_images/output_convexity_94e148_21_0.svg" alt="../_images/output_convexity_94e148_21_0.svg" style="zoom:67%;" />
</li>
</ul>
<h2>梯度下降<span class="hx-absolute -hx-mt-20" id="梯度下降"></span>
    <a href="#%e6%a2%af%e5%ba%a6%e4%b8%8b%e9%99%8d" class="subheading-anchor" aria-label="Permalink for this section"></a></h2><ul>
<li>梯度下降——最简单的迭代求解算法（SGD）</li>
<li>随机梯度下降
<ul>
<li>求导数需要求所有样本导数，样本多的情况下代价太大</li>
<li>理论依据：所用样本，和随机选取一个样本得到的数学期望是一样的。</li>
</ul>
</li>
<li>小批量随机梯度下降（实际应用的）
<ul>
<li>计算原因：计算单样本的梯度难以完全利用硬件资源</li>
<li>采集一个随机子集</li>
<li>理论依据：无偏近，但降低了方差</li>
</ul>
</li>
</ul>
<h2>冲量法（动量）<span class="hx-absolute -hx-mt-20" id="冲量法动量"></span>
    <a href="#%e5%86%b2%e9%87%8f%e6%b3%95%e5%8a%a8%e9%87%8f" class="subheading-anchor" aria-label="Permalink for this section"></a></h2><ul>
<li>使用平滑过的梯度对权重更新，不容易震荡</li>
<li>momentum</li>
<li>
<img src="https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/raw/main/imgs/72/72-03.png" alt="image" style="zoom:67%;" />
</li>
</ul>
<h2>Adam<span class="hx-absolute -hx-mt-20" id="adam"></span>
    <a href="#adam" class="subheading-anchor" aria-label="Permalink for this section"></a></h2><ul>
<li>
<p>非常平滑，对于学习率不敏感</p>
</li>
<li>
<p>对于t比较小的时候，由于$v_0=0$,所以会导致一开始值比较小，做了一个修正。</p>
</li>
<li>
<img src="https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/raw/main/imgs/72/72-04.png" alt="image" style="zoom: 50%;" />
</li>
<li>
<p>为什么除以$\sqrt{\widehat{s}_t}+\epsilon$？</p>
<ul>
<li>在nlp里面常用，起到正则化的作用，控制每个维度的值在合适的大小。</li>
<li><img src="https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/raw/main/imgs/72/72-05.png" alt="image" loading="lazy" /></li>
</ul>
</li>
</ul>
<p><code>小结</code></p>
<ul>
<li>深度学习模型大部分是非凸的</li>
<li>小批量随机梯度下降是最常见的优化算法</li>
<li>冲量是对梯度做平滑</li>
<li>Adam是对梯度做平滑，且对梯度各个维度值做重新调整，对于学习率不敏感</li>
</ul>
<h1>01-Regression</h1><h2>Machine Learning<span class="hx-absolute -hx-mt-20" id="machine-learning"></span>
    <a href="#machine-learning" class="subheading-anchor" aria-label="Permalink for this section"></a></h2><blockquote>
<p>概况：机器学习就是让机器具备找一个函式的能力。</p>
</blockquote>
<h2>三个机器学习任务<span class="hx-absolute -hx-mt-20" id="三个机器学习任务"></span>
    <a href="#%e4%b8%89%e4%b8%aa%e6%9c%ba%e5%99%a8%e5%ad%a6%e4%b9%a0%e4%bb%bb%e5%8a%a1" class="subheading-anchor" aria-label="Permalink for this section"></a></h2><ul>
<li>Regression：要找的函式,他的输出是一个数值</li>
<li>Classification:函式的输出,就是从设定好的选项裡面,选择一个当作输出</li>
<li>Structured Learning:机器产生有结构的东西的问题——学会创造</li>
</ul>
<h2>找函式的过程：三个步骤<span class="hx-absolute -hx-mt-20" id="找函式的过程三个步骤"></span>
    <a href="#%e6%89%be%e5%87%bd%e5%bc%8f%e7%9a%84%e8%bf%87%e7%a8%8b%e4%b8%89%e4%b8%aa%e6%ad%a5%e9%aa%a4" class="subheading-anchor" aria-label="Permalink for this section"></a></h2><ol>
<li>
<p>带有未知参数的函式</p>
<ul>
<li>带有Unknown的Parameter的Function =&gt; model</li>
</ul>
</li>
<li>
<p>定义一个东西叫做Loss(损失函数)</p>
<ul>
<li>Loss它也是一个Function,那这个Function它的输入,是 我们Model裡面的参数
<ul>
<li>L越大,代表一组参数越不好,这个大L越小,代表现在这一组参数越好</li>
<li>计算方法：求取估测的值跟实际的值（Label） 之间的差距
<ul>
<li>MAE(mean absolute error)——平均绝对误差</li>
<li><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/3ef87b78a9af65e308cf4aa9acf6f203efbdeded" alt="{\displaystyle \mathrm {MAE} ={\frac {\sum {i=1}^{n}\left|y{i}-x_{i}\right|}{n}}={\frac {\sum {i=1}^{n}\left|e{i}\right|}{n}}.}" loading="lazy" /></li>
<li>MSE(mean square error)——均方误差</li>
<li><img src="https://bkimg.cdn.bcebos.com/formula/845ae0515359869c505b869451eb4777.svg" alt="img" loading="lazy" /></li>
<li>Cross-entropy:计算<strong>概率分布</strong>之间的差距——交叉熵</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>
<p>Optimization(优化)</p>
<ul>
<li>
<p>找到能让损失函数值最小的参数</p>
</li>
<li>
<p>具体方法：Gradient Descent（梯度下降）</p>
<ol>
<li>
<p>随机选取初始值 $w_0$</p>
</li>
<li>
<p>计算在 $w=w_0$的时候,<em>w</em>这个参数对<em>loss</em>的微分是多少</p>
</li>
<li>
<p>根据微分（梯度）的方向，改变参数的值</p>
<ul>
<li><strong>改变的大小取决于：</strong>
<ol>
<li>斜率的大小</li>
<li>学习率的大小**（超参数）**</li>
</ol>
</li>
</ul>
</li>
<li>
<p>什么时候停下来？</p>
<ul>
<li>
<p>自己设置上限**（超参数）**</p>
</li>
<li>
<p>理想情况：微分值为0（极小值点），不会再更新⇒有可能陷入局部最小值，不能找到全局最小值</p>
<p><strong>事实上：局部最小值不是真正的问题！！！</strong></p>
</li>
</ul>
</li>
</ol>
</li>
</ul>
</li>
</ol>
<h2>Liner Model（线性模型）<span class="hx-absolute -hx-mt-20" id="liner-model线性模型"></span>
    <a href="#liner-model%e7%ba%bf%e6%80%a7%e6%a8%a1%e5%9e%8b" class="subheading-anchor" aria-label="Permalink for this section"></a></h2><p>==Sigmoid函数==</p>
<p>公式：</p>
<p><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/a26a3fa3cbb41a3abfe4c7ff88d47f0181489d13" alt="{\displaystyle S(t)={\frac {1}{1&#43;e^{-t}}}.}" loading="lazy" /></p>
<p>​</p>
<img src="https://diamond-mule-bee.notion.site/image/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2F18d619c4-5e89-4888-9f05-45e5e181d27f%2FUntitled.png?table=block&id=9300df07-51a3-4c32-805f-bd88c8e6c9e1&spaceId=effd33e2-527b-43dc-aef5-7b5ee7b83428&width=2000&userId=&cache=v2" alt="img" style="zoom: 67%;" />
<ul>
<li>Update：每次更新一次参数叫做一次 Update,</li>
<li>Epoch：把所有的 Batch 都看过一遍,叫做一个 Epoch</li>
</ul>
<p>模型变型⇒ReLU（Rectified Linear Unit，线性整流单元）</p>
<ul>
<li>把两个 ReLU 叠起来,就可以变成 Hard 的 Sigmoid</li>
</ul>
<p>==Softmax==</p>
<p>公式：</p>
<p><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/e348290cf48ddbb6e9a6ef4e39363568b67c09d3" alt="{\displaystyle \sigma (\mathbf {z} ){j}={\frac {e^{z{j}}}{\sum {k=1}^{K}e^{z{k}}}}}" loading="lazy" />  for <em>j</em> = 1, …, <em>K</em>.</p>
<p>**归一化指数函数。**它是二分类函数<a href="https://so.csdn.net/so/search?q=sigmoid&amp;spm=1001.2101.3001.7020" target="_blank" rel="noopener">sigmoid</a>在多分类上的推广，目的是将多分类的结果以概率的形式展现出来。</p>
<blockquote>
<p>多类分类模型</p>
<p>​		使用Softmax 操作子得到每个类的预测置信度</p>
<p>​		使用交叉熵来衡量预测和标号的区别</p>
</blockquote>
<h1>02.1-DeepLearning-General Guidance</h1><p><img src="https://diamond-mule-bee.notion.site/image/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2F6586a506-6ac8-43ad-a1d9-28e6de0b1fdb%2FUntitled.png?table=block&amp;id=53a2d275-3157-4673-93d0-c137a8465213&amp;spaceId=effd33e2-527b-43dc-aef5-7b5ee7b83428&amp;width=2000&amp;userId=&amp;cache=v2" alt="img" loading="lazy" /></p>
<h2>如何使模型达到更好的效果？<span class="hx-absolute -hx-mt-20" id="如何使模型达到更好的效果"></span>
    <a href="#%e5%a6%82%e4%bd%95%e4%bd%bf%e6%a8%a1%e5%9e%8b%e8%be%be%e5%88%b0%e6%9b%b4%e5%a5%bd%e7%9a%84%e6%95%88%e6%9e%9c" class="subheading-anchor" aria-label="Permalink for this section"></a></h2><ol>
<li>
<p>分析在训练数据上的Loss</p>
<ul>
<li>
<p>Model Bias</p>
<ul>
<li>
<p>所有的function集合起来,得到一个function的set.但是这个function的set太小了,没有包含任何一个function,可以让我们的loss变低⇒<strong>可以让loss变低的function,不在model可以描述的范围内。</strong></p>
<p>⇒解决方法：重新设计一个Model，**一个更复杂的、更有弹性的、有未知参数的、需要更多features的function</p>
</li>
</ul>
</li>
<li>
<p>Optimization</p>
</li>
<li>
<p>区分两种情况</p>
<ul>
<li>看到一个你从来没有做过的问题,也许你可以先跑一些比较小的,比较浅的network,或甚至用一些,不是deep learning的方法⇒比较容易做Optimize的,它们比较不会有optimization失败的问题</li>
<li>如果你发现你深的model,跟浅的model比起来,深的model明明弹性比较大,但loss却没有办法比浅的model压得更低,那就代表说你的optimization有问题</li>
</ul>
</li>
</ul>
</li>
<li>
<p>分析测试数据上的Loss</p>
<ul>
<li>
<p>Overfitting：training的loss小,testing的loss大,这个有可能是overfitting</p>
<p>如果你的model它的<strong>自由度很大</strong>的话,它可以<strong>产生非常奇怪的曲线</strong>,导致训练集上的结果好,但是测试集上的loss很大</p>
</li>
<li>
<p>解决方法</p>
<ul>
<li>增加训练集</li>
<li>限制模型，使其弹性不那么大
<ul>
<li>给它<strong>比较少的参数（比如神经元的数目）；模型</strong>共用参数**</li>
<li>使用<strong>比较少的features</strong></li>
<li>Early Stopping</li>
<li>Regularization</li>
<li>Dropout</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ol>
<p>==选出有较低testing-loss的模型==</p>
<ul>
<li>Cross Validation（交叉验证）</li>
</ul>
<img src="https://diamond-mule-bee.notion.site/image/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2F5782b3e5-2e99-488f-ba63-aaec6b59631d%2FUntitled.png?table=block&id=89a42d1a-8be3-41f5-923a-95f55307fb0d&spaceId=effd33e2-527b-43dc-aef5-7b5ee7b83428&width=2000&userId=&cache=v2" alt="img" style="zoom:50%;" />
<ol>
<li>把Training的资料分成两半,一部分叫作Training Set,一部分是Validation Set</li>
<li>在Validation Set上面,去衡量它们的分数,你根据Validation Set上面的分数,去挑选结果，不要管在public testing set上的结果，避免overfiting（过拟合）</li>
</ol>
<blockquote>
<p>总结</p>
<ul>
<li>
<p>训练数据集：训练模型参数</p>
</li>
<li>
<p>验证数据集：选择模型超参数</p>
</li>
<li>
<p>非大数据集上通常使用k-折交叉验证</p>
</li>
</ul>
<blockquote>
<p>k折交叉验证（ k-Folder Cross Validation），经常会用到的。 k折交叉验证先将数据集 D随机划分为 k个大小相同的互斥子集，即 ，每次随机的选择 k-1份作为训练集，剩下的1份做测试集。当这一轮完成后，重新随机选择 k份来训练数据。若干轮（小于 k ）之后，选择损失函数评估最优的模型和参数。注意，<strong>交叉验证法评估结果的稳定性和保真性在很大程度上取决于 k取值</strong>。</p>
</blockquote>
</blockquote>
<p>==分验证集==</p>
<ul>
<li>
<p>N-fold Cross Validation （N倍交叉验证）</p>
<p><strong>N-fold Cross Validation</strong>就是你先把你的训练集切成N等份,在这个例子里面我们切成N等份,切完以后,你拿其中一份当作Validation Set,另外N-1份当Training Set,重复N次</p>
<p>把这多个模型,在这三个setting下,通通跑过一次,把三种状况的结果都平均起来,看看谁的结果最好；最后再把选出来的model（这里是model 1）,用在全部的Training Set上,训练出来的模型,再用在Testing Set上面</p>
</li>
</ul>
<h2>权重衰退<span class="hx-absolute -hx-mt-20" id="权重衰退"></span>
    <a href="#%e6%9d%83%e9%87%8d%e8%a1%b0%e9%80%80" class="subheading-anchor" aria-label="Permalink for this section"></a></h2><p>模型在训练的过程中可能<strong>过拟合</strong>，这一般是由于数据复杂度太低而模型容量太大导致的，简而言之就是数据太简单，模型太复杂，模型学习到了数据的一切，包括噪音。此时，权重往往会很大（受噪音影响），显然模型并没有训练到最优（虽然它记住了训练数据的一切，但是对于新的样本泛化能力很差）。所以，<strong>我们想要适当降低权重，使模型接近最优，这样模型的泛化性能提升就适当的解决了过拟合问题，这就是权重衰退。</strong></p>
<img src="https://img-blog.csdnimg.cn/8e27156290e74d158ebd777a585b9c6b.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA5qmZ5a2Q5ZCWMjE=,size_17,color_FFFFFF,t_70,g_se,x_16" alt="img" style="zoom:67%;" />
<blockquote>
<p>总结</p>
<ul>
<li>
<p>权重衰退通过L2正则项使得模型参数不会过大，从而控制模型复杂度。</p>
</li>
<li>
<p>正则项权重是控制模型复杂度的超参数。</p>
</li>
</ul>
</blockquote>
<h2>丢弃法<span class="hx-absolute -hx-mt-20" id="丢弃法"></span>
    <a href="#%e4%b8%a2%e5%bc%83%e6%b3%95" class="subheading-anchor" aria-label="Permalink for this section"></a></h2><p>2012年，Alex、Hinton在其论文《ImageNet Classification with Deep Convolutional Neural Networks》中用到了Dropout算法，用于防止过拟合。</p>
<p>Dropout可以作为训练深度神经网络的一种正则方法供选择。在每个训练批次中，通过忽略一部分的神经元（<strong>让其隐层节点值为0</strong>），可以明显地减少过拟合现象。<strong>这种方式可以减少隐层节点间的相互作用</strong>，高层的神经元需要低层的神经元的输出才能发挥作用，如果<strong>高层神经元过分依赖某个低层神经元，就会有过拟合</strong>发生。在一次正向/反向的过程中，通过随机丢弃一些神经元，迫使高层神经元和其它的一些低层神经元协同工作，可以有效地防止神经元因为接收到过多的同类型参数而陷入过拟合的状态，来提高泛化程度。</p>
<p>正常：</p>
<img src="https://microsoft.github.io/ai-edu/%E5%9F%BA%E7%A1%80%E6%95%99%E7%A8%8B/A2-%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E6%9C%AC%E5%8E%9F%E7%90%86/%E7%AC%AC7%E6%AD%A5%20-%20%E6%B7%B1%E5%BA%A6%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/img/16/dropout_before.png" alt="img" style="zoom: 67%;" />
<p>丢弃后：</p>
<img src="https://microsoft.github.io/ai-edu/%E5%9F%BA%E7%A1%80%E6%95%99%E7%A8%8B/A2-%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E6%9C%AC%E5%8E%9F%E7%90%86/%E7%AC%AC7%E6%AD%A5%20-%20%E6%B7%B1%E5%BA%A6%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/img/16/dropout_after.png" alt="img" style="zoom:67%;" />
<blockquote>
<p>总结</p>
<ul>
<li>丢弃法将一些输出项随机置0来控制模型复杂度</li>
<li>常作用在多层感知机（MLP）的隐藏层输出上</li>
<li>丢弃概率是控制模型复杂度的超参数</li>
</ul>
</blockquote>
<h2>批量归一化<span class="hx-absolute -hx-mt-20" id="批量归一化"></span>
    <a href="#%e6%89%b9%e9%87%8f%e5%bd%92%e4%b8%80%e5%8c%96" class="subheading-anchor" aria-label="Permalink for this section"></a></h2><ul>
<li>最初论文目的是减少内部协变量转移（作者所说的“内部协变量转移”类似于上述的投机直觉，即<strong>变量值的分布在训练过程中会发生变化</strong>）</li>
<li>后续论文指出它是通过在每个小批量加入噪音，来控制模型复杂度</li>
</ul>
<img src="C:\Users\11842\AppData\Roaming\Typora\typora-user-images\image-20221023111910705.png" alt="image-20221023111910705" style="zoom:67%;" />
<blockquote>
<p>理解：在每一层输入和上一层输出之间加入了一个新的计算层，对数据的分布进行额外的约束，从而增强模型的泛化能力。 但是批量归一化同时也降低了模型的拟合能力，归一化之后的输入分布被强制拉到均值为0和标准差为1的正态分布上来。</p>
<p>作用是持续加深深层网络的收敛速度，这使得研究人员能够训练100层以上的网络</p>
</blockquote>
<ul>
<li>
<p>批量规范化和其他层之间的一个关键区别是</p>
<ul>
<li>由于批量规范化在完整的小批量上运行，因此我们不能像以前在引入其他层时那样忽略批量大小。</li>
</ul>
</li>
<li>
<p>可学习的参数为γ-缩放（gamma）和β-偏移（beta）</p>
</li>
<li>
<p>作用在</p>
<ul>
<li>全连接层和卷积层输出上，激活函数前</li>
<li>全连接层和卷积层输入上</li>
</ul>
</li>
<li>
<p>for 全连接层，作用在特征维</p>
</li>
<li>
<p>for 卷积层，作用在通道维</p>
</li>
</ul>
<p><code>代码</code></p>
<div class="hextra-code-block hx-relative hx-mt-6 first:hx-mt-0 hx-group/code">
  

<div><div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">batch_norm</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">gamma</span><span class="p">,</span> <span class="n">beta</span><span class="p">,</span> <span class="n">moving_mean</span><span class="p">,</span> <span class="n">moving_var</span><span class="p">,</span> <span class="n">eps</span><span class="p">,</span> <span class="n">momentum</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># 通过is_grad_enabled来判断当前模式是训练模式还是预测模式</span>
</span></span><span class="line"><span class="cl">    <span class="k">if</span> <span class="ow">not</span> <span class="n">torch</span><span class="o">.</span><span class="n">is_grad_enabled</span><span class="p">():</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># 如果是在预测模式下，直接使用传入的移动平均所得的均值和方差</span>
</span></span><span class="line"><span class="cl">        <span class="n">X_hat</span> <span class="o">=</span> <span class="p">(</span><span class="n">X</span> <span class="o">-</span> <span class="n">moving_mean</span><span class="p">)</span> <span class="o">/</span> <span class="n">torch</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">moving_var</span> <span class="o">+</span> <span class="n">eps</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="k">else</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">        <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="ow">in</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="c1"># 使用全连接层的情况，计算特征维上的均值和方差</span>
</span></span><span class="line"><span class="cl">            <span class="n">mean</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">            <span class="n">var</span> <span class="o">=</span> <span class="p">((</span><span class="n">X</span> <span class="o">-</span> <span class="n">mean</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="k">else</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="c1"># 使用二维卷积层的情况，计算通道维上（axis=1）的均值和方差。</span>
</span></span><span class="line"><span class="cl">            <span class="c1"># 这里我们需要保持X的形状以便后面可以做广播运算</span>
</span></span><span class="line"><span class="cl">            <span class="n">mean</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">            <span class="n">var</span> <span class="o">=</span> <span class="p">((</span><span class="n">X</span> <span class="o">-</span> <span class="n">mean</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># 训练模式下，用当前的均值和方差做标准化</span>
</span></span><span class="line"><span class="cl">        <span class="n">X_hat</span> <span class="o">=</span> <span class="p">(</span><span class="n">X</span> <span class="o">-</span> <span class="n">mean</span><span class="p">)</span> <span class="o">/</span> <span class="n">torch</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">var</span> <span class="o">+</span> <span class="n">eps</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># 更新移动平均的均值和方差</span>
</span></span><span class="line"><span class="cl">        <span class="n">moving_mean</span> <span class="o">=</span> <span class="n">momentum</span> <span class="o">*</span> <span class="n">moving_mean</span> <span class="o">+</span> <span class="p">(</span><span class="mf">1.0</span> <span class="o">-</span> <span class="n">momentum</span><span class="p">)</span> <span class="o">*</span> <span class="n">mean</span>
</span></span><span class="line"><span class="cl">        <span class="n">moving_var</span> <span class="o">=</span> <span class="n">momentum</span> <span class="o">*</span> <span class="n">moving_var</span> <span class="o">+</span> <span class="p">(</span><span class="mf">1.0</span> <span class="o">-</span> <span class="n">momentum</span><span class="p">)</span> <span class="o">*</span> <span class="n">var</span>
</span></span><span class="line"><span class="cl">    <span class="n">Y</span> <span class="o">=</span> <span class="n">gamma</span> <span class="o">*</span> <span class="n">X_hat</span> <span class="o">+</span> <span class="n">beta</span>  <span class="c1"># 缩放和移位</span>
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="n">Y</span><span class="p">,</span> <span class="n">moving_mean</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="n">moving_var</span><span class="o">.</span><span class="n">data</span></span></span></code></pre></div></div><div class="hextra-code-copy-btn-container hx-opacity-0 hx-transition group-hover/code:hx-opacity-100 hx-flex hx-gap-1 hx-absolute hx-m-[11px] hx-right-0 hx-top-0">
  <button
    class="hextra-code-copy-btn hx-group/copybtn hx-transition-all active:hx-opacity-50 hx-bg-primary-700/5 hx-border hx-border-black/5 hx-text-gray-600 hover:hx-text-gray-900 hx-rounded-md hx-p-1.5 dark:hx-bg-primary-300/10 dark:hx-border-white/10 dark:hx-text-gray-400 dark:hover:hx-text-gray-50"
    title="Copy code"
  >
    <div class="copy-icon group-[.copied]/copybtn:hx-hidden hx-pointer-events-none hx-h-4 hx-w-4"></div>
    <div class="success-icon hx-hidden group-[.copied]/copybtn:hx-block hx-pointer-events-none hx-h-4 hx-w-4"></div>
  </button>
</div>

  
</div>
<p><code>小结</code></p>
<ul>
<li>批量归一化固定小批量中的均值和方差，然后学习出适合的偏移和缩放</li>
<li>加速收敛速度，但一般不改变模型精度</li>
</ul>
<h1>02.2-类神经网络优化技巧</h1><h2>critical point 概述<span class="hx-absolute -hx-mt-20" id="critical-point-概述"></span>
    <a href="#critical-point-%e6%a6%82%e8%bf%b0" class="subheading-anchor" aria-label="Permalink for this section"></a></h2><p>==临界点==：梯度 （grad） 为 0 的点</p>
<p>loss,无法再下降,也许是因为卡在了critical point ⇒ local minima（局部最小值） OR saddle point（鞍点）</p>
<ul>
<li>局部最小值 -&gt; 可能无路可走</li>
<li>鞍点 -&gt; 旁边还是有路可走</li>
</ul>
<p><code>判断θ附近loss的梯度 -&gt; 泰勒展开 -&gt; 海塞矩阵</code></p>
<img src="https://diamond-mule-bee.notion.site/image/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2Fcad56cb3-6fc6-4488-b1cd-b567fea2075c%2FUntitled.png?table=block&id=1038a41a-a019-41ec-9e08-2e9a062e9bfc&spaceId=effd33e2-527b-43dc-aef5-7b5ee7b83428&width=2000&userId=&cache=v2" alt="img" style="zoom:50%;" />
<img src="https://diamond-mule-bee.notion.site/image/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2F515415e7-dcaa-499c-8dcb-9268061f824e%2FUntitled.png?table=block&id=5d24c4da-36ca-43f5-9ea0-1c8935326271&spaceId=effd33e2-527b-43dc-aef5-7b5ee7b83428&width=2000&userId=&cache=v2" alt="img" style="zoom:50%;" />
<ul>
<li>
<p>g：一次微分，当到达临界点时，表示g为0，则绿色项不存在，原式等于第一项加红色项</p>
</li>
<li>
<p>H：二次微分，根据红色项来判断临界点为哪种情况</p>
</li>
</ul>
<img src="https://diamond-mule-bee.notion.site/image/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2Fc88a449d-25e8-4c35-9e3f-5afe3e46e7b0%2FUntitled.png?table=block&id=15c6ddd8-63da-45eb-8499-085c395e3542&spaceId=effd33e2-527b-43dc-aef5-7b5ee7b83428&width=2000&userId=&cache=v2" alt="img" style="zoom: 67%;" />
<ul>
<li>红色部分 大于0，左边永远大于右边 L(θ`)，所以该点为最小值点</li>
<li>红色部分 小于0，左边永远小于右边 L(θ`)，所以该点为最大值点</li>
<li>红色部分有时大于0有时小于0，则为鞍点</li>
</ul>
<blockquote>
<p>注：如果走到鞍点，可以利用H的特征向量确定参数的更新方向</p>
<p>令特征值小于0，得到对应的特征向量u,在θ`的位置加上u,沿著u的方向做update得到θ,就可以让loss变小。</p>
<blockquote>
<p>Local Minima比Saddle Point少的多</p>
</blockquote>
</blockquote>
<h3>Small Batch v.s. Large Batch<span class="hx-absolute -hx-mt-20" id="small-batch-vs-large-batch"></span>
    <a href="#small-batch-vs-large-batch" class="subheading-anchor" aria-label="Permalink for this section"></a></h3><p><code>batch_size 取大取小的关系：</code></p>
<ul>
<li>
<p>结论1：使用较小的BatchSize，在更新参数时会有Noisy（图中曲线弯弯折折）⇒有利于训练</p>
<ul>
<li>不同的Batch 求得的Loss略有差异，可以避免局部极小值“卡住”</li>
</ul>
<p><img src="https://diamond-mule-bee.notion.site/image/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2F9ec2c77d-56dd-4f99-8efc-782ffa48586f%2FUntitled.png?table=block&amp;id=b876aaa1-e583-4960-997f-2a5d62968d22&amp;spaceId=effd33e2-527b-43dc-aef5-7b5ee7b83428&amp;width=2000&amp;userId=&amp;cache=v2" alt="img" loading="lazy" /></p>
</li>
<li>
<p>结论2：使用较小的BatchSize,可以避免Overfitting ⇒ 有利于测试(Testing)</p>
<ul>
<li>SB 在数据集（测试集）表现更好</li>
</ul>
<img src="https://diamond-mule-bee.notion.site/image/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2F149f4354-b2a9-41ee-bf78-a3e96d1ca042%2FUntitled.png?table=block&id=91fc00ba-88ff-4e1b-bcf4-2512b8047204&spaceId=effd33e2-527b-43dc-aef5-7b5ee7b83428&width=2000&userId=&cache=v2" alt="img" style="zoom: 80%;" />
</li>
<li>
<p>总结：BatchSize是一个需要调整的参数，它会影响训练速度与优化效果。</p>
<img src="https://diamond-mule-bee.notion.site/image/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2F3158ec11-5567-4ef4-a7d6-79d3db676675%2FUntitled.png?table=block&id=6160f7de-7bcc-4299-8e1d-39cf98246302&spaceId=effd33e2-527b-43dc-aef5-7b5ee7b83428&width=1090&userId=&cache=v2" alt="img" style="zoom: 80%;" />
</li>
</ul>
<h3>Momentum（动量）<span class="hx-absolute -hx-mt-20" id="momentum动量"></span>
    <a href="#momentum%e5%8a%a8%e9%87%8f" class="subheading-anchor" aria-label="Permalink for this section"></a></h3><blockquote>
<p>所谓的 Momentum, Update 的方向不是只考虑现在的 Gradient,而是考虑过去所有 Gradient 的总合</p>
</blockquote>
<ul>
<li>Vanilla Gradient Descent（一般的梯度下降）⇒ 只考虑梯度的方向，向反方向移动</li>
<li>Gradient Descent + Momentum（考虑动量）⇒ 综合梯度+前一步的方向</li>
</ul>
<h3>总结 - 关于“小梯度”<span class="hx-absolute -hx-mt-20" id="总结---关于小梯度"></span>
    <a href="#%e6%80%bb%e7%bb%93---%e5%85%b3%e4%ba%8e%e5%b0%8f%e6%a2%af%e5%ba%a6" class="subheading-anchor" aria-label="Permalink for this section"></a></h3><ul>
<li>临界点的梯度为 0</li>
<li>临界值点可以是鞍点或者局部最小值点
<ul>
<li>可以通过海塞矩阵确定</li>
<li>局部最小值可能很少见</li>
<li>有可能沿着海塞矩阵的特征向量的方向逃出鞍点</li>
</ul>
</li>
<li>较小的批次规模和动量有利于避开临界点</li>
</ul>
<h3>自适应学习率<span class="hx-absolute -hx-mt-20" id="自适应学习率"></span>
    <a href="#%e8%87%aa%e9%80%82%e5%ba%94%e5%ad%a6%e4%b9%a0%e7%8e%87" class="subheading-anchor" aria-label="Permalink for this section"></a></h3><p><code>Error Surface</code>: 根据不同参数，计算Loss得到的等高线图</p>
<ul>
<li>Training  stuck 训练卡住或暂停不一定是最小梯度 -&gt; Loss不再下降时，未必说明到达临界点，梯度可能还很大</li>
</ul>
<img src="https://diamond-mule-bee.notion.site/image/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2Fb0915a78-64fd-4120-87b1-2a03ca9f3318%2FUntitled.png?table=block&id=6c742f56-dd7f-4176-b101-1aedf57fe0ab&spaceId=effd33e2-527b-43dc-aef5-7b5ee7b83428&width=2000&userId=&cache=v2" alt="img" style="zoom:67%;" />
<ul>
<li>客制化“学习率”
<ul>
<li>较大的学习率：Loss在山谷的两端震荡而不会下降</li>
<li>较小的学习率：梯度较小时几乎难以移动</li>
</ul>
</li>
</ul>
<blockquote>
<p>客制化“梯度” ⇒  不同的参数（大小）需要不同的学习率</p>
<blockquote>
<p><strong>基本原则：</strong></p>
<ul>
<li>某一个方向上gradient的值很小,非常的平坦⇒learning rate调大一点,</li>
<li>某一个方向上非常的陡峭,坡度很大⇒learning rate可以设得小一点</li>
</ul>
</blockquote>
</blockquote>
<p><code>Adagrad</code>: 每次更新的𝜂就是等于前一次的𝜂再除以𝜎^t，而 σ^t则代表的是第 t 次以前的所有梯度更新值之平方和开根号(root mean square)。</p>
<ul>
<li>gradient都比较大,σ就比较大,在update的时候 参数update的量就比较小。
<ul>
<li>缺陷 ⇒ 不能“实时”考虑梯度的变化情况</li>
</ul>
</li>
</ul>
<p><code>RMSProp</code>:</p>
<p>添加参数$\alpha$，越大说明过去的梯度信息<strong>更重要</strong></p>
<ul>
<li>α设很小趋近於0,就代表这一步算出的gᵢ相较於之前所算出来的gradient而言比较重要</li>
<li>α设很大趋近於1,就代表现在算出来的gᵢ比较不重要,之前算出来的gradient比较重要</li>
</ul>
<p><code>最常用的策略：Adam=RMSProp + Momentum</code></p>
<p>​	Adam其实就是加了momentum的RMSProp，下图的公式mt代表的是momentum，就是前一个时间点的movement（momentum动量），vt就是RMSProp裡的σ，式子虽然看起來很复杂，但其實跟RMSProp很類似，</p>
<p>​	每次更新都會调整新的gradient的比重。所以<strong>Adam</strong>继承两者的优点，适合大部分的状况，为目前最常使用的优化方法。</p>
<p><img src="https://miro.medium.com/max/1400/1*EmEGVj6OvV0kEdsT-nyIlg.png" alt="img" style="zoom:50%;" /><img src="https://miro.medium.com/max/780/1*_oz4zR8-sUB6a7lf3j42Bw.png" alt="img" loading="lazy" /></p>
<blockquote>
<p>Learning Rate Decay：随著时间的不断地进行,随著参数不断的update,η越来越小</p>
</blockquote>
<p><code>Warm Up⇒让learning rate先变大后变小</code></p>
<ul>
<li>
<p>在一开始，<strong>σ^t</strong>下标 **i **的估计值有很大的方差</p>
</li>
<li>
<p>σ指示某一个方向它到底有多陡/多平滑,这个统计的结果,要看得够多笔数据以后才精准,所以一开始我们的统计是不精準的。一开始learning rate比较小，是让它探索收集一些有关error surface的情报，在这一阶段使用较小的learning rate，限制参数不会走的离初始的地方太远；等到σ统计得比较精準以后再让learning rate慢慢爬升</p>
</li>
</ul>
<h3>总结<span class="hx-absolute -hx-mt-20" id="总结"></span>
    <a href="#%e6%80%bb%e7%bb%93" class="subheading-anchor" aria-label="Permalink for this section"></a></h3><ol>
<li>使用动量，考虑过去的梯度**“大小”与“方向”**</li>
<li>引入$\sigma$,考虑过去梯度的“<strong>大小</strong>”（RMS）</li>
<li>使用LearningRate Schedule</li>
</ol>
<h3>另一种思路<span class="hx-absolute -hx-mt-20" id="另一种思路"></span>
    <a href="#%e5%8f%a6%e4%b8%80%e7%a7%8d%e6%80%9d%e8%b7%af" class="subheading-anchor" aria-label="Permalink for this section"></a></h3><ul>
<li>将Error Surface“铲平”  ⇒  Batch Normalization 批次标准化（归一化）</li>
<li><strong>解决：给不同的 dimension同样的数值范围  ⇒  Feature Normalization(归一化)</strong>
<ul>
<li>一种Standardization（标准化）方法：对不同数据样本向量的<strong>同一维</strong>进行归一化</li>
<li>做完 normalize 以后,这个 dimension 上面的数值就会平均是 0,然后它的 variance就会是 1,所以<strong>这一排数值的分布就都会在 0 上下</strong></li>
<li>对每一个 dimension都做一样的 normalization,就会发现所有 feature 不同 dimension 的数值都在 0 上下,那你可能就可以<strong>制造一个,比较好的 error surface</strong></li>
</ul>
</li>
<li>在深度学习中，每一层都需要一次Normalization
<ul>
<li>对向量的对应element做求平均、标准差的运算，求得向量$\mu,\sigma$</li>
<li>对每个向量$z$,利用$\mu,\sigma$对对应element进行归一化，得到$\tilde{z}$</li>
<li>继续后续的步骤</li>
</ul>
</li>
</ul>
<blockquote>
<p>注意理解：“对一批z数据进行归一化”  ⇒  “网络”模型变为能够一次处理“一批x数据”的模型，数据之间相互关联</p>
<p>Batch Normalization：实际上做Normalization时，只能考虑有限数量的数据⇒考虑一个Batch内的数据⇒近似整个数据集</p>
<blockquote>
<p>Batch Normalization适用於 batch size 比较大时。其中data可以认为足以表示整个 corpus 的分布；从而，将对整个 corpus做 Feature Normalization 这件事情,改成只在一个 batch中做 Feature Normalization作为近似</p>
</blockquote>
</blockquote>
<h1>02.3-DeepLearning-Loss of Classification</h1><blockquote>
<p>各种损失函数的建议</p>
</blockquote>
<h2>Classification as Regression<span class="hx-absolute -hx-mt-20" id="classification-as-regression"></span>
    <a href="#classification-as-regression" class="subheading-anchor" aria-label="Permalink for this section"></a></h2><p><code>Classification with softmax</code></p>
<p><img src="https://diamond-mule-bee.notion.site/image/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2F96fb2865-7d3f-42ea-acee-6da18cdd6260%2FUntitled.png?table=block&amp;id=60e4d4be-6caf-4908-8b47-02633b3d4976&amp;spaceId=effd33e2-527b-43dc-aef5-7b5ee7b83428&amp;width=2000&amp;userId=&amp;cache=v2" alt="img" loading="lazy" /></p>
<p>我们的目标只有0跟1,而y有任何值,我们就使用Softmax先把它Normalize到0到1之间,这样才好跟 label 的计算相似度</p>
<img src="https://diamond-mule-bee.notion.site/image/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2Ff52d8d7e-0ba4-4e96-8109-6eb741ec3a2d%2FUntitled.png?table=block&id=15c46703-192d-46ae-9e96-4918fd19edcb&spaceId=effd33e2-527b-43dc-aef5-7b5ee7b83428&width=2000&userId=&cache=v2" alt="img" style="zoom:67%;" />
<p>经过计算后：</p>
<ul>
<li>输出值变成0到1之间</li>
<li>输出值的和為1</li>
<li>原本大的值跟小的值的<strong>差距更大</strong></li>
</ul>
<p>Softmax的输入，称作<strong>Logit</strong></p>
<blockquote>
<p>二分类：使用sigmoid与softmax是等价的</p>
</blockquote>
<h2>优化目标：减小y^和y&rsquo;之间的差距e<span class="hx-absolute -hx-mt-20" id="优化目标减小y和y之间的差距e"></span>
    <a href="#%e4%bc%98%e5%8c%96%e7%9b%ae%e6%a0%87%e5%87%8f%e5%b0%8fy%e5%92%8cy%e4%b9%8b%e9%97%b4%e7%9a%84%e5%b7%ae%e8%b7%9de" class="subheading-anchor" aria-label="Permalink for this section"></a></h2><ul>
<li>
<p>在分类问题上，交叉熵相比较 MSE 更加适合</p>
</li>
<li>
<blockquote>
<p>注：在Pytorch中，softmax 函数被内建在Cross-enrtopy 损失函数中</p>
</blockquote>
</li>
<li>
<p>从优化角度出发进行讨论，使用MSE时，左上角的位置虽然Loss很大，但梯度平坦，难以优化；而Cross-entropy则更易收敛⇒改变Loss函数，也会影响训练的过程</p>
</li>
</ul>
<img src="https://diamond-mule-bee.notion.site/image/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2F1f6dae63-ffbc-41c6-83ee-bcf286ef2764%2FUntitled.png?table=block&id=e028b452-d68c-4a12-be9e-42962d24b75a&spaceId=effd33e2-527b-43dc-aef5-7b5ee7b83428&width=2000&userId=&cache=v2" alt="img" style="zoom: 80%;" />
<h1>03-CNN</h1><p>==网络模型的架构设计思想==</p>
<h2>场景： 图片分类<span class="hx-absolute -hx-mt-20" id="场景-图片分类"></span>
    <a href="#%e5%9c%ba%e6%99%af-%e5%9b%be%e7%89%87%e5%88%86%e7%b1%bb" class="subheading-anchor" aria-label="Permalink for this section"></a></h2><ul>
<li>一般过程：
<ul>
<li>把所有图片都先 Rescale 成大小一样</li>
<li>把每一个类别,表示成一个 One-Hot 的 Vector（Dimension 的长度就决定了模型可以辨识出多少不同种类的东西,）</li>
<li>将图像【输入】到模型中</li>
</ul>
</li>
<li>如何将图片输入到模型中？⇒  一般思路：展平→参数量过大</li>
</ul>
<h2>神经元角度<span class="hx-absolute -hx-mt-20" id="神经元角度"></span>
    <a href="#%e7%a5%9e%e7%bb%8f%e5%85%83%e8%a7%92%e5%ba%a6" class="subheading-anchor" aria-label="Permalink for this section"></a></h2><p><code>观察（1）：模型通过识别一些“特定模式”来识别物体，而非“整张图”</code></p>
<p><code>简化（1）：设定“感受野”（Receptive Field）</code></p>
<ul>
<li>
<p>每个神经元只需要考察特定范围内的图像信息，将图像内容展平后输入到神经元中即可</p>
<ul>
<li>感受野之间可以重叠</li>
<li>一个感受野可以有多个神经元“守备”</li>
<li>感受野大小可以“有大有小”</li>
<li>感受野可以只考虑某一些Channel</li>
<li>感受野可以是“长方形”的</li>
<li>感受野不一定要“相连”</li>
</ul>
</li>
<li>
<p>感受野的基本设置</p>
<ul>
<li>
<p>看所有的Channel</p>
<p>一般在做影像辨识的时候会看全部的 Channel。那么，在描述一个 Receptive Field 的时候,无需说明其Channel数，只要讲它的<strong>高、宽⇒Kernel Size</strong></p>
<p>一般不做过大的kernal Size，<strong>常常设定为</strong>$3\times3$</p>
</li>
<li>
<p>每个感受野会有<strong>不止一个神经元进行“守备”⇒输出通道数/卷积核数目</strong></p>
</li>
<li>
<p>不同的感受野之间的关系⇒感受野的平移位移：stride【hyperparameter】</p>
<p>一般希望感受野之间有重叠，避免交界处的pattern被忽略</p>
</li>
<li>
<p>感受野超出影响的范围⇒padding（补值）</p>
<p>补0；补平均值；补边缘值……</p>
</li>
<li>
<p>垂直方向移动</p>
</li>
</ul>
</li>
</ul>
<p><code>观察（2）：同样的pattern，可能出现在图片的“不同位置”</code></p>
<p><code>简化（2）：不同 Receptive Field 的 Neuron共享参数⇒ Parameter Sharing权值共享</code></p>
<ul>
<li>对每个感受野，都使用一组相同的神经元进行守备；这一组神经元被称作filter，对不同感受野使用的filter参数相同</li>
</ul>
<h3>卷积层的优势<span class="hx-absolute -hx-mt-20" id="卷积层的优势"></span>
    <a href="#%e5%8d%b7%e7%a7%af%e5%b1%82%e7%9a%84%e4%bc%98%e5%8a%bf" class="subheading-anchor" aria-label="Permalink for this section"></a></h3><blockquote>
<p>卷积层是“受限”（弹性变小）的FC（全连接层）</p>
</blockquote>
<img src="https://diamond-mule-bee.notion.site/image/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2Ff84607df-a9c7-4df9-a346-6e64b748e790%2FUntitled.png?table=block&id=32d002ac-b6d6-46b1-8658-e6a1b1ede39c&spaceId=effd33e2-527b-43dc-aef5-7b5ee7b83428&width=2000&userId=&cache=v2" alt="img" style="zoom:67%;" />
<ul>
<li>FC可以通过“学习”决定要看到的“图片”的范围。加上“感受野”概念后，就只能看某一个范围。</li>
<li>FC可以自由决定守备不同“感受野”的各个神经元参数。加上“权值共享”概念后，守备不同感受野的<strong>同一个滤波器（filter）参数相同。</strong></li>
</ul>
<p><strong>分析：</strong></p>
<ul>
<li>一般而言，Model Bias 小,Model 的 Flexibility 很高的时候,它比较容易 Overfitting,Fully Connected Layer可以做各式各样的事情,它<strong>可以有各式各样的变化</strong>,但是它可能没有办法在任何<strong>特定的任务</strong>上做好</li>
<li>CNN 的 Bias 比较大，它是专门為影像设计的，所以它在影像上仍然可以做得好。</li>
</ul>
<h2>滤波器角度<span class="hx-absolute -hx-mt-20" id="滤波器角度"></span>
    <a href="#%e6%bb%a4%e6%b3%a2%e5%99%a8%e8%a7%92%e5%ba%a6" class="subheading-anchor" aria-label="Permalink for this section"></a></h2><p>卷积层中有若干个filter，每个filter可以用来“抓取”图片中的某一种特征（特征pattern的大小，小于感受野大小）。</p>
<p>ilter的参数，其实就是神经元中的“权值（weight）”。</p>
<p>不同的filter扫过一张图片，将会产生“新的图片”，每个filter将会产生图片中的一个channel⇒<strong>feature map</strong></p>
<p>filter的计算是**“内积”**：filter跟图片对应位置的数值直接相乘，所有的都乘完以后再相加。</p>
<p><code>多层卷积</code></p>
<ul>
<li>多层卷积⇒让“小”卷积核看到“大”pattern</li>
</ul>
<h2>总结<span class="hx-absolute -hx-mt-20" id="总结-1"></span>
    <a href="#%e6%80%bb%e7%bb%93-1" class="subheading-anchor" aria-label="Permalink for this section"></a></h2><ul>
<li>对全连接层使用<strong>平移不变性</strong>和<strong>局部性</strong>得到卷积层</li>
<li>填充和步幅
<ul>
<li>这两者是卷积层的超参数</li>
<li><strong>padding</strong>  避免信息损失，填充在输入周围添加额外的行或列，来控制输出形状的减少量，例如输入3×3，输出为4×4</li>
<li><strong>stride</strong>  压缩一部分信息，步幅是每次滑动卷积核窗口的行或列步长，可以<strong>成倍的减少输出形状</strong></li>
</ul>
</li>
</ul>
<p>两个角度理解“卷积”：神经元角度（neuron）与滤波器（filter）</p>
<table>
<thead>
<tr>
<th style="text-align:center"></th>
<th style="text-align:center">不用看整张图片范围</th>
<th style="text-align:center">图片不同位置的相同模式pattern</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">神经元</td>
<td style="text-align:center">只要守备感受野</td>
<td style="text-align:center">守备不同感受野的神经元共用参数</td>
</tr>
<tr>
<td style="text-align:center">滤波器</td>
<td style="text-align:center">使用滤波器侦测模式pattern</td>
<td style="text-align:center">滤波器“扫过”整张图片</td>
</tr>
</tbody>
</table>
<h2>池化层 Pooling<span class="hx-absolute -hx-mt-20" id="池化层-pooling"></span>
    <a href="#%e6%b1%a0%e5%8c%96%e5%b1%82-pooling" class="subheading-anchor" aria-label="Permalink for this section"></a></h2><p>==图片降采样不影响图片的辨析⇒Pooling（池化）把图片变小，减小运算量==</p>
<blockquote>
<p>Pooling本身没有参数,所以它不是一个 Layer，没有要 Learn 的东西。行为类似于一个 Activation Function,（Sigmoid ， ReLU ），是一个 Operator，行为固定</p>
<p>分类：</p>
<ul>
<li>Max pooling 最大池化层：每个窗口最强的模式信号</li>
<li>Avg Pooling 平均池化层：将最大池化层中的“最大”操作替换为“平均”</li>
</ul>
</blockquote>
<p>总结：</p>
<ul>
<li>池化层返回窗口中最大或平均值</li>
<li>缓解卷积层对位置的敏感性</li>
<li>同样有窗口大小，填充，步幅等超参数</li>
</ul>
<h2>The whole CNN（典型分类网络结构）<span class="hx-absolute -hx-mt-20" id="the-whole-cnn典型分类网络结构"></span>
    <a href="#the-whole-cnn%e5%85%b8%e5%9e%8b%e5%88%86%e7%b1%bb%e7%bd%91%e7%bb%9c%e7%bb%93%e6%9e%84" class="subheading-anchor" aria-label="Permalink for this section"></a></h2><p>conv-pooling-&hellip;（循环）-flatten-FC-softmax</p>
<ul>
<li>
<p>一般：卷积与池化交替使用。pooling⇒可有可无（算力支撑）</p>
</li>
<li>
<p>算力足够 -&gt;  无需池化
Pooling对于 Performance,会带来一点伤害的。如果你运算资源足够支撑你不做 Pooling 的话,很多 Network 的架构的设计,往往今天就不做 Pooling,全 Convolution。</p>
</li>
</ul>
<blockquote>
<p>最后注意：</p>
<p>CNN 并不能够处理影像放大缩小,或者是旋转的问题。所以在做影像辨识的时候,往往都要做 Data Augmentation（数据增强），把你的训练数据截一小块出来放大缩小、把图片旋转,CNN 才会做到好的结果。</p>
<p>有一个架构叫 spacial Transformer Layer可以处理。</p>
</blockquote>
<h1>04-Self-attention</h1><h2>attention<span class="hx-absolute -hx-mt-20" id="attention"></span>
    <a href="#attention" class="subheading-anchor" aria-label="Permalink for this section"></a></h2><blockquote>
<p><strong>Attention机制</strong>就是让<code>编码器编码出来的向量根据解码器要解码的东西动态变化的一种机制</code>，貌似来源灵感就是人类视觉在看某一个东西的时候会有选择的针对重要的地方看。</p>
</blockquote>
<p><code>计算attention</code></p>
<ol>
<li>第一步是将query和每个key进行相似度计算得到权重，常用的相似度函数有点积，拼接，感知机等</li>
<li>第二步一般是使用一个softmax函数对这些权重进行归一化</li>
<li>第三步将权重和相应的键值value进行加权求和得到最后的attention。目前在NLP研究中，key和value常常都是同一个，即<strong>key=value</strong></li>
</ol>
<blockquote>
<p><strong>Attention</strong>机制发生在Target（输出）的元素Query（查询）和Source（输入）中的所有元素之间。</p>
<ul>
<li>比如entity1，entity2，entity3….，attn会输出[0.1，0.2，0.5，….]这种，告诉你entity3重要些。</li>
</ul>
<p>而 <strong>Self-attention</strong>，它指的不是Target和Source之间的Attention机制，而是Source内部元素之间或者Target内部元素之间发生的Attention机制，也可以理解为Target=Source这种特殊情况下的注意力计算机制。<strong>Q=K=V</strong>。</p>
<ul>
<li>self attention会给你一个矩阵，告诉你 entity1 和entity2、entity3 ….的关联程度、entity2和entity1、entity3…的关联程度。</li>
</ul>
<p>总结：</p>
<ul>
<li>
<p>attention是source对target的attention</p>
</li>
<li>
<p>self attention 是source 对source的attention。</p>
</li>
</ul>
<p>例如：</p>
<p>Transformer中在计算权重参数时将文字向量转成对应的KQV，只需要在Source处进行对应的矩阵操作，用不到Target中的信息。</p>
</blockquote>
<h2>Self-attention v.s. CNN<span class="hx-absolute -hx-mt-20" id="self-attention-vs-cnn"></span>
    <a href="#self-attention-vs-cnn" class="subheading-anchor" aria-label="Permalink for this section"></a></h2><img src="https://diamond-mule-bee.notion.site/image/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2Ff7af7984-e535-4c87-bcc7-b678b6e5402f%2FUntitled.png?table=block&id=bc9d4c30-939d-49bf-b64f-7fa7e6a5a189&spaceId=effd33e2-527b-43dc-aef5-7b5ee7b83428&width=2000&userId=&cache=v2" alt="img" style="zoom:67%;" />
<p><code>两者对比</code></p>
<ul>
<li>CNN：感知域（receptive field）是人为设定的，只考虑范围内的信息</li>
<li>Self-attention：考虑一个像素和整张图片的信息⇒自己学出“感知域”的形状和大小</li>
</ul>
<p><strong>结论：CNN就是 Self-attention 的特例,Self-attention 只要设定合适的参数,它可以做到跟 CNN 一模一样的事情</strong></p>
<p><strong>self attention,是更 flexible 的 CNN</strong></p>
<p><strong>⇒self-attention需要更多的数据进行训练，否则会欠拟合；否则CNN的性能更好</strong></p>
<ul>
<li>Self-attention 它弹性比较大,所以需要比较多的训练资料,训练资料少的时候,就会 overfitting</li>
<li>而 CNN 它弹性比较小,在训练资料少的时候,结果比较好,但训练资料多的时候,它没有办法从更大量的训练资料得到好处</li>
</ul>
<h2>Self-attention v.s. RNN（循环神经网络）<span class="hx-absolute -hx-mt-20" id="self-attention-vs-rnn循环神经网络"></span>
    <a href="#self-attention-vs-rnn%e5%be%aa%e7%8e%af%e7%a5%9e%e7%bb%8f%e7%bd%91%e7%bb%9c" class="subheading-anchor" aria-label="Permalink for this section"></a></h2><img src="https://diamond-mule-bee.notion.site/image/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2Fbbf60895-7a71-416f-b617-003aa847020e%2FUntitled.png?table=block&id=93343e26-2054-43ba-bcf7-102f0e3e8cc1&spaceId=effd33e2-527b-43dc-aef5-7b5ee7b83428&width=2000&userId=&cache=v2" alt="img" style="zoom:67%;" />
<p><code>主要区别：</code></p>
<ul>
<li>对 RNN 来说,假设最右边这个黄色的 vector,要考虑最左边的这个输入,那它必须要把最左边的输入存在 memory 裡面都<strong>不能够忘掉</strong>,一路带到最右边,才能够在最后一个时间点被考虑</li>
<li>但对 Self-attention 来说没有这个问题,可以在整个 sequence 上非常远的 vector之间<strong>轻易地抽取信息</strong>,所以这是 RNN 跟 Self-attention,一个不一样的地方</li>
</ul>
<p><strong>Self-attention 有一个优势,是它可以平行处理所有的输出，效率更高：</strong></p>
<ul>
<li>Self-attention:四个 vector 是平行产生的,并不需要等谁先运算完才把其他运算出来</li>
<li>RNN 是没有办法平行化的，必须依次产生</li>
</ul>
<h1>05-Transformer</h1><h2>应用<span class="hx-absolute -hx-mt-20" id="应用"></span>
    <a href="#%e5%ba%94%e7%94%a8" class="subheading-anchor" aria-label="Permalink for this section"></a></h2><blockquote>
<p>语音，机器翻译，聊天机器人，语音合成</p>
</blockquote>
<blockquote>
<p>由于自注意力同时具有<em><strong>并行计算</strong></em>和<em><strong>最短的最大路径长度</strong></em>这两个优势，所以想到用该想法来设计深度学习架构。&gt; &gt;</p>
<blockquote>
<p>transformer模型完全基于注意力机制，没有任何卷积层或循环神经网络层</p>
<p>更准确地讲，Transformer由且仅由<strong>self-Attenion</strong>和<strong>Feed Forward Neural Network</strong>组成。一个基于Transformer的可训练的神经网络可以通过堆叠Transformer的形式进行搭建</p>
</blockquote>
</blockquote>
<img src="https://zh-v2.d2l.ai/_images/transformer.svg" alt="../_images/transformer.svg" style="zoom: 80%;" />
<h2>解决的问题<span class="hx-absolute -hx-mt-20" id="解决的问题"></span>
    <a href="#%e8%a7%a3%e5%86%b3%e7%9a%84%e9%97%ae%e9%a2%98" class="subheading-anchor" aria-label="Permalink for this section"></a></h2><p>考虑到 RNN 相关算法只能从左向右依次计算或者从右向左依次计算，这种机制带来了两个问题：</p>
<ol>
<li>
<p>时间片 t 的计算依赖 t−1 时刻的计算结果，这样限制了模型的并行能力；（后者的输入过分依赖前者输出）</p>
</li>
<li>
<p>顺序计算的过程中信息会丢失，尽管LSTM等门机制的结构一定程度上缓解了长期依赖的问题，但是对于特别长期的依赖现象,LSTM（长短期记忆）依旧无能为力。</p>
<blockquote>
<p>LSTM（Long-Short Term Memory）：一种特殊的 <a href="https://easyai.tech/ai-definition/rnn/" target="_blank" rel="noopener">RNN</a>，能够学习长期依赖性。公共LSTM单元由单元，输入门，输出门和忘记门组成。该单元记住任意时间间隔内的值，并且三个门控制进出单元的信息流。</p>
</blockquote>
<blockquote>
<p>GRU（Gate Recurrent Unit）：和LSTM一样，也是为了解决长期记忆和反向传播中的梯度等问题而提出来的。功能相当于LSTM，但更易计算，GRU内部少了一个”门控“，参数比LSTM少，考虑到硬件的<strong>计算能力</strong>和<strong>时间成本</strong>，GRU优先</p>
</blockquote>
</li>
</ol>
<p><strong>Transformer</strong>的提出解决了上面两个问题，首先它使用了Attention机制，将序列中的任意两个位置之间的距离是缩小为一个常量（可以为1）；其次它不是类似RNN的顺序结构，因此具有更好的并行性，符合现有的GPU框架。</p>
<h2>本质<span class="hx-absolute -hx-mt-20" id="本质"></span>
    <a href="#%e6%9c%ac%e8%b4%a8" class="subheading-anchor" aria-label="Permalink for this section"></a></h2><blockquote>
<p>一个Encoder-Decoder的结构</p>
</blockquote>
<img src="https://pic1.zhimg.com/v2-5a252caa82f87920eadea2a2e93dc528_r.jpg" alt="img" style="zoom: 67%;" />
<img src="https://pic3.zhimg.com/80/v2-c14a98dbcb1a7f6f2d18cf9a1f591be6_1440w.webp" alt="img" style="zoom: 50%;" />
<p>由上图，编码器由6个编码block组成，同样解码器是6个解码block组成。与所有的生成模型相同的是，编码器的输出会作为解码器的输入</p>
<p>在Transformer的encoder中，数据首先会经过一个叫做<code>self-attention</code>的模块得到一个加权之后的特征向量 Z ，这个 Z 便是论文公式1中的 Attention(Q,K,V) ：</p>
<img src="C:\Users\11842\AppData\Roaming\Typora\typora-user-images\image-20221008140244425.png" alt="image-20221008140244425" style="zoom:80%;" />
<p>得到 Z 之后，它会被送到encoder的下一个模块，即<code>Feed Forward Neural Network</code>(前馈神经网络)。这个全连接有两层，第一层的激活函数是ReLU，第二层是一个线性激活函数，可以表示为：</p>
<blockquote>
<p>前馈神经网络：又叫<a href="https://so.csdn.net/so/search?q=%e5%a4%9a%e5%b1%82%e6%84%9f%e7%9f%a5%e5%99%a8&amp;spm=1001.2101.3001.7020" target="_blank" rel="noopener">多层感知器</a>（Multi-Layer Perceptron，MLP），是一种最简单的<a href="https://baike.baidu.com/item/%e7%a5%9e%e7%bb%8f%e7%bd%91%e7%bb%9c/16600562?fromModule=lemma_inlink" target="_blank" rel="noopener">神经网络</a>，各神经元分层排列，每个神经元只与前一层的神经元相连。接收前一层的输出，并输出给下一层，各层间没有反馈</p>
</blockquote>
<img src="C:\Users\11842\AppData\Roaming\Typora\typora-user-images\image-20221008140402702.png" alt="image-20221008140402702" style="zoom:80%;" />
<p><code>Self-Attention是Transformer最核心的内容</code></p>
<p>self-attention中，每个单词有3个不同的向量，它们分别是<strong>Query向量（ Q ），Key向量（ K ）和Value向量（ V ）</strong>，长度均是64。它们是通过3个不同的权值矩阵由嵌入向量 X 乘以三个不同的权值矩阵 WQ ， WK ， WV 得到，其中三个矩阵的尺寸也是相同的。均是 512×64 。</p>
<p><code>Attention的计算方法，整个过程可以分成7步：</code></p>
<ol>
<li>如上文，将输入单词转化成嵌入向量；</li>
<li>根据嵌入向量得到 q ， k ， v 三个向量；</li>
<li>为每个向量计算一个score： score=q⋅k ；</li>
<li>为了梯度的稳定，Transformer使用了score归一化，即除以 dk ；</li>
<li>对score施以softmax激活函数；</li>
<li>softmax点乘Value值 v ，得到加权的每个输入向量的评分 v ；</li>
<li>相加之后得到最终的输出结果 z ： z=∑v 。</li>
</ol>
<blockquote>
<p>最后一点强调其采用了<a href="https://zhuanlan.zhihu.com/p/42706477" target="_blank" rel="noopener">残差网络</a>中的short-cut结构，目的当然是解决深度学习中的退化问题,层加深可能导致“网络”退化</p>
</blockquote>
<h2>优缺点<span class="hx-absolute -hx-mt-20" id="优缺点"></span>
    <a href="#%e4%bc%98%e7%bc%ba%e7%82%b9" class="subheading-anchor" aria-label="Permalink for this section"></a></h2><p><strong>优点</strong>：</p>
<ol>
<li>虽然Transformer最终也没有逃脱传统学习的套路，Transformer也只是一个全连接（或者是一维卷积）加Attention的结合体。但是其设计已经足够有创新，因为其抛弃了在NLP中最根本的RNN或者CNN并且取得了非常不错的效果，算法的设计非常精彩，值得每个深度学习的相关人员仔细研究和品位。</li>
<li>Transformer的设计最大的带来性能提升的关键是将任意两个单词的距离是1，这对解决NLP中棘手的长期依赖问题是非常有效的。</li>
<li>Transformer不仅仅可以应用在NLP的机器翻译领域，甚至可以不局限于NLP领域，是非常有科研潜力的一个方向。</li>
<li>算法的并行性非常好，符合目前的硬件（主要指GPU）环境。</li>
</ol>
<p><strong>缺点</strong>：</p>
<ol>
<li>粗暴的抛弃RNN和CNN虽然非常炫技，但是它也使模型丧失了捕捉局部特征的能力，RNN + CNN + Transformer的结合可能会带来更好的效果</li>
<li>Transformer失去的位置信息其实在NLP中非常重要，而论文中在特征向量中加入Position Embedding也只是一个权宜之计，并没有改变Transformer结构上的固有缺陷。</li>
</ol>
<h2>Seq2Seq（<em>序列到序列</em>）<span class="hx-absolute -hx-mt-20" id="seq2seq序列到序列"></span>
    <a href="#seq2seq%e5%ba%8f%e5%88%97%e5%88%b0%e5%ba%8f%e5%88%97" class="subheading-anchor" aria-label="Permalink for this section"></a></h2><p><strong>Encoder-Decoder</strong>结构的网络，它的输入是一个序列，输出也是一个序列。在Encoder中，将序列转换成一个固定长度的向量，然后通过Decoder将该向量转换成我们想要的序列输出出来。</p>
<p>==Encoder==</p>
<ul>
<li>输入序列,可以使用RNN，CNN，Self-attention</li>
<li>内部 block 包含若干层, Self-attention+FC在送入block之前，需先进行positional encoding(位置编码)</li>
</ul>
<p>==Decoder==</p>
<ul>
<li>
<p>输出序列，Decoder 会把自己的输出,当做接下来的输入。</p>
<ul>
<li>
<p>如果产生错误则会导致Error Propagation，步步错 	–&gt; 	解决：Teacher Forcing</p>
</li>
<li>
<blockquote>
<p>teacher-forcing 在训练网络过程中，每次不使用上一个state的输出作为下一个state的输入，而是直接使用训练数据的标准答案(ground truth)的对应上一项作为下一个state的输入。</p>
</blockquote>
</li>
</ul>
</li>
</ul>
<p>==Encoder-Decoder之间的信息传递⇒CrossAttention==</p>
<p>过程：</p>
<ol>
<li>Encoder输入一排向量,输出一排向量 $a^1,a^2,a^3$，经过transform產生 Key1 Key2 Key3（ $k^1,k^2,k^3$)，以及 $v^1,v^2,v^3$.（encoder 拿到 K，V）</li>
<li>Decoder 会先吃 BEGIN,得到一个向量,输入多少长度的向量,输出就是多少向量。乘上一个矩阵做一个 Transform,得到一个 Query 叫做  $q$（decoder 拿到 Q）</li>
<li>利用q,k计算attention的分数，并做Normalization，得到 $\alpha_1&rsquo;,\alpha_2&rsquo;,\alpha_3&rsquo;,$</li>
<li>$\alpha_1&rsquo;,\alpha_2&rsquo;,\alpha_3&rsquo;,$与 $v^1,v^2,v^3$做weighted sum（加权求和），得到  $v$.</li>
<li>$v$丢进Fully-Connected 的Network，做接下来的任务。</li>
</ol>
<blockquote>
<p>总结：Decoder 就是产生一个q,去 Encoder 抽取信息出来,当做接下来的 Decoder 的Fully-Connected 的 Network 的 Input</p>
</blockquote>
<p>==评测标准==</p>
<p><code>BLEU</code></p>
<blockquote>
<p>BLEU 就是用来衡量<a href="https://so.csdn.net/so/search?q=%e6%9c%ba%e5%99%a8%e7%bf%bb%e8%af%91&amp;spm=1001.2101.3001.7020" target="_blank" rel="noopener">机器翻译</a>文本与参考文本之间的相似程度的指标,取值范围在0-1, 取值越靠近1表示机器翻译结果越好。</p>
</blockquote>
<img src="C:\Users\11842\AppData\Roaming\Typora\typora-user-images\image-20221009103458199.png" alt="image-20221009103458199" style="zoom:67%;" />
<p><strong>但是</strong>，在训练时，是对每一个生成的token进行优化，使用的指标是交叉熵。</p>
<p>换言之，训练的时候,是看 Cross Entropy,但是我们实际上你作业真正评估的时候,看的是 BLEU Score。</p>
<p><strong>并且，不能把BLEU作为LOSS⇒无法微分。</strong></p>
<p>**解决办法：**遇到你在 Optimization 无法解决的问题,用 RL 硬 Train 一发。遇到你无法 Optimize 的 Loss Function,把它当做是 RL 的 Reward,把你的 Decoder 当做是 Agent。</p>
<p>==Scheduled Sampling==</p>
<p>Scheduled Sampling是指RNN训练时时会<strong>随机使用模型真实label</strong>来作为下一个时刻的输入，而不像原先那样只会使用预测输出，原先是Teacher Forcing的缘故，但会使训练集和测试集效果不一，所以偶尔需要给 decoder一些错误的输入 —&gt; 采用计划采样。</p>
<p>缺点是会损坏平行化能力。</p>
<h1>06-Generative Model(GAN)</h1><p><code>生成对抗网络</code></p>
<p>属于非监督学习，通过两个神经网络相互博弈的方式进行学习</p>
<h2>应用<span class="hx-absolute -hx-mt-20" id="应用-1"></span>
    <a href="#%e5%ba%94%e7%94%a8-1" class="subheading-anchor" aria-label="Permalink for this section"></a></h2><p>Anime Face Generation（动画人脸生成）</p>
<p>Progressive GAN——真实人脸生成⇒生成“没有看过的\连续变化的”人脸</p>
<h2>结构<span class="hx-absolute -hx-mt-20" id="结构"></span>
    <a href="#%e7%bb%93%e6%9e%84" class="subheading-anchor" aria-label="Permalink for this section"></a></h2><p><code>生成器 Generation</code></p>
<ul>
<li>
<p>对于生成器，输入需要一个n维度向量，输出为图片像素大小的图片。因而首先我们需要得到输入的向量。</p>
<blockquote>
<p>Tips: 生成器可以是任意可以输出图片的模型，比如最简单的全连接神经网络，又或者是反卷积网络等。</p>
</blockquote>
<p>这里输入的向量我们将其视为携带输出的某些信息，比如说手写数字为数字几，手写的潦草程度等等。由于这里我们对于输出数字的具体信息不做要求，只要求其能够最大程度与真实手写数字相似（能骗过判别器）即可。所以我们使用<strong>随机生成的向量来作为输入</strong>即可，这里面的随机输入最好是满足常见分布比如均值分布，高斯分布等。</p>
<blockquote>
<p>Tips: 假如我们后面需要获得具体的输出数字等信息的时候，我们可以对输入向量产生的输出进行分析，获取到哪些维度是用于控制数字编号等信息的即可以得到具体的输出。而在训练之前往往不会去规定它。</p>
</blockquote>
</li>
</ul>
<p><code>判别器 Discriminator</code></p>
<ul>
<li>
<p>往往是常见的判别器，输入为图片，输出为图片的真伪标签。</p>
<blockquote>
<p>Tips: 判别器与生成器一样，可以是任意的判别器模型，比如全连接网络，或者是包含卷积的网络等等。</p>
</blockquote>
</li>
</ul>
<h2>训练<span class="hx-absolute -hx-mt-20" id="训练"></span>
    <a href="#%e8%ae%ad%e7%bb%83" class="subheading-anchor" aria-label="Permalink for this section"></a></h2><p>基本流程如下：</p>
<ul>
<li>初始化判别器D的参数 θd 和生成器G的参数 θg 。</li>
<li>从真实样本中采样 m 个样本 { x1,x2,&hellip;xm } ，从先验分布噪声中采样 m 个噪声样本 { z1,z2,&hellip;,zm } 并通过生成器获取 m 个生成样本 { x~1,x~2,&hellip;,x~m } 。固定生成器G，训练判别器D尽可能好地准确判别真实样本和生成样本，尽可能大地区分正确样本和生成的样本。</li>
<li><strong>循环k次更新判别器之后，使用较小的学习率来更新一次生成器的参数</strong>，训练生成器使其尽可能能够减小生成样本与真实样本之间的差距，也相当于尽量使得判别器判别错误。</li>
<li>多次更新迭代之后，最终理想情况是使得判别器判别不出样本来自于生成器的输出还是真实的输出。亦即最终样本判别概率均为0.5。</li>
</ul>
<blockquote>
<p>Tips: 之所以要训练k次判别器，再训练生成器，是因为要先拥有一个好的判别器，使得能够教好地区分出真实样本和生成样本之后，才好更为准确地对生成器进行更新。更直观的理解可以参考下图：</p>
</blockquote>
<img src="https://pic2.zhimg.com/v2-11cdb09371a33f4526a8a7f79e0e39f1_r.jpg" alt="img" style="zoom: 50%;" />
<blockquote>
<p>注：图中的<strong>黑色虚线</strong>表示真实的样本的分布情况，<strong>蓝色虚线</strong>表示判别器判别概率的分布情况，<strong>绿色实线</strong>表示生成样本的分布。 Z 表示噪声， Z 到 x 表示通过生成器之后的分布的映射情况。</p>
</blockquote>
<p>我们的目标是使用生成样本分布（绿色实线）去拟合真实的样本分布（黑色虚线），来达到生成以假乱真样本的目的。</p>
<p>可以看到在**（a）<strong>状态处于最初始的状态的时候，生成器生成的分布和真实分布区别较大，并且判别器判别出样本的概率不是很稳定，因此会先训练判别器来更好地分辨样本。
通过多次训练判别器来达到</strong>（b）<strong>样本状态，此时判别样本区分得非常显著和良好。然后再对生成器进行训练。
训练生成器之后达到</strong>（c）<strong>样本状态，此时生成器分布相比之前，逼近了真实样本分布。
经过多次反复训练迭代之后，最终希望能够达到</strong>（d）**状态，生成样本分布拟合于真实样本分布，并且判别器分辨不出样本是生成的还是真实的（判别概率均为0.5）。也就是说我们这个时候就可以生成出非常真实的样本啦，目的达到。</p>
<h3>训练的难点<span class="hx-absolute -hx-mt-20" id="训练的难点"></span>
    <a href="#%e8%ae%ad%e7%bb%83%e7%9a%84%e9%9a%be%e7%82%b9" class="subheading-anchor" aria-label="Permalink for this section"></a></h3><ul>
<li>生成器和判别器需要 match each other（棋逢对手）</li>
</ul>
<p>这两个 Network,这个 Generator 跟 Discriminator,它们是<strong>互相砥砺,才能互相成长的</strong>,只要其中一者,发生什么问题停止训练,另外一者就会跟著停下训练,就会跟著变差。我们需要保证二者的loss在这一过程中不断下降。</p>
<p>**困难：**Discriminator 跟 Generator,它们互动的过程是自动的。我们不会在中间,每一次 Train Discriminator 的时候都换 Hyperparameter（超参数）。如果有一次loss没有下降，那整个训练过程都有可能出现问题。</p>
<p><code>GAN for sequence Generation⇒不能用GD</code></p>
<p>由于取了max，这一运算使得Discriminator的score对decoder参数不可微分，也就不能做GD。</p>
<p>不能使用GD⇒使用Reinforcement Learning（强化学习）？→GAN+RL难以训练</p>
<p>**解决：**直接从随机的初始化参数开始Train 它的 Generator,然后让 Generator 可以產生文字,它最关键的就是爆调 Hyperparameter,跟一大堆的 Tips</p>
<h2>生成器评估<span class="hx-absolute -hx-mt-20" id="生成器评估"></span>
    <a href="#%e7%94%9f%e6%88%90%e5%99%a8%e8%af%84%e4%bc%b0" class="subheading-anchor" aria-label="Permalink for this section"></a></h2><ul>
<li>直觉的方法：人眼来看⇒不客观、不稳定、代价高</li>
<li>自动化方法：影像分类系统</li>
</ul>
<p><code>Quality：对一张图片</code></p>
<p>将图片输入影像辨识系统：</p>
<ul>
<li>这个概率的分布如果越集中，说明产生的图片能够被影像分类系统“很肯定地”分辨出来，代表说现在产生的图片可能越好。</li>
<li>反之，如果产生的图像是“四不像”，图片分类系统感到困惑，概率分布变得平坦。</li>
</ul>
<p><code>Diversity：对所有（一批）图片</code></p>
<ul>
<li>Diversity-Mode Collapse(模型崩溃）⇒训练输出的分布局限在很小的范围。</li>
<li>Diversity-Mode Dropping(模型丢弃）⇒训练输出的分布范围较大，但没有完全覆盖真实数据分布（多样性减小）。</li>
</ul>
<p>评估多样性：把影像辨识系统对所有生成结果的输出平均起来。</p>
<img src="https://diamond-mule-bee.notion.site/image/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2Fb9a35b8b-fe11-4aaa-9ac1-1d7808592205%2FUntitled.png?table=block&id=0f03650e-417e-423a-aca1-76b75a6ea4c7&spaceId=effd33e2-527b-43dc-aef5-7b5ee7b83428&width=2000&userId=&cache=v2" alt="img" style="zoom:67%;" />
<ul>
<li>平均分布集中⇒多样性低</li>
<li>平均分布“均匀”⇒多样性高</li>
</ul>
<p><code>量化指标</code></p>
<p>Inception Score（IS）⇒基于CNN的Inception网络</p>
<blockquote>
<p>基于paper：<em><strong>A Note on the Inception Score</strong></em></p>
</blockquote>
<p><strong>很多关于 GAN 生成图片的论文中，作者评价其模型表现的一项重要指标是 Inception Score（下文简称 IS）</strong></p>
<p>主要考虑两方面：</p>
<ul>
<li>清晰度</li>
<li>多样性</li>
</ul>
<p>言归正传：将生成器 生成结果放进Inception网络，通过输出的分布结果来衡量。如果 Quality 高,那个 Diversity 又大,那 Inception Score 就会比较大</p>
<p><code>Fréchet Inception Distance (FID)</code></p>
<p>Frechet Inception 距离（FID）是评估生成图像质量的度量标准，专门用于评估生成对抗网络的性能。</p>
<p>一些情况下，生成的图像是“同一类别”的，看“分布”并不合适。</p>
<p>同样将图片送入Inception Network，取Softmax 之前的 Hidden Layer 输出的向量，来代表这张图片，利用这个向量来衡量两个分布之间的关系。</p>
<p>⇒假设真实数据和生成数据的两个分布，都是从高斯分布中抽样得到的，计算两个高斯分布之间的Fréchet Distance，越小代表分布越接近，图片品质越高。</p>
<p><strong>问题：</strong></p>
<ul>
<li>将任意分布都视为“高斯分布”会有问题</li>
<li>计算FID需要大量采样，计算量大。</li>
</ul>
<h2>举例<span class="hx-absolute -hx-mt-20" id="举例"></span>
    <a href="#%e4%b8%be%e4%be%8b" class="subheading-anchor" aria-label="Permalink for this section"></a></h2><p>Conditional Generation⇒supervised learning</p>
<h3>Case 1:Text-to-image<span class="hx-absolute -hx-mt-20" id="case-1text-to-image"></span>
    <a href="#case-1text-to-image" class="subheading-anchor" aria-label="Permalink for this section"></a></h3><img src="https://diamond-mule-bee.notion.site/image/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2F00475494-2ba0-4859-b34b-4e56deb3b17e%2FUntitled.png?table=block&id=d912cb25-2a9c-457a-a6dd-13561a566535&spaceId=effd33e2-527b-43dc-aef5-7b5ee7b83428&width=2000&userId=&cache=v2" alt="img" style="zoom: 67%;" />
<p><strong>操控 Generator 的输出</strong>,我们给它一个 Condition条件 x，再从一个简单分布中抽样一个$z$,让generator<strong>根据 x 跟 z 来产生 y。</strong></p>
<p>例如，x 就是一段文字，对希望得到的人脸形象进行描述。</p>
<blockquote>
<p>如何训练？</p>
</blockquote>
<p>魔改DIscriminator**：**</p>
<p>Discriminator 不是只吃图片 y,它还要吃 Condition x。一方面<strong>图片要好</strong>,另外一方面,这个<strong>图片跟文字的叙述必须要是相配</strong>的,Discriminator 才会给高分。</p>
<h3>Case 2：Image Translation（pix2pix）<span class="hx-absolute -hx-mt-20" id="case-2image-translationpix2pix"></span>
    <a href="#case-2image-translationpix2pix" class="subheading-anchor" aria-label="Permalink for this section"></a></h3><blockquote>
<p>注：利用Supervised Learning训练的问题→输出“模糊”</p>
<p>解决：单纯用 GAN 的话,它有一个小问题,所以它產生出来的图片,比较真实,但是它的问题是它的创造力,想像力过度丰富,如果你要做到最好,往往就是 GAN 跟 Supervised Learning,同时使用。</p>
</blockquote>
<h3>Case 3：声音-图片<span class="hx-absolute -hx-mt-20" id="case-3声音-图片"></span>
    <a href="#case-3%e5%a3%b0%e9%9f%b3-%e5%9b%be%e7%89%87" class="subheading-anchor" aria-label="Permalink for this section"></a></h3><h3>Case 4： 产生会动的人像<span class="hx-absolute -hx-mt-20" id="case-4-产生会动的人像"></span>
    <a href="#case-4-%e4%ba%a7%e7%94%9f%e4%bc%9a%e5%8a%a8%e7%9a%84%e4%ba%ba%e5%83%8f" class="subheading-anchor" aria-label="Permalink for this section"></a></h3><h1>07-Self-Supervised Learning（BERT）</h1><p><code>自我监督学习</code></p>
<blockquote>
<p>BERT(Bidirectional Encoder Representation from Transformers)是2018年10月由Google AI研究院提出的一种预训练模型</p>
</blockquote>
<p>BERT是一个<strong>transformer的Encoder</strong>，BERT可以输入一行向量，然后输出另一行向量，输出的长度与输入的长度相同。BERT一般用于<strong>自然语言处理</strong>，一般来说，它的输入是一串文本。当然，也可以输入语音、图像等“序列”。</p>
<h2>Masking Input<span class="hx-absolute -hx-mt-20" id="masking-input"></span>
    <a href="#masking-input" class="subheading-anchor" aria-label="Permalink for this section"></a></h2><p>随机盖住一些输入的文字，被mask的部分是随机决定的。</p>
<p><code>MASK的方法：</code></p>
<ul>
<li>第一种方法是，用一个<strong>特殊的符号替换句子中的一个词</strong>，我们用 <strong>&ldquo;MASK &ldquo;标</strong>记来表示这个特殊符号，你可以把它看作一个新字，这个字完全是一个新词，它不在你的字典里，这意味着mask了原文。</li>
<li>另外一种方法，<strong>随机</strong>把某一个字<strong>换成另一个字</strong>。中文的 &ldquo;湾&quot;字被放在这里，然后你可以选择另一个中文字来替换它，它可以变成 &ldquo;一 &ldquo;字，变成 &ldquo;天 &ldquo;字，变成 &ldquo;大 &ldquo;字，或者变成 &ldquo;小 &ldquo;字，我们只是用随机选择的某个字来替换它</li>
</ul>
<p>两种方法<strong>都可以使用，使用哪种方法也是随机决定的。</strong></p>
<p><code>训练方法：</code></p>
<ol>
<li>向BERT输入一个句子，先随机决定哪一部分的汉字将被mask。</li>
<li>输入一个序列，我们把BERT的相应输出看作是另一个序列</li>
<li>在输入序列中寻找mask部分的相应输出，将这个向量通过一个Linear transform（矩阵相乘），并做Softmax得到一个分布。</li>
<li>用一个one-hot vector来表示MASK的字符，并使输出和one-hot vector之间的交叉熵损失最小。</li>
</ol>
<blockquote>
<p>💡 本质上，就是在解决一个<strong>分类问题</strong>。BERT要做的是<strong>预测什么被盖住。</strong></p>
</blockquote>
<p><code>BERT的实际用途</code>⇒下游任务（Downstream Tasks）</p>
<p><code>预训练与微调：</code></p>
<ul>
<li>
<p>预训练：产生BERT的过程</p>
</li>
<li>
<p>微调：利用一些特别的信息，使BERT能够完成某种任务</p>
<ul>
<li>BERT只学习了两个“填空”任务。</li>
</ul>
</li>
<li>
<p>一个是掩盖一些字符，然后要求它填补缺失的字符。</p>
</li>
<li>
<p>预测两个句子是否有顺序关系。</p>
</li>
</ul>
<p>但是，BERT可以被应用在其他的任务【真正想要应用的任务】上，可能与“填空”并无关系甚至完全不同。【胚胎干细胞】当我们想让BERT学习做这些任务时，只<strong>需要一些标记的信息，就能够“激发潜能”</strong>。</p>
<h2>评价任务集——GLUE<span class="hx-absolute -hx-mt-20" id="评价任务集glue"></span>
    <a href="#%e8%af%84%e4%bb%b7%e4%bb%bb%e5%8a%a1%e9%9b%86glue" class="subheading-anchor" aria-label="Permalink for this section"></a></h2><p><strong>（General Language Understanding Evaluation）</strong></p>

        </div>
        <div class="hx-mt-16"></div>
        
        
      </main>
    </article>
  </div>

      <footer class="hextra-footer hx-bg-gray-100 hx-pb-[env(safe-area-inset-bottom)] dark:hx-bg-neutral-900 print:hx-bg-transparent"><div
    class="hx-max-w-screen-xl hx-mx-auto hx-flex hx-justify-center hx-py-12 hx-pl-[max(env(safe-area-inset-left),1.5rem)] hx-pr-[max(env(safe-area-inset-right),1.5rem)] hx-text-gray-600 dark:hx-text-gray-400 md:hx-justify-start"
  >
    <div class="hx-flex hx-w-full hx-flex-col hx-items-center sm:hx-items-start"><div class="hx-font-semibold"><a class="hx-flex hx-text-sm hx-items-center hx-gap-1 hx-text-current" target="_blank" rel="noopener noreferrer" title="Hextra GitHub Homepage" href="https://github.com/imfing/hextra">
    <span>Powered by Hextra<svg height=1em class="hx-inline-block ltr:hx-ml-1 rtl:hx-mr-1 hx-align-[-2.5px]" viewBox="0 0 180 180" xmlns="http://www.w3.org/2000/svg" fill="currentColor"><path fill-rule="evenodd" clip-rule="evenodd" d="m 105.50024,22.224647 c -9.59169,-5.537563 -21.40871,-5.537563 -31.000093,0 L 39.054693,42.689119 C 29.463353,48.226675 23.55484,58.460531 23.55484,69.535642 v 40.928918 c 0,11.07542 5.908513,21.3092 15.499853,26.84652 l 35.445453,20.46446 c 9.591313,5.53732 21.408404,5.53732 31.000094,0 l 35.44507,-20.46446 c 9.59131,-5.53732 15.49985,-15.7711 15.49985,-26.84652 V 69.535642 c 0,-11.075111 -5.90854,-21.308967 -15.49985,-26.846523 z M 34.112797,85.737639 c -1.384445,2.397827 -1.384445,5.352099 0,7.749927 l 24.781554,42.922974 c 1.38437,2.39783 3.942853,3.87496 6.711592,3.87496 h 49.563107 c 2.76905,0 5.3273,-1.47713 6.71144,-3.87496 l 24.78194,-42.922974 c 1.38414,-2.397828 1.38414,-5.3521 0,-7.749927 L 121.88049,42.814746 c -1.38414,-2.397828 -3.94239,-3.874964 -6.71144,-3.874964 H 65.605944 c -2.768739,0 -5.327223,1.477059 -6.711592,3.874964 z" style="stroke-width:0.774993" /></svg></span>
  </a></div>
    </div>
  </div>
</footer>
    
    <script defer src="/js/main.js" integrity=""></script>


<script defer src="/lib/flexsearch/flexsearch.bundle.min.0425860527cc9968f9f049421c7a56b39327d475e2e3a8f550416be3a9134327.js" integrity="sha256-BCWGBSfMmWj58ElCHHpWs5Mn1HXi46j1UEFr46kTQyc="></script>
    <script defer src="/en.search.js" integrity=""></script>


  </body>
</html>
